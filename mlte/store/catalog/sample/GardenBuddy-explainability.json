{
    "header": {
        "identifier": "GardenBuddy-explainability",
        "creator": "admin",
        "created": 1762988044,
        "updater": null,
        "updated": 1762988044,
        "catalog_id": "sample"
    },
    "tags": [
        "Computer Vision",
        "Object detection"
    ],
    "quality_attribute": "explainability",
    "code": "# ## 2e. Evidence - Explainability QAS Measurements.\n# \n# Now we proceed to gather data about the Interpretability of the model, for the corresponding scenario.\n# \n# The cell below must contain JSON data about this evidence that will be used to automatically populate the sample test catalog.\n\n# ### Initialize MLTE Context\n# \n# MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use.\n\n# Sets up context for the model being used, sets up constants related to folders and model data to be used.\nfrom session import *\n\n\n# ### Set up scenario test case\n\nfrom mlte.negotiation.artifact import NegotiationCard\n\ncard = NegotiationCard.load()\nqa = 4\nprint(card.quality_scenarios[qa])\n\n\n# **A Specific test case generated from the scenario:**\n# \n# **Data and Data Source:**\tThe original test data set can be used.\n# \n# **Measurement and Condition:**\tThe model needs to return evidence, in this case a heat map implementing the Integrated Gradients algorithm, showing the pixels that were most informative in the classification decision. This evidence should be returned with each inference. \n# \n# **Context:**\tNormal Operation\n\n# ### Helper Functions\n# \n# Functions to help, and data setup.\n\nfrom utils.model_analysis import *\n\n# Load the model/\nloaded_model = load_model(MODEL_FILE_PATH)\n\n\n# Load and show the image.\n\nflower_img = \\\"0degk_image_flower3.jpg\\\"  # Filename of flower image to use, public domain image adapted from: https://commons.wikimedia.org/wiki/File:Beautiful_white_flower_in_garden.jpg\nflower_idx = (\n    42  # Classifier index of associated flower (see OxfordFlower102Labels.csv)\n)\n\nim = read_image(os.path.join(SAMPLE_DATASET_DIR, flower_img))\n\nplt.imshow(im)\nplt.axis(\\\"off\\\")\nplt.show()\n\n\npredictions = run_model(im, loaded_model)\n\nbaseline, alphas = generate_baseline_and_alphas()\n\n\ninterpolated_images = interpolate_images(\n    baseline=baseline, image=im, alphas=alphas\n)\n\n\nfig = plt.figure(figsize=(20, 20))\n\ni = 0\nfor alpha, image in zip(alphas[0::10], interpolated_images[0::10]):\n    i += 1\n    plt.subplot(1, len(alphas[0::10]), i)\n    plt.title(f\\\"alpha: {alpha:.1f}\\\")\n    plt.imshow(image)\n    plt.axis(\\\"off\\\")\n\nplt.tight_layout()\n\n\npath_gradients = compute_gradients(\n    loaded_model=loaded_model,\n    images=interpolated_images,\n    target_class_idx=flower_idx,\n)\nprint(path_gradients.shape)\n\nig = integral_approximation(gradients=path_gradients)\nprint(ig.shape)\n\n\nig_attributions = integrated_gradients(\n    baseline=baseline,\n    image=im,\n    target_class_idx=flower_idx,\n    loaded_model=loaded_model,\n    m_steps=240,\n)\nprint(ig_attributions.shape)\n\n\n# ### Measurements\n# \n# Execute and store measurements.\n\nfig = plot_img_attributions(\n    image=im,\n    baseline=baseline,\n    target_class_idx=flower_idx,\n    loaded_model=loaded_model,\n    m_steps=240,\n    cmap=plt.cm.inferno,\n    overlay_alpha=0.4,\n)\n\nplt.savefig(MEDIA_DIR / \\\"0e_explainability_attributions.png\\\")\n\n\nfrom mlte.measurement.external_measurement import ExternalMeasurement\nfrom mlte.evidence.types.image import Image\n\n# Save to MLTE store.\nimg_collector = ExternalMeasurement(\\\"image attributions\\\", Image)\nimg = img_collector.evaluate(MEDIA_DIR / \\\"0e_explainability_attributions.png\\\")\nimg.save(force=True)\n\n\n\n",
    "description": "The model should return, when prompted, a image highlighting the most informative features to identifying the flower. This case attaches the generated image which needs to be manually validated for test pass/fail",
    "inputs": "Garden flower image",
    "output": "Image with informative features, which needs to be manually validated for pass/fail"
}