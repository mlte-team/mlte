{
    "header": {
        "identifier": "demo-interpretability",
        "creator": "admin",
        "created": 1727114774,
        "updater": null,
        "updated": 1761163043,
        "catalog_id": "sample"
    },
    "tags": [
        "Computer Vision"
    ],
    "quality_attribute": "Understanding Model Results",
    "code": "# ## 2d. Evidence - Interpretability QAS Measurements.\n# \n# Now we proceed to gather data about the Interpretability of the model, for the corresponding scenario.\n\n# ### Initialize MLTE Context\n# \n# MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use.\n\n# Sets up context for the model being used, sets up constants related to folders and model data to be used.\nfrom demo.scenarios.session import *\n\n\n# ### Helper Functions\n# \n# Functions to help, and data setup.\n\nfrom demo.scenarios.model_analysis import *\n\n# Load the model/\nloaded_model = load_model(MODEL_FILE_PATH)\n\n\n# Load and show the image.\n\nflower_img = \\\"flower3.jpg\\\"  # Filename of flower image to use, public domain image adapted from: https://commons.wikimedia.org/wiki/File:Beautiful_white_flower_in_garden.jpg\nflower_idx = (\n    42  # Classifier index of associated flower (see OxfordFlower102Labels.csv)\n)\n\nim = read_image(os.path.join(SAMPLE_DATASET_DIR, flower_img))\n\nplt.imshow(im)\nplt.axis(\\\"off\\\")\nplt.show()\n\n\npredictions = run_model(im, loaded_model)\n\nbaseline, alphas = generate_baseline_and_alphas()\n\n\ninterpolated_images = interpolate_images(\n    baseline=baseline, image=im, alphas=alphas\n)\n\n\nfig = plt.figure(figsize=(20, 20))\n\ni = 0\nfor alpha, image in zip(alphas[0::10], interpolated_images[0::10]):\n    i += 1\n    plt.subplot(1, len(alphas[0::10]), i)\n    plt.title(f\\\"alpha: {alpha:.1f}\\\")\n    plt.imshow(image)\n    plt.axis(\\\"off\\\")\n\nplt.tight_layout()\n\n\npath_gradients = compute_gradients(\n    loaded_model=loaded_model,\n    images=interpolated_images,\n    target_class_idx=flower_idx,\n)\nprint(path_gradients.shape)\n\nig = integral_approximation(gradients=path_gradients)\nprint(ig.shape)\n\n\nig_attributions = integrated_gradients(\n    baseline=baseline,\n    image=im,\n    target_class_idx=flower_idx,\n    loaded_model=loaded_model,\n    m_steps=240,\n)\nprint(ig_attributions.shape)\n\n\n# ### Measurements\n# \n# Execute and store measurements.\n\nfig = plot_img_attributions(\n    image=im,\n    baseline=baseline,\n    target_class_idx=flower_idx,\n    loaded_model=loaded_model,\n    m_steps=240,\n    cmap=plt.cm.inferno,\n    overlay_alpha=0.4,\n)\n\nplt.savefig(MEDIA_DIR / \\\"attributions.png\\\")\n\n\nfrom mlte.measurement.external_measurement import ExternalMeasurement\nfrom mlte.evidence.types.image import Image\n\n# Save to MLTE store.\nimg_collector = ExternalMeasurement(\\\"image attributions\\\", Image)\nimg = img_collector.evaluate(MEDIA_DIR / \\\"attributions.png\\\")\nimg.save(force=True)\n",
    "description": "The application that runs on the loaned device should indicate the main features that were used to recognize the flower, as part of the educational experience. The app will display the image highlighting the most informative features in flower identification, in addition to the flower name. The original test data set can be used. The model needs to return evidence, in this case a heat map implementing the Integrated Gradients algorithm, showing the pixels that were most informative in the classification decision. This evidence should be returned with each inference.",
    "inputs": "existing garden ML model, sample image",
    "output": "image with attributions"
}