{
    "header": {
        "identifier": "demo-fairness",
        "creator": "admin",
        "created": 1761246745,
        "updater": null,
        "updated": 1761246745,
        "catalog_id": "sample"
    },
    "tags": [
        "Computer Vision"
    ],
    "quality_attribute": "Model Impartial to Photo Location",
    "code": "# ## 2a. Evidence - Fairness QAS Measurements\n# \n# Evidence collected in this section checks for the Fairness scenario defined in the previous step. Note that some functions will be loaded from external Python files.\n# \n# The cell below must contain JSON data about this evidence that will be used to automatically populate the sample test catalog.\n\n# ### Initialize MLTE Context\n# \n# MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use.\n\n# Sets up context for the model being used, sets up constants related to folders and model data to be used.\nfrom demo.scenarios.session import *\n\n\n# ### Helper Functions\n# General functions and external imports.\n\n# General functions.\n\nfrom demo.scenarios import garden\nimport numpy as np\n\n\ndef load_data(data_folder: str):\n    \\\"\\\"\\\"Loads all garden data results and taxonomy categories.\\\"\\\"\\\"\n    df_results = garden.load_base_results(data_folder, \\\"predictions_test.csv\\\")\n    df_results.head()\n\n    # Load the taxonomic data and merge with results.\n    df_info = garden.load_taxonomy(data_folder)\n    df_results.rename(columns={\\\"label\\\": \\\"Label\\\"}, inplace=True)\n    df_all = garden.merge_taxonomy_with_results(df_results, df_info)\n\n    return df_info, df_all\n\n\ndef split_data(df_info, df_all, population_size=100):\n    \\\"\\\"\\\"Splits the data into 3 different populations to evaluate them.\\\"\\\"\\\"\n    df_gardenpop = df_info.copy()\n    df_gardenpop[\\\"Population1\\\"] = (\n        np.around(\n            np.random.dirichlet(np.ones(df_gardenpop.shape[0]), size=1)[0],\n            decimals=3,\n        )\n        * population_size\n    ).astype(int)\n    df_gardenpop[\\\"Population2\\\"] = (\n        np.around(\n            np.random.dirichlet(np.ones(df_gardenpop.shape[0]), size=1)[0],\n            decimals=3,\n        )\n        * population_size\n    ).astype(int)\n    df_gardenpop[\\\"Population3\\\"] = (\n        np.around(\n            np.random.dirichlet(np.ones(df_gardenpop.shape[0]), size=1)[0],\n            decimals=3,\n        )\n        * population_size\n    ).astype(int)\n    # df_gardenpop\n    print(\\\"Hello\\\")  # df_gardenpop[\\\"Population2\\\"])\n\n    print(df_gardenpop[\\\"Population2\\\"])\n    # build populations from test data set that match the garden compositions\n    from random import choices\n\n    # build 3 gardens with populations of population_size.\n    pop_names = [\\\"Population1\\\", \\\"Population2\\\", \\\"Population3\\\"]\n    gardenpops = np.zeros((3, population_size), int)\n    gardenmems = np.zeros((3, population_size), int)\n\n    for j in range(population_size):\n        for i in range(len(df_gardenpop)):\n            my_flower = df_gardenpop.iloc[i][\\\"Common Name\\\"]\n\n            for g in range(3):\n                n_choices = df_gardenpop.iloc[i][pop_names[g]]\n                my_choices = df_all[df_all[\\\"Common Name\\\"] == my_flower][\n                    \\\"model correct\\\"\n                ].to_list()\n                # print(f\\\"{n_choices} {my_choices}\\\")\n                my_selection = choices(my_choices, k=n_choices)\n\n                gardenpops[g][j] += sum(my_selection)\n                gardenmems[g][j] += len(my_selection)\n\n    gardenpops\n\n    return gardenpops, gardenmems\n\n\ndef calculate_model_performance_acc(\n    gardenpops, gardenmems, population_size=100\n):\n    \\\"\\\"\\\"Get accucray of models across the garden populations\\\"\\\"\\\"\n    gardenacc = np.zeros((3, population_size), float)\n    for i in range(population_size):\n        for g in range(3):\n            gardenacc[g][i] = gardenpops[g][i] / gardenmems[g][i]\n    gardenacc\n\n    model_performance_acc = []\n    for g in range(3):\n        avg = round(np.average(gardenacc[g][:]), 3)\n        std = round(np.std(gardenacc[g][:]), 3)\n        min = round(np.amin(gardenacc[g][:]), 3)\n        max = round(np.amax(gardenacc[g][:]), 3)\n        model_performance_acc.append(round(avg, 3))\n\n        print(\\\"%1d %1.3f %1.3f %1.3f %1.3f\\\" % (g, avg, std, min, max))\n\n    return model_performance_acc\n\n\n# Prepare the data. For this section, instead of executing the model, we will use CSV files containing the results of an already executed run of the model.\ndata = load_data(DATASETS_DIR)\nprint(\\\"Splitting Data\\\")\n# print(data)\nsplit_data = split_data(data[0], data[1])\n\n\ndata\n\n\n# ### Measurements\n# \n# In this first example, we simply wrap the output from `accuracy_score` with a custom `Result` type to cope with the output of a third-party library that is not supported by a MLTE builtin.\n\nfrom mlte.evidence.types.array import Array\nfrom mlte.measurement.external_measurement import ExternalMeasurement\n\n# Evaluate accuracy, identifier has to be the same one defined in the TestSuite.\naccuracy_measurement = ExternalMeasurement(\n    \\\"accuracy across gardens\\\", Array, calculate_model_performance_acc\n)\naccuracy = accuracy_measurement.evaluate(split_data[0], split_data[1])\n\n# Inspect value\nprint(accuracy)\n\n# Save to artifact store\naccuracy.save(force=True)\n",
    "description": "The model receives a picture taken at the garden and, regardless of the garden location, can correctly identify the correct flowers at least 90% of the time. Test data needs to include pictures of the flowers from the different gardens, grouped by the garden that the image was taken at. The quantity of the flower images should be representative of the garden population they are taken from. The total accuracy of the model across each garden population should be higher or equal to 0.9.",
    "inputs": "three garden populations, model results on Oxford garden data",
    "output": "accuracy across gardens"
}