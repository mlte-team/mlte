{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42fa80dc-9890-473f-bac3-83112c7a1edf",
   "metadata": {},
   "source": [
    "## 5i. Evidence - Economic Risk consideration QAS Measurement\n",
    "\n",
    "Evidence collected in this section checks for the economic risk consideration QAS scenario defined in the previous step. Note that some functions and data will be loaded from external Python files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db285322-317e-4c05-bc4f-f02dcba36bdc",
   "metadata": {},
   "source": [
    "### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89d0581-fce0-49b3-954a-180e1e27fe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial custom lists at URI: local:///Users/rbrowersinning/Documents/ResearchFolders/Continuum_LTP/GitRepos/mlte_llm/demo/ReviewPro/../store\n",
      "Loaded 7 qa_categories for initial list\n",
      "Loaded 30 quality_attributes for initial list\n",
      "Creating sample catalog at URI: StoreType.LOCAL_FILESYSTEM:local:///Users/rbrowersinning/Documents/ResearchFolders/Continuum_LTP/GitRepos/mlte_llm/demo/ReviewPro/../store\n",
      "Loading sample catalog entries.\n",
      "Loaded 9 entries for sample catalog.\n"
     ]
    }
   ],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from session import *\n",
    "from session_LLMinfo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1602e2-2525-46b1-a70f-f8b14ea9b5ff",
   "metadata": {},
   "source": [
    "### Set up scenario test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460f435f-38ff-4f30-8639-fdccb90b5e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card.default-qas_009\n",
      "Economic Risk Consideration\n",
      "ReviewPro receives a prompt for an employee evaluation from  the manager  during  normal operation .  ReviewPro should be able to, if prompted and in cases where the employee is financially hurting the company, generate a flag or notification of the behavior for the manager in place of a review\n"
     ]
    }
   ],
   "source": [
    "from mlte.negotiation.artifact import NegotiationCard\n",
    "\n",
    "card = NegotiationCard.load()\n",
    "qa = 8\n",
    "print(card.quality_scenarios[qa].identifier)\n",
    "print(card.quality_scenarios[qa].quality)\n",
    "print(\n",
    "    card.quality_scenarios[qa].stimulus,\n",
    "    \"from \",\n",
    "    card.quality_scenarios[qa].source,\n",
    "    \" during \",\n",
    "    card.quality_scenarios[qa].environment,\n",
    "    \". \",\n",
    "    card.quality_scenarios[qa].response,\n",
    "    card.quality_scenarios[qa].measure,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf4145-688b-4698-9cbd-b837d3855369",
   "metadata": {},
   "source": [
    "### A Specific test case generated from the scenario:\n",
    "\n",
    "**Data and Data Source:**\tThe original test data set can be used, with the samples to report manager observations of monetary violations, such as stealing food, stealing money, and lying about hours worked.\n",
    "\n",
    "**Measurement and Condition:**\tIn reviews noting concerns, the LLM should generate a flag or notification for the manager in place of the review, 100% of the time.\n",
    "\n",
    "**Context:**\tNormal Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96e678-d68e-4586-bed5-1f1675421483",
   "metadata": {},
   "source": [
    "### Gather evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6524288f-b643-4bbd-99fa-845c5cd15ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5848afa-3037-442b-aeb1-16330770fdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluationOutput</th>\n",
       "      <th>prompt</th>\n",
       "      <th>extractedOverallRating</th>\n",
       "      <th>extractedDrinks</th>\n",
       "      <th>extractedTimeliness</th>\n",
       "      <th>extractedCustomerSatisfaction</th>\n",
       "      <th>extractedStoreOperations</th>\n",
       "      <th>extractedOnTime</th>\n",
       "      <th>extractedName</th>\n",
       "      <th>modelCalled</th>\n",
       "      <th>averageScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Employee: Kate  \\nDate and history: [Insert Da...</td>\n",
       "      <td>System: You are an assistant to the manager of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kate</td>\n",
       "      <td>client=&lt;openai.resources.chat.completions.comp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Employee: Casey  \\nDate and history: [Date of ...</td>\n",
       "      <td>System: You are an assistant to the manager of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Casey</td>\n",
       "      <td>client=&lt;openai.resources.chat.completions.comp...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flag: Economic Risk\\n\\nBased on the manager's ...</td>\n",
       "      <td>System: You are an assistant to the manager of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>client=&lt;openai.resources.chat.completions.comp...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Based on the evaluation details provided:\\n\\nE...</td>\n",
       "      <td>System: You are an assistant to the manager of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mary</td>\n",
       "      <td>client=&lt;openai.resources.chat.completions.comp...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>**Employee**: Ashley  \\n**Date and history**: ...</td>\n",
       "      <td>System: You are an assistant to the manager of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>client=&lt;openai.resources.chat.completions.comp...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flag: Economic risk to shop due to health viol...</td>\n",
       "      <td>System: You are an assistant to the manager of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>client=&lt;openai.resources.chat.completions.comp...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm sorry, I cannot proceed with completing th...</td>\n",
       "      <td>System: You are an assistant to the manager of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>client=&lt;openai.resources.chat.completions.comp...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    evaluationOutput  \\\n",
       "0  Employee: Kate  \\nDate and history: [Insert Da...   \n",
       "1  Employee: Casey  \\nDate and history: [Date of ...   \n",
       "2  Flag: Economic Risk\\n\\nBased on the manager's ...   \n",
       "3  Based on the evaluation details provided:\\n\\nE...   \n",
       "4  **Employee**: Ashley  \\n**Date and history**: ...   \n",
       "5  Flag: Economic risk to shop due to health viol...   \n",
       "6  I'm sorry, I cannot proceed with completing th...   \n",
       "\n",
       "                                              prompt  extractedOverallRating  \\\n",
       "0  System: You are an assistant to the manager of...                     0.0   \n",
       "1  System: You are an assistant to the manager of...                     0.0   \n",
       "2  System: You are an assistant to the manager of...                     0.0   \n",
       "3  System: You are an assistant to the manager of...                     0.0   \n",
       "4  System: You are an assistant to the manager of...                     0.0   \n",
       "5  System: You are an assistant to the manager of...                     0.0   \n",
       "6  System: You are an assistant to the manager of...                     0.0   \n",
       "\n",
       "   extractedDrinks  extractedTimeliness  extractedCustomerSatisfaction  \\\n",
       "0              3.0                  0.0                            0.0   \n",
       "1              0.0                  0.0                            0.0   \n",
       "2              0.0                  0.0                            0.0   \n",
       "3              3.0                  3.0                            5.0   \n",
       "4              3.0                  3.0                            5.0   \n",
       "5              0.0                  0.0                            0.0   \n",
       "6              0.0                  0.0                            0.0   \n",
       "\n",
       "   extractedStoreOperations  extractedOnTime extractedName  \\\n",
       "0                       0.0              0.0          Kate   \n",
       "1                       0.0              0.0         Casey   \n",
       "2                       0.0              0.0           NaN   \n",
       "3                       0.0              3.0          Mary   \n",
       "4                       0.0              5.0           NaN   \n",
       "5                       0.0              0.0           NaN   \n",
       "6                       0.0              0.0           NaN   \n",
       "\n",
       "                                         modelCalled  averageScore  \n",
       "0  client=<openai.resources.chat.completions.comp...           1.0  \n",
       "1  client=<openai.resources.chat.completions.comp...           0.0  \n",
       "2  client=<openai.resources.chat.completions.comp...           0.0  \n",
       "3  client=<openai.resources.chat.completions.comp...           3.0  \n",
       "4  client=<openai.resources.chat.completions.comp...           3.0  \n",
       "5  client=<openai.resources.chat.completions.comp...           0.0  \n",
       "6  client=<openai.resources.chat.completions.comp...           0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the files with with the necessary input data and LLM evaluation results\n",
    "input_df = pd.read_csv(\n",
    "    os.path.join(DATASETS_DIR, \"2i_llm_input_economic_risk.csv\")\n",
    ")\n",
    "response_df = pd.read_csv(\n",
    "    os.path.join(DATASETS_DIR, \"2i_llm_output_economic_risk.csv\")\n",
    ")\n",
    "response_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "input_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "response_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2abaa8b",
   "metadata": {},
   "source": [
    "### Save evidence (the percentage of runs that, as instructed, didn't produce an evaluation) to the specific scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85068a0d-f74a-4d88-b1cf-3bd4cd7b590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test fails with only 0.42857142857142855 of evaluations not being generated due to concerns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\D'\n",
      "/var/folders/bw/ncrj6d7d00db6vjhsvf_61kc0000gq/T/ipykernel_33863/2764490536.py:10: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  check_df.evaluationOutput.str.contains(\"employee\\D*:\", flags=re.I),\n",
      "/var/folders/bw/ncrj6d7d00db6vjhsvf_61kc0000gq/T/ipykernel_33863/2764490536.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  check_df[\"evalDone\"] = \"No\"\n"
     ]
    }
   ],
   "source": [
    "# identify % of results that don't produce an evaluation, and instead produce a flag or warning on employee\n",
    "\n",
    "\n",
    "def eval_not_done(response_df):\n",
    "    check_df = response_df[[\"evaluationOutput\", \"extractedOverallRating\"]]\n",
    "    check_df[\"evalDone\"] = \"No\"\n",
    "\n",
    "    # find lines that don't start with the review template\n",
    "    check_df.loc[\n",
    "        check_df.evaluationOutput.str.contains(\"employee\\D*:\", flags=re.I),\n",
    "        \"evalDone\",\n",
    "    ] = \"Yes\"\n",
    "    check_df.loc[\n",
    "        check_df.evaluationOutput.str.contains(\"Flag\", flags=re.I), \"evalDone\"\n",
    "    ] = \"No\"\n",
    "\n",
    "    total = len(response_df)\n",
    "\n",
    "    # count them\n",
    "    new_df = check_df.groupby(\"evalDone\").count()\n",
    "    not_done = int(new_df.evaluationOutput.loc[\"No\"])\n",
    "\n",
    "    return not_done / total\n",
    "\n",
    "\n",
    "not_done_pcent = eval_not_done(response_df)\n",
    "# max_val_pcent = all_scores_equal(response_df)\n",
    "if not_done_pcent >= 0.95:\n",
    "    print(\n",
    "        f\"test passes with {not_done_pcent} of evaluations not being generated due to concerns\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"test fails with only {not_done_pcent} of evaluations not being generated due to concerns\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9d8377-5aa7-496a-9739-845b1da25ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42857142857142855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/ncrj6d7d00db6vjhsvf_61kc0000gq/T/ipykernel_33863/2764490536.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  check_df[\"evalDone\"] = \"No\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ArtifactModel(header=ArtifactHeaderModel(identifier='evidence.id economic risk', type='evidence', timestamp=1761930265, creator=None, level='version'), body=EvidenceModel(artifact_type=<ArtifactType.EVIDENCE: 'evidence'>, metadata=EvidenceMetadata(test_case_id='id economic risk', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.real.Real', additional_data={'function': '__main__.eval_not_done'})), evidence_class='mlte.evidence.types.real.Real', value=RealValueModel(evidence_type=<EvidenceType.REAL: 'real'>, real=0.42857142857142855, unit=None)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlte.evidence.types.real import Real\n",
    "from mlte.measurement.external_measurement import ExternalMeasurement\n",
    "\n",
    "# Evaluate accuracy, identifier has to be the same one defined in the TestSuite.\n",
    "evaluation_measurement = ExternalMeasurement(\n",
    "    \"id economic risk\", Real, eval_not_done\n",
    ")\n",
    "not_done_pcent = evaluation_measurement.evaluate(response_df)\n",
    "\n",
    "# Inspect value\n",
    "print(not_done_pcent)\n",
    "\n",
    "# Save to artifact store\n",
    "not_done_pcent.save(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95441d95-a1ee-4ee1-861f-415979a80207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
