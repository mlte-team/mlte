{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collect Evidence\n",
    "\n",
    "In the second phase of SDMT, we collect _evidence_ to attest to the fact that the model realized the properties specified in the previous phase.\n",
    "\n",
    "We define and instantiate `Measurement`s to generate this evidence. Each individual piece of evidence is a `Value`. Once `Value`s are produced, we can persist them to an _artifact store_ to maintain our evidence across sessions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# The path at which datasets are stored\n",
    "DATASETS_DIR = Path(os.getcwd()) / \"data\"\n",
    "os.makedirs(DATASETS_DIR, exist_ok=True)\n",
    "\n",
    "# The path at which models are stored\n",
    "MODELS_DIR = Path(os.getcwd()) / \"models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# The path at which media is stored\n",
    "MEDIA_DIR = Path(os.getcwd()) / \"media\"\n",
    "os.makedirs(MEDIA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "def load_data() -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Load machine learning dataset.\n",
    "    :return (X_train, X_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    iris = load_iris(as_frame=True)\n",
    "    X, y = iris.data, iris.target\n",
    "    return train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Train a classifier and save.\"\"\"\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "    with (MODELS_DIR / \"model_demo.pkl\").open(\"wb\") as f:\n",
    "        pickle.dump(clf, f)\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load a trained model.\"\"\"\n",
    "    path = MODELS_DIR / \"model_demo.pkl\"\n",
    "    with path.open(\"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training dataset for use by training procedure\n",
    "X_train, _, y_train, _ = load_data()\n",
    "X_train.to_csv(DATASETS_DIR / \"data.csv\")\n",
    "y_train.to_csv(DATASETS_DIR / \"target.csv\")\n",
    "\n",
    "# Train and save the model.\n",
    "train_model(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.session import set_context, set_store\n",
    "\n",
    "store_path = os.path.join(os.getcwd(), \"store\")\n",
    "os.makedirs(store_path, exist_ok=True)\n",
    "\n",
    "store_path = os.path.join(os.getcwd(), \"store\")\n",
    "os.makedirs(\n",
    "    store_path, exist_ok=True\n",
    ")  # Ensure we are creating the folder if it is not there.\n",
    "\n",
    "set_context(\"IrisClassifier\", \"0.0.1\")\n",
    "set_store(f\"local://{store_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage Cost Measurements\n",
    "\n",
    "This section demonstrates the simplest possible use-case. We import a MLTE-defined `Measurement`, which is then invoked to produce a `Value`. This value can then be inspected and automatically saved to the artifact store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.measurement.storage import LocalObjectSize\n",
    "from mlte.value.types.integer import Integer\n",
    "\n",
    "# Create a measurement\n",
    "store_measurement = LocalObjectSize(\"model size\")\n",
    "# Execute the measurement\n",
    "size: Integer = store_measurement.evaluate(MODELS_DIR / \"model_demo.pkl\")\n",
    "\n",
    "# Inspec values\n",
    "print(size)\n",
    "\n",
    "# Save to artifact store\n",
    "size.save(force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Cost Measurements\n",
    "\n",
    "Evidence in this section is largely the same as that demonstrated in the previous section, except it requires some additional setup from the user's perspective. Again, we utilize MLTE-defined `Measurement`s to produce `Value`s that can then be saved to the artifact store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = Path.cwd() / \"train.py\"\n",
    "args = [\n",
    "    \"--dataset-dir\",\n",
    "    str(DATASETS_DIR.absolute()),\n",
    "    \"--models-dir\",\n",
    "    str(MODELS_DIR.absolute()),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first evidence we collect are CPU utilization statistics for a local training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.measurement import ProcessMeasurement\n",
    "from mlte.measurement.cpu import LocalProcessCPUUtilization, CPUStatistics\n",
    "\n",
    "# Create a measurement\n",
    "cpu_measurement = LocalProcessCPUUtilization(\"training cpu\")\n",
    "# Execute the measurement\n",
    "cpu_stats: CPUStatistics = cpu_measurement.evaluate(\n",
    "    ProcessMeasurement.start_script(script, args)\n",
    ")\n",
    "\n",
    "# Inspect values\n",
    "print(cpu_stats)\n",
    "\n",
    "# Save to artifact store\n",
    "cpu_stats.save(force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform a similar procedure to measure the memory consumption of a local training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.measurement.memory import (\n",
    "    LocalProcessMemoryConsumption,\n",
    "    MemoryStatistics,\n",
    ")\n",
    "\n",
    "# Create a measurement\n",
    "mem_measurement = LocalProcessMemoryConsumption(\"training memory\")\n",
    "# Execute the measurement\n",
    "mem_stats: MemoryStatistics = mem_measurement.evaluate(\n",
    "    ProcessMeasurement.start_script(script, args)\n",
    ")\n",
    "\n",
    "# Inspect values\n",
    "print(mem_stats)\n",
    "\n",
    "# Save to artifact store\n",
    "mem_stats.save(force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also avoid starting the training process twice by using the asynch methods for both measurements. We start the training process once and pass the id to both measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.measurement import ProcessMeasurement\n",
    "from mlte.measurement.cpu import LocalProcessCPUUtilization, CPUStatistics\n",
    "from mlte.measurement.memory import (\n",
    "    LocalProcessMemoryConsumption,\n",
    "    MemoryStatistics,\n",
    ")\n",
    "\n",
    "# Create measurements\n",
    "cpu_measurement = LocalProcessCPUUtilization(\"training cpu\")\n",
    "mem_measurement = LocalProcessMemoryConsumption(\"training memory\")\n",
    "\n",
    "# Start the process to measure.\n",
    "pid = ProcessMeasurement.start_script(script, args)\n",
    "\n",
    "# Execute the measurements\n",
    "cpu_measurement.evaluate_async(pid)\n",
    "mem_measurement.evaluate_async(pid)\n",
    "cpu_stats: CPUStatistics = cpu_measurement.wait_for_output()\n",
    "mem_stats: MemoryStatistics = mem_measurement.wait_for_output()\n",
    "\n",
    "# Inspect values\n",
    "print(cpu_stats)\n",
    "print(mem_stats)\n",
    "\n",
    "# Save to artifact store\n",
    "cpu_stats.save(force=True)\n",
    "mem_stats.save(force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Efficacy Measurements\n",
    "\n",
    "Evidence collected in this section demonstrates MLTE's flexibility in handling inputs from external libraries and in different media types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "_, X_test, _, y_test = load_data()\n",
    "\n",
    "# Load the model\n",
    "model = load_model()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test.to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first example, we simply wrap the output from `accuracy_score` with a builtin MLTE type (`Real`) to integrate it with our growing collection of evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from mlte.value.types.real import Real\n",
    "from mlte.measurement import ExternalMeasurement\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy_measurement = ExternalMeasurement(\"accuracy\", Real, accuracy_score)\n",
    "accuracy = accuracy_measurement.evaluate(y_test, y_pred)\n",
    "\n",
    "# Inspect value\n",
    "print(accuracy)\n",
    "\n",
    "# Save to artifact store\n",
    "accuracy.save(force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next example, we define a custom `Result` type to cope with the output of a third-party library that is not supported by a MLTE builtin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from confusion_matrix import ConfusionMatrix\n",
    "from mlte.measurement import ExternalMeasurement\n",
    "\n",
    "# Generate value\n",
    "matrix_measurement = ExternalMeasurement(\n",
    "    \"confusion matrix\", ConfusionMatrix, confusion_matrix\n",
    ")\n",
    "matrix = matrix_measurement.evaluate(y_test, y_pred)\n",
    "\n",
    "# Inspect\n",
    "print(matrix)\n",
    "\n",
    "# Save to artifact store\n",
    "matrix.save(force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final example, we demonstrate the ability to integrate other forms of media in our evidence collection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlte.measurement import ExternalMeasurement\n",
    "from mlte.value.types.image import Image\n",
    "\n",
    "x = [\"Setosa\", \"Versicolour\", \"Virginica\"]\n",
    "y = [sum(1 for value in y_pred if value == target) for target in [0, 1, 2]]\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.title(\"Distribution of Predicted Classes\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.xticks([0, 1, 2])\n",
    "plt.ylabel(\"Occurrences\")\n",
    "plt.savefig(MEDIA_DIR / \"classes.png\")\n",
    "\n",
    "img_collector = ExternalMeasurement(\"class distribution\", Image)\n",
    "img = img_collector.ingest(MEDIA_DIR / \"classes.png\")\n",
    "\n",
    "img.save(force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82adda432962015d5f71beb9387a99f24d390514e497c776c87ff3434daf7312"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
