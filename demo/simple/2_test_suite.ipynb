{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a TestSuite\n",
    "\n",
    "In the second phase of SDMT, we define a `TestSuite` that represents the tests the completed model must will have to pass in order to be acceptable for use in the system into which it will be integrated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial custom lists at URI: local:///Users/rbrowersinning/Documents/ResearchFolders/Continuum_LTP/GitRepos/mlte/demo/simple/store\n",
      "Loaded 8 qa_categories for initial list\n",
      "Loaded 14 quality_attributes for initial list\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mlte.session import set_context, set_store\n",
    "\n",
    "store_path = os.path.join(os.getcwd(), \"store\")\n",
    "\n",
    "set_context(\"IrisClassifier\", \"0.0.1\")\n",
    "set_store(f\"local://{store_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a `TestSuite`\n",
    "\n",
    "In MLTE, we define the tests that will be required for the different requirements in a `TestSuite`. Note that a new `Evidence` types (`ConfusionMatrix`) was created in this case to simplify the definition the `Validator` for that case.\n",
    "\n",
    "Also note that, for this `TestSuite`, we are defining the (optional) `Measurement` up front. This will allow us to later automate the execution of all the test cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load up our `NegotiationCard`, so we can get the list of ids of its quaity attribute scenarios, that will be added to the `TestCase`s here. Those ids are the way to link the `TestCase`s to their quality attribute requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default.card-qas_001 (Functional Correctness): The model receives a dimensions of an iris flower from the flower identification application while in normal operations, the model returns proper results, with an accuracy of 98%\n",
      "default.card-qas_002 (Functional Correctenss): The model receives measurements of an iris flower from a garden from the flower identification application while in normal operations, the model returns proper results, with misclassification less than 2\n",
      "default.card-qas_003 (Functional Correctness): The model receives easurements of an iris flower from a garden from the flower identification application while in normal operations, the model returns proper results, with a proper distribution\n",
      "default.card-qas_004 (Resource Uilization): The model is being trained from by model developers while in development time, the model is properly trained, and requires less than 3 mb of storage.\n",
      "default.card-qas_005 (Resource Utilization): The model is being trained from by model developers while in development time, the model is properly trained, without using more than 60 mb of memory\n",
      "default.card-qas_006 (Resource Utilization): The model is being trained from by model developers while in development time, the model is properly trained, without using more than 5% of cpu\n"
     ]
    }
   ],
   "source": [
    "from mlte.negotiation.artifact import NegotiationCard\n",
    "\n",
    "card = NegotiationCard.load()\n",
    "card.print_quality_scenarios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to look at the `Quality Attribute Scenarios` or the `Quality Attributes` that are available, we can do that with these listing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Parent: Functional Correctness): \n",
      "Detect Out-of-Distribution (OOD) Inputs (Parent: Monitorability): \n",
      "Detect Shifts in Output (Confidence) Distribution (Parent: Monitorability): \n",
      "Inference Time on Operational Platform (Parent: Performance): \n",
      "Input Validation (Parent: Resilience): \n",
      "Input and Output Specification (Parent: Functional Correctness): \n",
      "Model Impartial to Photo Location (Parent: Fairness): \n",
      "Model Robust to Noise (Channel Loss) (Parent: Robustness): \n",
      "Model Robust to Noise (Image Blur) (Parent: Robustness): \n",
      "Reliability (Parent: Robustness): Reliability\n",
      "Resource Consumption on Operational Platform (Parent: Performance): \n",
      "Resource Usage (Parent: Performance): \n",
      "Security (Parent: Trust): Security\n",
      "Understanding Model Results (Parent: Interpretability): \n"
     ]
    }
   ],
   "source": [
    "from mlte.custom_list.custom_list_names import CustomListName\n",
    "from mlte.session.session import print_custom_list_entries\n",
    "\n",
    "print_custom_list_entries(CustomListName.QUALITY_ATTRIBUTES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our `TestSuite`, consisting of a list of `TestCases`, each of them addressing one or more Quality Attribute Scenarios from our `NegotiationCard`. When defining the `TestCase`s below, we need to set the id of the corresponding Quality Attribute Scenario we want to test in its \"quality_scenarios\" attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from mlte.measurement.external_measurement import ExternalMeasurement\n",
    "from mlte.measurement.units import Units\n",
    "from mlte.tests.test_case import TestCase\n",
    "from mlte.tests.test_suite import TestSuite\n",
    "from mlte.measurement.storage import LocalObjectSize\n",
    "from mlte.measurement.cpu import LocalProcessCPUUtilization\n",
    "from mlte.measurement.memory import LocalProcessMemoryConsumption\n",
    "from mlte.evidence.types.real import Real\n",
    "from mlte.evidence.types.image import Image\n",
    "\n",
    "from demo.simple import measurements\n",
    "from demo.simple.confusion_matrix import ConfusionMatrix\n",
    "\n",
    "spec = TestSuite(\n",
    "    test_cases=[\n",
    "        TestCase(\n",
    "            identifier=\"accuracy\",\n",
    "            goal=\"Understand if the model is useful for this case\",\n",
    "            quality_scenarios=[\"card.default-qas_001\"],\n",
    "            validator=Real.greater_or_equal_to(0.98),\n",
    "            measurement=ExternalMeasurement(\n",
    "                output_evidence_type=Real, function=accuracy_score\n",
    "            ),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"confusion matrix\",\n",
    "            goal=\"Understand if the model is useful for this case\",\n",
    "            quality_scenarios=[\"card.default-qas_002\"],\n",
    "            validator=ConfusionMatrix.misclassification_count_less_than(2),\n",
    "            measurement=ExternalMeasurement(\n",
    "                output_evidence_type=ConfusionMatrix, function=confusion_matrix\n",
    "            ),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"class distribution\",\n",
    "            goal=\"Understand if the model is useful for this case\",\n",
    "            quality_scenarios=[\"card.default-qas_003\"],\n",
    "            validator=Image.register_info(\n",
    "                \"Visual inspection is required to confirm that distribution is above 1.2%.\"\n",
    "            ),\n",
    "            measurement=ExternalMeasurement(\n",
    "                output_evidence_type=Image, function=measurements.create_image\n",
    "            ),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"model size\",\n",
    "            goal=\"Check resource consumption\",\n",
    "            quality_scenarios=[\"card.default-qas_004\"],\n",
    "            validator=LocalObjectSize.get_output_type().less_than(\n",
    "                3.0, Units.megabyte\n",
    "            ),\n",
    "            measurement=LocalObjectSize(),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"training memory\",\n",
    "            goal=\"Check resource consumption\",\n",
    "            quality_scenarios=[\"card.default-qas_005\"],\n",
    "            validator=LocalProcessMemoryConsumption.get_output_type().average_consumption_less_than(\n",
    "                60, unit=Units.megabyte\n",
    "            ),\n",
    "            measurement=LocalProcessMemoryConsumption(),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"training cpu\",\n",
    "            goal=\"Check resource consumption\",\n",
    "            quality_scenarios=[\"card.default-qas_006\"],\n",
    "            validator=LocalProcessCPUUtilization.get_output_type().max_utilization_less_than(\n",
    "                5.0, unit=Units.percent\n",
    "            ),\n",
    "            measurement=LocalProcessCPUUtilization(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "spec.save(parents=True, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
