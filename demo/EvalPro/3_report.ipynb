{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation and Report Generation\n",
    "\n",
    "The final phase of SDMT involves aggregating evidence, validating the metrics reflected by the evidence we collected, and displaying this information in a report."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from session import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Evidence and get an updated `TestResults` with `Result`s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `TestSuite` ready and we have enough evidence, we create a `TestSuiteValidator` with our TestSuite, and add all the `Evidence`s we have. With that we can validate our tests and generate an output `TestResults`, with the validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.validation.test_suite_validator import TestSuiteValidator\n",
    "\n",
    "# Load validator for default TestSuite id\n",
    "test_suite_validator = TestSuiteValidator()\n",
    "\n",
    "# Load all Evidence and validate TestCases\n",
    "test_results = test_suite_validator.load_and_validate()\n",
    "\n",
    "# We want to see the validation results in the Notebook, regardless of them being saved.\n",
    "test_results.print_results()\n",
    "\n",
    "# TestResults also supports persistence\n",
    "test_results.save(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see some of the results of the validation.\n",
    "\n",
    "For example, there is a significant difference between original model with no blur and blur 0x8. So we see a drop in model accuracy with increasing blur. But aside from max blur (0x8), the model accuracy fall off isn't bad.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a Report\n",
    "\n",
    "The final step of SDMT involves the generation of a report to communicate the results of model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.report.artifact import (\n",
    "    Report,\n",
    "    CommentDescriptor,\n",
    ")\n",
    "\n",
    "# Create a report with the default NegotiationCard, TestSuite and TestResults in this store.\n",
    "report = Report(\n",
    "    comments=[\n",
    "        CommentDescriptor(\n",
    "            content=\"This model should not be used for nefarious purposes.\"\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "report.save(force=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
