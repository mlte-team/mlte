{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2j. Evidence - Time Behavior QAS Measurements\n",
    "\n",
    "Measure time required to run model and execute inferences.\n",
    "\n",
    "The cell below must contain JSON data about this evidence that will be used to automatically populate the sample test catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"tags\": [\"Computer Vision\", \"Object Detection\"],\n",
    "    \"quality_attribute\": \"Time Behavior\",\n",
    "    \"description\": \"Checks the time required of the ML model to produce an inference from a given input\",\n",
    "    \"inputs\": \"A flower image from the garden\",\n",
    "    \"output\": \"Time required for the model to produce an inference (s)\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from session import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up scenario test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.negotiation.artifact import NegotiationCard\n",
    "\n",
    "card = NegotiationCard.load()\n",
    "qa = 10\n",
    "print(card.quality_scenarios[qa])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Specific test case generated from the scenario:**\n",
    "\n",
    "**Data and Data Source:**\tThe original test dataset can be used.\n",
    "\n",
    "**Measurement and Condition:**\tTimestamps are generated for all inferences and verified to be less than or equal to two seconds.\n",
    "\n",
    "**Context:**\tNormal Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Set up functions to time the model run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import utils.model_predict as model_predict\n",
    "from mlte.measurement.units import Units\n",
    "\n",
    "\n",
    "def time_model():\n",
    "    \"\"\"Returns total time, and average time per inference.\"\"\"\n",
    "    start = time.time()\n",
    "    avg_time, _, _ = model_predict.run_model(\n",
    "        SAMPLE_DATASET_DIR, MODEL_FILE_PATH\n",
    "    )\n",
    "    end = time.time()\n",
    "    total = end - start\n",
    "    return total, Units.second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurements\n",
    "\n",
    "Finally, we execute the measurements and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.measurement.external_measurement import ExternalMeasurement\n",
    "from mlte.evidence.types.real import Real\n",
    "\n",
    "# Evaluate, identifier has to be the same one defined in the Spec.\n",
    "measurement = ExternalMeasurement(\"predicting cpu time\", Real, time_model)\n",
    "result = measurement.evaluate()\n",
    "\n",
    "# Inspect value\n",
    "print(result)\n",
    "\n",
    "# Save to artifact store\n",
    "result.save(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
