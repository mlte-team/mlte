{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d. Evidence - Resource Utilization QAS Measurements\n",
    "\n",
    "Now we collect stored, CPU and memory usage data when predicting with the model, for the Performance scenario.\n",
    "\n",
    "The cell below must contain JSON data about this evidence that will be used to automatically populate the sample test catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"tags\": [\"Computer Vision\", \"Image\"],\n",
    "    \"quality_attribute\": \"Resource Utilization\",\n",
    "    \"description\": \"Evaluating model anility to run adequately on deployment platform\",\n",
    "    \"inputs\": \"Model\",\n",
    "    \"output\": \"Memory usuage, CPU usuage and disk space\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from session import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up scenario test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.negotiation.artifact import NegotiationCard\n",
    "\n",
    "card = NegotiationCard.load()\n",
    "qa = 3\n",
    "print(card.quality_scenarios[qa])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Specific test case generated from the scenario:**\n",
    "\n",
    "**Data and Data Source:**\tThe original test dataset can be used (i.e., original test data set aside for testing during data split into training, validation, and test).\n",
    "\n",
    "**Measurement and Condition:**\t    \n",
    "    1- Executing the model on the loaned platform will not exceed maximum CPU usage of 30% to ensure reasonable response time. CPU usage will be measure using ps.\n",
    "    2- Memory usage at inference time will not exceed available memory of 512 MB. This will be measured using pmap.\n",
    "    3- Disk usage will not exceed allocated disk space of 150 MB bytes. This will be measured by adding the size of each file in the path for the model code.\n",
    "\n",
    "**Context:**\tNormal Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurements\n",
    "\n",
    "Prepare and execute measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.measurement.storage import LocalObjectSize\n",
    "from mlte.evidence.types.real import Real\n",
    "from mlte.measurement.units import Units\n",
    "\n",
    "store_measurement = LocalObjectSize(\"model size\")\n",
    "size: Real = store_measurement.evaluate(MODELS_DIR, unit=Units.byte)\n",
    "print(size)\n",
    "size.save(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.measurement.process_measurement import ProcessMeasurement\n",
    "from mlte.measurement.cpu import LocalProcessCPUUtilization, CPUStatistics\n",
    "\n",
    "cpu_measurement = LocalProcessCPUUtilization(\"predicting cpu\")\n",
    "cpu_stats: CPUStatistics = cpu_measurement.evaluate(MODEL_COMMAND)\n",
    "print(cpu_stats)\n",
    "cpu_stats.save(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.measurement.memory import (\n",
    "    LocalProcessMemoryUtilization,\n",
    "    MemoryStatistics,\n",
    ")\n",
    "\n",
    "mem_measurement = LocalProcessMemoryUtilization(\"predicting memory\")\n",
    "mem_stats: MemoryStatistics = mem_measurement.evaluate(MODEL_COMMAND)\n",
    "print(mem_stats)\n",
    "mem_stats.save(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also avoid starting the training process twice by using the asynch methods for both measurements. We start the training process once and pass the id to both measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.measurement.cpu import LocalProcessCPUUtilization\n",
    "from mlte.measurement.memory import LocalProcessMemoryUtilization\n",
    "from mlte.measurement.process_measurement_group import ProcessMeasurementGroup\n",
    "\n",
    "# Create measurement group\n",
    "measurements = ProcessMeasurementGroup()\n",
    "\n",
    "# Add measurements to group.\n",
    "measurements.add(LocalProcessCPUUtilization(\"predicting cpu\"))\n",
    "measurements.add(LocalProcessMemoryUtilization(\"predicting memory\"))\n",
    "\n",
    "# Evaluate the measurements.\n",
    "evidences = measurements.evaluate(command=MODEL_COMMAND)\n",
    "\n",
    "# Get results.\n",
    "cpu_stats = evidences[\"predicting cpu\"]\n",
    "mem_stats = evidences[\"predicting memory\"]\n",
    "\n",
    "# Inspect values\n",
    "print(cpu_stats)\n",
    "print(mem_stats)\n",
    "\n",
    "# Save to artifact store\n",
    "cpu_stats.save(force=True)\n",
    "mem_stats.save(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
