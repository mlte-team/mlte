{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d54e5b-a922-4cbf-bbdd-c9dfd09d4203",
   "metadata": {},
   "source": [
    "## 3a. Automatic Validation\n",
    "Evidence collected in this section checks for theTest Repeatability scenario defined in the previous step. Note that some functions will be loaded from external Python files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f67ba90-471d-494c-bae0-3796371ccfd9",
   "metadata": {},
   "source": [
    "Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active session. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3e6b003-2c97-4db1-87ed-5beb57ff2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from demo.scenarios.session import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d50bf4cd-f9c5-4a5e-8bff-d4e3879aa0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Test Case: accuracy across gardens, result: Success, details: All accuracies are equal to or over threshold 0.9 - values: [\"[0.946, 0.956, 0.913]\"]\n",
      " > Test Case: ranksums blur2x8, result: Success, details: P-Value is greater or equal to 0.016666666666666666 - values: [\"[0.07946178703316073, 0.9366653249981838]\"]\n",
      " > Test Case: ranksums blur5x8, result: Success, details: P-Value is greater or equal to 0.016666666666666666 - values: [\"[0.4032389192727559, 0.6867724711187835]\"]\n",
      " > Test Case: ranksums blur0x8, result: Failure, details: P-Value is less than threshold 0.016666666666666666 - values: [\"[2.908064206049404, 0.003636736621916332]\"]\n",
      " > Test Case: effect of blur across families, result: Success, details: All p-values are equal to or over threshold 0.0003546099290780142 - values: [\"{'array': [{'evidence.ranksums Order Apiales-Apiales blurdelta_2x8': [0.0, 1.0]}, {'evidence.ranksums Order Apiales-Alismatales blurdelta_2x8': [0.0, 1.0]}, {'evidence.ranksums Order Apiales-Asterales blurdelta_2x8': [-0.1091089451179962, 0.9131160800723744]}, {'evidence.ranksums Order Apiales-Erica...\"]\n",
      " > Test Case: ranksums channel loss R, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[0.8052918417241214, 0.4206512885130542]\"]\n",
      " > Test Case: ranksums channel loss G, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[0.6356942962652858, 0.5249756947411197]\"]\n",
      " > Test Case: ranksums channel loss B, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[0.7673399434396266, 0.44287942555285786]\"]\n",
      " > Test Case: model size, result: Success, details: Real magnitude is less than threshold 150 megabyte - values: [\"13.0 byte\"]\n",
      " > Test Case: predicting memory, result: Success, details: Average consumption below threshold 512.0 megabyte - values: [\"Average: 251292 kilobyte\\nMinimum: 32 kilobyte\\nMaximum: 437792 kilobyte\"]\n",
      " > Test Case: predicting cpu, result: Success, details: Maximum utilization below threshold 30.00 percent - values: [\"Average: 1.83 percent\\nMinimum: 0.00 percent\\nMaximum: 5.40 percent\"]\n",
      " > Test Case: overall model accuracy, result: Success, details: Real magnitude is greater than threshold 0.9 - values: [\"0.947265625\"]\n",
      " > Test Case: repeated results sampling, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[38.903978816768415, 0.8487546281441082]\"]\n",
      " > Test Case: repeated training on training samples, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[1.3575418994429564, 0.9980720828075595]\"]\n",
      " > Test Case: running in new domain, result: Failure, details: One or more p-values are below threshold 0.05 - values: [\"{'array': [{'evidence.label 0': [35.98058233033483, 7.269476178488252e-06]}, {'evidence.label 1': [1.2823981355178078, 0.2715430886274718]}, {'evidence.label 2': [4.059687454037485, 0.05829167989491706]}, {'evidence.label 3': [0.000382861952999998, 0.9845827951232068]}, {'evidence.label 4': [26.6332...\"]\n",
      " > Test Case: test results from dev and op env, result: Info, details: Inspect the alignment of results for no more than 0.25% difference.\n",
      " > Test Case: understanding design choices, result: Info, details: Inspect projrct code and documentation.\n",
      " > Test Case: keep ML component up to date, result: Info, details: Validate work time less than 8hrs.\n",
      " > Test Case: update data pipelines, result: Info, details: Validate work time less than 4hrs.\n",
      " > Test Case: update ML training algorithm, result: Info, details: Validate train time less than 16hrs.\n",
      " > Test Case: retrain ML model, result: Info, details: Model takes less than 1 hr to retrain.\n",
      " > Test Case: reuse ML component, result: Info, details: Validate work time less than 4hrs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ArtifactModel(header=ArtifactHeaderModel(identifier='results.default', type='results', timestamp=1759248187, creator=None, level='version'), body=TestResultsModel(artifact_type=<ArtifactType.TEST_RESULTS: 'results'>, test_suite_id='suite.default', test_suite=TestSuiteModel(artifact_type=<ArtifactType.TEST_SUITE: 'suite'>, test_cases=[TestCaseModel(identifier='accuracy across gardens', goal='Check if model performs well accross different populations', qas_list=['default.card-qas_001'], measurement=None, validator=ValidatorModel(bool_exp='gASVfgMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgWARj/EAIo/pRLAUsASwBLAUsESxNDbJUBlwB0AQAAAAAAAAAAiAFmAWQBhAh8AGoCAAAAAAAAAAAAAAAAAAAAAAAARACrAAAAAAAAAKsBAAAAAAAAdAUAAAAAAAAAAHwAagIAAAAAAAAAAAAAAAAAAAAAAACrAQAAAAAAAGsoAABTAJROaAQoQwIKAZRLAUsASwBLAksDSzNDKJUBSwABAJcAfABdCQAAfQF8AYkCa1wAAJYBlwEBAIwLBAB5AK0DdwGUToWUKYwCLjCUjAFnlIaUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCTxnZW5leHByPpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6USxJDGfjoAPiAAPAAAjoG2SArmDGIAYhZjQ6hC/mUQwSDDxIBlIwJdGhyZXNob2xklIWUKXSUUpSGlIwDc3VtlIwFYXJyYXmUjANsZW6Uh5SMBXZhbHVllIWUaA2MCDxsYW1iZGE+lIwzYWxsX2FjY3VyYWNpZXNfbW9yZV9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsSQyz4gAC0Y/MAAjoG2CAlpwuiC/MDAjoG8wACNwbkCQyIVY9biVvTCRnyBQI3GpRDAJRoEoWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaB51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaDGMB3NldGF0dHKUk5SHlFKUaCeMDWNlbGxfY29udGVudHOURz/szMzMzMzNh5RSMC4=', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.9', failure='One or more accuracies are below threshold 0.9', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.9'])), TestCaseModel(identifier='ranksums blur2x8', goal='Check blur and noise for 2x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur5x8', goal='Check blur and noise for 5x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur0x8', goal='Check blur and noise for 0x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='effect of blur across families', goal='Check consistency in families', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/Nz1eDFiZ94eUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.0003546099290780142'], success='All p-values are equal to or over threshold 0.0003546099290780142', failure='One or more p-values are below threshold 0.0003546099290780142', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.0003546099290780142'])), TestCaseModel(identifier='ranksums channel loss R', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss G', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss B', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='model size', goal='Check storage consumption', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASV5wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrAgAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwgUmVhbC5sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US21DFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEuWjAlwaW50LnV0aWyUjA5Vbml0c0NvbnRhaW5lcpSTlCmBlGgzjAV1ZGljdJSTlCmBlIwIbWVnYWJ5dGWUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda real: (real.get_value_w_units() < threshold_w_unit)', thresholds=[], success='Real magnitude is less than threshold 150 megabyte', failure='Real magnitude exceeds threshold 150 megabyte', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='less_than', creator_args=['150', 'megabyte'])), TestCaseModel(identifier='predicting memory', goal='Check memory used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVNAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDYXZnlIWUjAVzdGF0c5SFlIyHL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvbWVtb3J5L2xvY2FsX3Byb2Nlc3NfbWVtb3J5X2NvbnN1bXB0aW9uLnB5lIwIPGxhbWJkYT6UjEBNZW1vcnlTdGF0aXN0aWNzLmF2ZXJhZ2VfY29uc3VtcHRpb25fbGVzc190aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEuMQw/4gACYJZ8pmSnQJjbSGjaUaAWMEHRocmVzaG9sZF93X3VuaXSUhZQpdJRSlGNtbHRlLm1lYXN1cmVtZW50Lm1lbW9yeS5sb2NhbF9wcm9jZXNzX21lbW9yeV9jb25zdW1wdGlvbgpfX2RpY3RfXwpoDU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaA51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaCGMB3NldGF0dHKUk5SHlFKUaBeMDWNlbGxfY29udGVudHOUjARwaW50lIwSX3VucGlja2xlX3F1YW50aXR5lJOUjBpwaW50LmZhY2V0cy5wbGFpbi5xdWFudGl0eZSMDVBsYWluUXVhbnRpdHmUk5RHQIAAAAAAAACMCXBpbnQudXRpbJSMDlVuaXRzQ29udGFpbmVylJOUKYGUaDOMBXVkaWN0lJOUKYGUjAhtZWdhYnl0ZZRLAXNLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda stats: (stats.avg < threshold_w_unit)', thresholds=['512.0 megabyte'], success='Average consumption below threshold 512.0 megabyte', failure='Average consumption exceeds threshold 512.0 megabyte', info=None, input_types=['mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics'], creator_entity='mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics', creator_function='average_consumption_less_than', creator_args=['512.0', 'megabyte'])), TestCaseModel(identifier='predicting cpu', goal='Check cpu % used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVIAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDbWF4lIWUjAVzdGF0c5SFlIyBL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvY3B1L2xvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uLnB5lIwIPGxhbWJkYT6UjDlDUFVTdGF0aXN0aWNzLm1heF91dGlsaXphdGlvbl9sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US3dDD/iAAJglnymZKdAmNtIaNpRoBYwQdGhyZXNob2xkX3dfdW5pdJSFlCl0lFKUY21sdGUubWVhc3VyZW1lbnQuY3B1LmxvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEdAPgAAAAAAAIwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZSMB3BlcmNlbnSUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda stats: (stats.max < threshold_w_unit)', thresholds=['30.0 percent'], success='Maximum utilization below threshold 30.00 percent', failure='Maximum utilization exceeds threshold 30.00 percent', info=None, input_types=['mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics'], creator_entity='mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics', creator_function='max_utilization_less_than', creator_args=['30.0', 'percent'])), TestCaseModel(identifier='overall model accuracy', goal='Measure the overall accuracy of your end to end pipeline', qas_list=['default.card-qas_006'], measurement=None, validator=ValidatorModel(bool_exp='gASV4wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrRAAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwjUmVhbC5ncmVhdGVyX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US5tDFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEc/7MzMzMzMzYwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZRLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda real: (real.get_value_w_units() > threshold_w_unit)', thresholds=[], success='Real magnitude is greater than threshold 0.9', failure='Real magnitude is below threshold 0.9', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='greater_than', creator_args=['0.9', 'None'])), TestCaseModel(identifier='repeated results sampling', goal='Repeatedly sampling results gives same results', qas_list=['default.card-qas_012'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='repeated training on training samples', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_013'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='running in new domain', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_014'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/qZmZmZmZmoeUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.05'], success='All p-values are equal to or over threshold 0.05', failure='One or more p-values are below threshold 0.05', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.05'])), TestCaseModel(identifier='test results from dev and op env', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_015'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect the alignment of results for no more than 0.25% difference.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect the alignment of results for no more than 0.25% difference.'])), TestCaseModel(identifier='understanding design choices', goal='understanding design and implementation choices', qas_list=['default.card-qas_016'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect projrct code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect projrct code and documentation.'])), TestCaseModel(identifier='keep ML component up to date', goal='keep trained ML component up to date with op environment changes', qas_list=['default.card-qas_017'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 8hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 8hrs.'])), TestCaseModel(identifier='update data pipelines', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_018'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.'])), TestCaseModel(identifier='update ML training algorithm', goal='update ML component training algorithm', qas_list=['default.card-qas_019'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate train time less than 16hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate train time less than 16hrs.'])), TestCaseModel(identifier='retrain ML model', goal='update ML component training algorithm', qas_list=['default.card-qas_020'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Model takes less than 1 hr to retrain.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Model takes less than 1 hr to retrain.'])), TestCaseModel(identifier='reuse ML component', goal='reuse ML component in new app', qas_list=['default.card-qas_021'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.']))]), results={'accuracy across gardens': ResultModel(type='Success', message='All accuracies are equal to or over threshold 0.9 - values: [\"[0.946, 0.956, 0.913]\"]', evidence_metadata=EvidenceMetadata(test_case_id='accuracy across gardens', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.calculate_model_performance_acc'}))), 'ranksums blur2x8': ResultModel(type='Success', message='P-Value is greater or equal to 0.016666666666666666 - values: [\"[0.07946178703316073, 0.9366653249981838]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums blur2x8', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'ranksums blur5x8': ResultModel(type='Success', message='P-Value is greater or equal to 0.016666666666666666 - values: [\"[0.4032389192727559, 0.6867724711187835]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums blur5x8', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'ranksums blur0x8': ResultModel(type='Failure', message='P-Value is less than threshold 0.016666666666666666 - values: [\"[2.908064206049404, 0.003636736621916332]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums blur0x8', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'effect of blur across families': ResultModel(type='Success', message='All p-values are equal to or over threshold 0.0003546099290780142 - values: [\"{\\'array\\': [{\\'evidence.ranksums Order Apiales-Apiales blurdelta_2x8\\': [0.0, 1.0]}, {\\'evidence.ranksums Order Apiales-Alismatales blurdelta_2x8\\': [0.0, 1.0]}, {\\'evidence.ranksums Order Apiales-Asterales blurdelta_2x8\\': [-0.1091089451179962, 0.9131160800723744]}, {\\'evidence.ranksums Order Apiales-Erica...\"]', evidence_metadata=EvidenceMetadata(test_case_id='effect of blur across families', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', additional_data={'function': '__main__.calculate_multiple_ranksums'}))), 'ranksums channel loss R': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[0.8052918417241214, 0.4206512885130542]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums channel loss R', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'ranksums channel loss G': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[0.6356942962652858, 0.5249756947411197]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums channel loss G', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'ranksums channel loss B': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[0.7673399434396266, 0.44287942555285786]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums channel loss B', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'model size': ResultModel(type='Success', message='Real magnitude is less than threshold 150 megabyte - values: [\"13.0 byte\"]', evidence_metadata=EvidenceMetadata(test_case_id='model size', measurement=MeasurementMetadata(measurement_class='mlte.measurement.storage.local_object_size.LocalObjectSize', output_class='mlte.evidence.types.real.Real', additional_data={}))), 'predicting memory': ResultModel(type='Success', message='Average consumption below threshold 512.0 megabyte - values: [\"Average: 251292 kilobyte\\\\nMinimum: 32 kilobyte\\\\nMaximum: 437792 kilobyte\"]', evidence_metadata=EvidenceMetadata(test_case_id='predicting memory', measurement=MeasurementMetadata(measurement_class='mlte.measurement.memory.local_process_memory_consumption.LocalProcessMemoryConsumption', output_class='mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics', additional_data={}))), 'predicting cpu': ResultModel(type='Success', message='Maximum utilization below threshold 30.00 percent - values: [\"Average: 1.83 percent\\\\nMinimum: 0.00 percent\\\\nMaximum: 5.40 percent\"]', evidence_metadata=EvidenceMetadata(test_case_id='predicting cpu', measurement=MeasurementMetadata(measurement_class='mlte.measurement.cpu.local_process_cpu_utilization.LocalProcessCPUUtilization', output_class='mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics', additional_data={}))), 'overall model accuracy': ResultModel(type='Success', message='Real magnitude is greater than threshold 0.9 - values: [\"0.947265625\"]', evidence_metadata=EvidenceMetadata(test_case_id='overall model accuracy', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.real.Real', additional_data={'function': '__main__.calculate_model_performance_basic_acc'}))), 'repeated results sampling': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[38.903978816768415, 0.8487546281441082]\"]', evidence_metadata=EvidenceMetadata(test_case_id='repeated results sampling', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.kruskal'}))), 'repeated training on training samples': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[1.3575418994429564, 0.9980720828075595]\"]', evidence_metadata=EvidenceMetadata(test_case_id='repeated training on training samples', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.friedmanchisquare'}))), 'running in new domain': ResultModel(type='Failure', message='One or more p-values are below threshold 0.05 - values: [\"{\\'array\\': [{\\'evidence.label 0\\': [35.98058233033483, 7.269476178488252e-06]}, {\\'evidence.label 1\\': [1.2823981355178078, 0.2715430886274718]}, {\\'evidence.label 2\\': [4.059687454037485, 0.05829167989491706]}, {\\'evidence.label 3\\': [0.000382861952999998, 0.9845827951232068]}, {\\'evidence.label 4\\': [26.6332...\"]', evidence_metadata=EvidenceMetadata(test_case_id='running in new domain', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', additional_data={'function': '__main__.calculate_multiple_anova'}))), 'test results from dev and op env': ResultModel(type='Info', message='Inspect the alignment of results for no more than 0.25% difference.', evidence_metadata=None), 'understanding design choices': ResultModel(type='Info', message='Inspect projrct code and documentation.', evidence_metadata=None), 'keep ML component up to date': ResultModel(type='Info', message='Validate work time less than 8hrs.', evidence_metadata=None), 'update data pipelines': ResultModel(type='Info', message='Validate work time less than 4hrs.', evidence_metadata=None), 'update ML training algorithm': ResultModel(type='Info', message='Validate train time less than 16hrs.', evidence_metadata=None), 'retrain ML model': ResultModel(type='Info', message='Model takes less than 1 hr to retrain.', evidence_metadata=None), 'reuse ML component': ResultModel(type='Info', message='Validate work time less than 4hrs.', evidence_metadata=None)}))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlte.validation.test_suite_validator import TestSuiteValidator\n",
    "\n",
    "# Load validator for default TestSuite id\n",
    "test_suite_validator = TestSuiteValidator()\n",
    "\n",
    "# Load all Evidence and validate TestCases\n",
    "test_results = test_suite_validator.load_and_validate()\n",
    "\n",
    "# We want to see the validation results in the Notebook, regardless of them being saved.\n",
    "test_results.print_results()\n",
    "\n",
    "# TestResults also supports persistence\n",
    "test_results.save(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd941a2-1bac-4e5d-b275-b11ff07a3413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
