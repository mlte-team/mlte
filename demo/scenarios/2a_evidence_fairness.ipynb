{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Evidence - Fairnesss QAS Measurements\n",
    "\n",
    "Evidence collected in this section checks for the Fairness scenario defined in the previous step. Note that some functions will be loaded from external Python files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlte.session import set_context, set_store\n",
    "\n",
    "store_path = os.path.join(os.getcwd(), \"store\")\n",
    "os.makedirs(\n",
    "    store_path, exist_ok=True\n",
    ")  # Ensure we are creating the folder if it is not there.\n",
    "\n",
    "set_context(\"OxfordFlower\", \"0.0.1\")\n",
    "set_store(f\"local://{store_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define different folders that will be used as input or output for the data gathering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# The path at which datasets are stored\n",
    "DATASETS_DIR = Path.cwd() / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General functions and external imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General functions.\n",
    "\n",
    "import garden\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data(data_folder: str):\n",
    "    \"\"\"Loads all garden data results and taxonomy categories.\"\"\"\n",
    "    df_results = garden.load_base_results(data_folder)\n",
    "    df_results.head()\n",
    "\n",
    "    # Load the taxonomic data and merge with results.\n",
    "    df_info = garden.load_taxonomy(data_folder)\n",
    "    df_results.rename(columns={\"label\": \"Label\"}, inplace=True)\n",
    "    df_all = garden.merge_taxonomy_with_results(df_results, df_info)\n",
    "\n",
    "    return df_info, df_all\n",
    "\n",
    "\n",
    "def split_data(df_info, df_all):\n",
    "    \"\"\"Splits the data into 3 different populations to evaluate them.\"\"\"\n",
    "    df_gardenpop = df_info.copy()\n",
    "    df_gardenpop[\"Population1\"] = (\n",
    "        np.around(\n",
    "            np.random.dirichlet(np.ones(df_gardenpop.shape[0]), size=1)[0],\n",
    "            decimals=3,\n",
    "        )\n",
    "        * 1000\n",
    "    ).astype(int)\n",
    "    df_gardenpop[\"Population2\"] = (\n",
    "        np.around(\n",
    "            np.random.dirichlet(np.ones(df_gardenpop.shape[0]), size=1)[0],\n",
    "            decimals=3,\n",
    "        )\n",
    "        * 1000\n",
    "    ).astype(int)\n",
    "    df_gardenpop[\"Population3\"] = (\n",
    "        np.around(\n",
    "            np.random.dirichlet(np.ones(df_gardenpop.shape[0]), size=1)[0],\n",
    "            decimals=3,\n",
    "        )\n",
    "        * 1000\n",
    "    ).astype(int)\n",
    "    df_gardenpop\n",
    "\n",
    "    # build populations from test data set that match the garden compositions\n",
    "    from random import choices\n",
    "\n",
    "    # build 3 gardens with populations of 1000.\n",
    "    pop_names = [\"Population1\", \"Population2\", \"Population3\"]\n",
    "    gardenpops = np.zeros((3, 1000), int)\n",
    "    gardenmems = np.zeros((3, 1000), int)\n",
    "\n",
    "    for j in range(1000):\n",
    "        for i in range(len(df_gardenpop)):\n",
    "            my_flower = df_gardenpop.iloc[i][\"Common Name\"]\n",
    "\n",
    "            for g in range(3):\n",
    "                n_choices = df_gardenpop.iloc[i][pop_names[g]]\n",
    "                my_choices = df_all[df_all[\"Common Name\"] == my_flower][\n",
    "                    \"model correct\"\n",
    "                ].to_list()\n",
    "                my_selection = choices(my_choices, k=n_choices)\n",
    "\n",
    "                gardenpops[g][j] += sum(my_selection)\n",
    "                gardenmems[g][j] += len(my_selection)\n",
    "\n",
    "    gardenpops\n",
    "\n",
    "    return gardenpops, gardenmems\n",
    "\n",
    "\n",
    "def calculate_model_performance_acc(gardenpops, gardenmems):\n",
    "    \"\"\"Get accucray of models across the garden populations\"\"\"\n",
    "    gardenacc = np.zeros((3, 1000), float)\n",
    "    for i in range(1000):\n",
    "        for g in range(3):\n",
    "            gardenacc[g][i] = gardenpops[g][i] / gardenmems[g][i]\n",
    "    gardenacc\n",
    "\n",
    "    model_performance_acc = []\n",
    "    for g in range(3):\n",
    "        avg = round(np.average(gardenacc[g][:]), 3)\n",
    "        std = round(np.std(gardenacc[g][:]), 3)\n",
    "        min = round(np.amin(gardenacc[g][:]), 3)\n",
    "        max = round(np.amax(gardenacc[g][:]), 3)\n",
    "        model_performance_acc.append(round(avg, 3))\n",
    "\n",
    "        print(\"%1d %1.3f %1.3f %1.3f %1.3f\" % (g, avg, std, min, max))\n",
    "\n",
    "    return model_performance_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data. For this section, instead of executing the model, we will use CSV files containing the results of an already executed run of the model.\n",
    "data = load_data(DATASETS_DIR)\n",
    "split_data = split_data(data[0], data[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first example, we simply wrap the output from `accuracy_score` with a custom `Result` type to cope with the output of a third-party library that is not supported by a MLTE builtin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from values.multiple_accuracy import MultipleAccuracy\n",
    "from mlte.measurement.external_measurement import ExternalMeasurement\n",
    "\n",
    "# Evaluate accuracy, identifier has to be the same one defined in the Spec.\n",
    "accuracy_measurement = ExternalMeasurement(\n",
    "    \"accuracy across gardens\", MultipleAccuracy, calculate_model_performance_acc\n",
    ")\n",
    "accuracy = accuracy_measurement.evaluate(split_data[0], split_data[1])\n",
    "\n",
    "# Inspect value\n",
    "print(accuracy)\n",
    "\n",
    "# Save to artifact store\n",
    "accuracy.save(force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
