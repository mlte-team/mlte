{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAS Demo\n",
    "\n",
    "This is a set of demo notebooks to illustrate the use of the MLTE library and SDMT process, using Quality Attribute Scenarios as guidance for the required Properties and Conditions.\n",
    "\n",
    "NOTE: this demo has an additional set of requirements than MLTE. You can install them with the command: \n",
    "\n",
    "`poetry install --with demo`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0. Quality Attribute Scenarios\n",
    "\n",
    "The following are the QASs that we want to validate through the use of MLTE. The examples below relate to a hypothetical system used by visitors to a botanical garden to identify flowers in the different gardens and learn more about them. The system used an ML model that was trained on the flower category dataset [Nilsback 2008] (https://www.robots.ox.ac.uk/~vgg/data/flowers/102/). \n",
    "\n",
    "* **Fairness - Model Impartial to Photo Location**\n",
    "The Garden Buddy application receives a picture taken at the garden and, regardless of the garden location, can correctly identify the correct flowers at least 90% of the time. Test data needs to include pictures of the flowers from the different gardens, grouped by the garden that the image was taken at. The quantity of the flower images should be representative of the garden population they are taken from. The total accuracy of the model across each garden population should be higher or equal to 0.9.\n",
    "    \n",
    "* **Robustness- Model Robust to Noise (Image Blur)**\n",
    "The Garden Buddy application receives a picture taken at a garden by a member of the general public, and it is a bit blurry.  The model should still be able to successfully identify the flower at the same rate as non-blurry images. Test data needs to include blurred flower images.  Blurred images will be created using ImageMagick. Three datasets will be generated, each with different amounts of blur: minimal blur, maximum blur, and in between minimal and maximum blur. Blurry images are successfully identified at rates equal to that of non-blurred images. This will be measured using the Wilcoxon Rank-Sum test, with significance at p-value <=0.05.\n",
    "    \n",
    "* **Resilience - Model Resilient to Hardware Sensor Failure (Channel Loss)**\n",
    "The Garden Buddy application receives a picture taken at a garden using a loaned device. These devices are known to sometimes lose a channel (i.e., RGB channel). The model should still be able to successfully identify the flower at the same rate as full images. Test data needs to include images with a missing channel. Test images will be generated by removing the R, G and B channels in the original test data using ImageMagic, therefore producing three data sets. Images with a missing channel are successfully identified at rates equal to that of original images. This will be measured using the Wilcoxon Rank-Sum test, with significance at p-value <=0.05.\n",
    "    \n",
    "* **Resource Utilization - Performance on Operational Platform**\n",
    "The Garden Buddy application will need to run on the devices loaned out by the garden centers to visitors. These are small, inexpensive devices with limited CPU power, as well as limited memory and disk space (512 MB and 150 MB, respectively). The original test dataset can be used. 1- Executing the model on the loaned platform will not exceed maximum CPU usage of 30% to ensure reasonable response time. CPU usage will be measure using ps. 2- Memory usage at inference time will not exceed available memory of 512 MB. This will be measured using pmap. 3 - Disk usage will not exceed available disk space of 150 MB. This will be measured using by adding the size of each file in the path for the model code.\n",
    "    \n",
    "* **Explainability - Understanding Model Results**\n",
    "The application that runs on the loaned device should indicate the main features that were used to recognize the flower, as part of the educational experience. The app will display the image highlighting the most informative features in flower identification, in addition to the flower name. The original test data set can be used. The model needs to return evidence, in this case a heat map implementing the Integrated Gradients algorithm, showing the pixels that were most informative in the classification decision. This evidence should be returned with each inference. \n",
    "\n",
    "* **Functional Correctness - Accuracy**\n",
    "The Garden Buddy application receives receives a picture taken at the garden and can identify it correctly at least 90% of the time during normal operation.\n",
    "\n",
    "* **Functional Correctness - Input and Output Specification**\n",
    "The Garden Buddy application reads inputs and provides outputs according to established input and output specifications during normal operation. During test execution all data in the test dataset produces an output that conforms to the output specification.\n",
    "\n",
    "* **Reliability - Input Validation** \n",
    "During normal operation, if the ML pipeline receives an input that does conform to the input specification it will generate the output \"N/A\" which the app will interpret as an error. The ML pipeline will create a log entry with the tag \"Model - Input Validation Error - [Input].\"\n",
    "\n",
    "* **Analyzability - Detect OOD inputs**\n",
    "During normal operation, the ML pipeline will log errors when out of distribution data is observed. The ML pipeline will create a log entry with the tag \"Model - Input OOD Error - [Input].\"\n",
    "\n",
    "* **Monitorability - Monitor Shifts in Output (Confidence) Distribution**\n",
    "During normal operation, ML pipeline will log errors when the output distribution changes. The ML pipeline will create a log entry with the tag \"Model - Output Confidence Error - [Output].\"\n",
    "\n",
    "* **Time Behavior - Inference Time on Operational Platform**\n",
    "During normal operation, running on the operational platform, the model returns an output within two seconds.\n",
    " \n",
    "* **Repeatability - Produce the Statistically Similar Output distribution Upon Repeated Sampling of Input Test Data**\n",
    "The ML component receives a picture taken at the garden from the Garden Buddy application during normal operations. The ML component should demonstrate consistently similar performance for pictures from the same garden from day to day such that garden visitors and garden employees have consistent experiences using the app.\n",
    "\n",
    "* **Reproducibility - Train the Statistically Similar ML Components when Upon Repeated Sampling of Training Data**\n",
    "Garden Buddy stakeholders want to switch to an automated retraining process and want assurances that the results will be similar to the manual training process. The ML model should produce the same results on the test data set regardless of the training data used to train the ML component during development.\n",
    " \n",
    "* **Domain Adaptability - Using ML Component in new Operational Environment without Loss of Functionality**\n",
    "System stakeholders would like the Garden Buddy app to work in a VR garden environment that is under development. The performance of the ML model in the new VR  environment should be similar to that in the current garden environment.\n",
    " \n",
    "* **Testability - ML Component has same results in operationing and development environments**\n",
    "The developed ML component is handed over to the operations for integration into the ML-enabled system after development of the ML component is complete. The delivery of the ML component will include a test data set and corresponding component outputs. During integration testing of the ML component the differences between provided outputs and actual outputs should be less than 0.25%.\n",
    " \n",
    "* **Understandability - ML Component documentation and design choices are easy to understand**\n",
    "A new model developer joins the team and is asked to review the ML component code as part of their onboarding process. The new developer is able to fully understand the ML component design and implementation choices in 2 person/days.\"\n",
    " \n",
    "* **Maintainability - Using ML Component in new Operational Environment without Loss of Functionality**\n",
    "Given that new flowers will be added to the garden, the ML component will need to be repeatedly updated and redeployed to keep up with changes. As new flowers are added to the garden, developers can update the ML component to recognize the new flowers in less than 1 person/day.\n",
    " \n",
    "* **Modifiability - Using ML Component in new Operational Environment without Loss of Functionality**\n",
    "As the loaned devices are replaced over time due to wear or obsolescence, changes to the ML component to integrate new inputs or input formats should not take more than 1/2 person/day.\n",
    " \n",
    "* **Replaceability - Using ML Component in new Operational Environment without Loss of Functionality**\n",
    "Given how fast the machine learning field moves, system stakeholders would want to take advantage of new algorithms in a timely manner. The effort to incorporate a new trained model should be localized to a minimal number of modules and take no longer than 16 hours of development time.\n",
    "\n",
    "* **Retrainability - Using ML Component in new Operational Environment without Loss of Functionality**\n",
    "Given that the ML component will need to be periodically retrained to keep pace with the shifts in appearance of the garden flowers due to growth and changes in seasons, system stakeholders want to limit the amount of development time and resources need to retrain the ML component. The effort required to retrain the ML component on an updated flower population, while not changing the model architecture or outputs, should be no more than 2 hours. \n",
    " \n",
    "* **Reuseability - Using ML Component in new Operational Environment without Loss of Functionality**\n",
    "  System stakeholders would like to use the ML component in an upcoming mobile app version of Garden Buddy that members that are home gardeners can use to identify flowers in their gardens. Integrating the same ML component in the Garden Buddy app should be done in 4 hours of development time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Requirements\n",
    "\n",
    "## 1.1 Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial custom lists at URI: local:///Users/rbrowersinning/Documents/ResearchFolders/Continuum_LTP/GitRepos/mlte/demo/scenarios/../store\n",
      "Loaded 7 qa_categories for initial list\n",
      "Loaded 30 quality_attributes for initial list\n",
      "Creating sample catalog at URI: StoreType.LOCAL_FILESYSTEM:local:///Users/rbrowersinning/Documents/ResearchFolders/Continuum_LTP/GitRepos/mlte/demo/scenarios/../store\n",
      "Loading sample catalog entries.\n",
      "Loaded 9 entries for sample catalog.\n"
     ]
    }
   ],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from demo.scenarios.session import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Build a `NegotiationCard`\n",
    "\n",
    "In MLTE, we negotiation requirements with the help of a `NegotiationCard`. This can be done manually through code, but it is easier to use the MLTE UI to do so. Below we are copying a pre-built one that applies to this scenario. In MLTE, we define requirements by constructing a `NegotiationCard` that will include explicit Quality Attribute Scenarios with the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: ./sample_store/: No such file or directory\n",
      "/bin/ls: /bin/ls: cannot execute binary file\n"
     ]
    }
   ],
   "source": [
    "##!sh ../setup_store.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Define a TestSuite\n",
    "\n",
    "In the first phase of SDMT, we define a `TestSuite` that represents the tests the completed model must will have to pass in order to be acceptable for use in the system into which it will be integrated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MLTE, we define the tests that will be required for the different requirements in a `TestSuite`. Note that a new `Evidence` types (`MultipleRanksums`) had to be created in this case to handle the data and `Validator` for that case, and two stand-alone `Validator`s were defined in `validators.py` to validate data using existing `Evidence` types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load up our `NegotiationCard`, so we can get the list of ids of its quaity attribute scenarios, that will be added to the `TestCase`s here. Those ids are the way to link the `TestCase`s to their quality attribute requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default.card-qas_001 (Fairness): The model receives a picture taken at the garden from the garden buddy application while in normal operations, regardless of the location in the garden, the model can correctly identify the correct flowers, at least 90% of the time\n",
      "default.card-qas_002 (Robustness): The model receives a picture taken at the garden, and it is a bit blurry. imagemagick will be used with different levels of blur introduced to the origional flower test data set to simulate the operational images taken from the by the garden buddy application while in normal operations, the model successfully identifies flowers, at the same rate as non-blurry images, as measured using the wilcoxon rank-sum test, with significance at p-value <=0.05.\n",
      "default.card-qas_003 (Resilience): The model receives a picture taken at the garden, and it is a bit blurry. imagemagick will be used with different channel loss introduced to the origional flower test data set to simulate the operational images taken from the garden buddy application  while in normal operations. these devices are known to sometimes lose a channel (i.e., rgb channel), the model successfully identifies flowers, at the same rate as full images, as measured using the wilcoxon rank-sum test, with significance at p-value <=0.05.\n",
      "default.card-qas_004 (Resource  Utilization): The model running on the loaned device receives pictures taken at the garden from the flower identification application while in normal operations. the loaned devices are small, inexpensive devices with limited cpu power, as well as limited memory and disk space (512 mb and 150 mb, respectively), the model executes on the loaned device, without any errors due to unavailable resources\n",
      "default.card-qas_005 (Understandability): The model receives a picture taken at the garden from the garden buddy application while in normal operations, the application indicates main features that were used to recognize the flower, as part of the educational experience., the app displays the original image highlighting the most informative features in flower identification, in addition to the flower name\n",
      "default.card-qas_006 (Functional Correctness): The model receives a picture taken at the garden from garden buddy application while in normal operations, the model identifies the flower correctly, with an accurayc of at least 90%\n",
      "default.card-qas_007 (Functional Correctness): The model receives a picture taken at the garden from garden biddy application while in normal operations, model correctly processes inputs and produces outputs, according to established input and output specifications without exceptions\n",
      "default.card-qas_008 (Resilience): The ml pipeline receives a picture taken at the garden that does not conform to the input specification from the garden buddy application while in normal operations, the model does not process the input, and instead the ml pipeline produces -99 as the output and creates a log entry with the tag \"model - input validation error - <input>, where <input> is the original input.\n",
      "default.card-qas_009 (Analyzability): The ml pipeline receives a picture that corresponds to an ood input from the garden buddy application while in normal operations, the model will process the input , and the ml pipeline will create a log entry with the tag \"model - input ood error - <input>, where <input> is the original input\n",
      "default.card-qas_010 (Monitorability): The ml pipeline detects an output distribution change from the output produced by the model while in normal operations, the ml pipeline will create a log entry, with the tag \"model - output confidence error - <output>, where <output> is the output produced by the model that triggered the condition\n",
      "default.card-qas_011 (Time  Behavior): Model running on the loaned device receives a picture from the garden buddy application while in normal operations, the time for the model to return an output, is no more than two seconds\n",
      "default.card-qas_012 (Repeatability): The model receives a picture taken at the garden, simulated by using the test data set, from the garden buddy application while in normal operation, the results over 50 test data sets, each with 500 randomly selected test samples, will be compared using kruskal-wallis test will be used to evaluate if similarity of class of model results, with p<0.05 \n",
      "default.card-qas_013 (Reproducibility): The ml component will periodically need to be retrained in which 10 sampled training data sets will be used to generate a new trained ml component,   from an automated, identicall retraining process while in an automated, identicall retraining process, the performance of the model, as measured on the same test data set,, using a friedman test will be used to evaluate if similarity of class of model results, with p<0.05 \n",
      "default.card-qas_014 (Domain  Adaptability): The garden buddy application may be used in a vr environment, and as such the ml component may receive synthetic flower images from the garden buddy application while in normal operation, comparing the results of the application on the origional flower test data set and the new synthetic test data set,, should show no signifigant differences in performance on performance will be assessed using anova on each label set, with significance at p-value < 0.05 \n",
      "default.card-qas_015 (Testability): Ml component will transition from the development environment through integration with the operational ml enabled system from conclusion of development activities while in into the operational environment, the new ml component, post integrated into the ml-enabled operational system, should have test set results differ by less than 0.25% when comparing results to those obtained in the development environment. \n",
      "default.card-qas_016 (Understandability): A new developer is joining the garden buddy team from outside the organiation while in development, the implementation and design choices are easily understood by a new developer after reading the code and documentation, after 2 person/days\n",
      "default.card-qas_017 (Maintainability): A new flower is introduced into the garden from the garden staff updating the garden and hosting traveling botanical exhibits while in during run time, a new trained ml component, trained on updated training data and number of output labels,, will be available no later than 8 hours after the development team is notified.\n",
      "default.card-qas_018 (Modifiability): The need for the app to run with a new input format for the ml component from the operations/maintenance team needs to changing input data processing pipelines as a new device type is used for the garden buddy app  while in normal operation, the new sensor's data input  processing pipeline is to replace the old input data processing pipeline, and the total effort involved is less than 4 hours of operations staff time.\n",
      "default.card-qas_019 (Replaceability): The team needs to quickly change the ml model being run by the application from as an advancement in the field has occurred that necessitates an update in the algorithm used to generate the ml component while in normal operation, the model switch change over is made , and the total effort involved is less than 16 hours of development and operation teams' time\n",
      "default.card-qas_020 (Retrainability): The ml component needs to be retrained from as an environment necessitating a new model has occured  while in normal operation, the development team kicks off the ml model retraining process, and the total personnel time devoted to kick off, monitoring and checking the output of the retraining process is no more than 1 hour. \n",
      "default.card-qas_021 (Reusability): The decision to produce a new app, with only changing who it is marketed to, user interface, and platform is issued from stakeholders while in development time, the existing garden buddy ml component is used in the new app, with limited changes to the ml component code were needed to integrate the ml component into the new app, totaling no more than 1/2 a development day. \n"
     ]
    }
   ],
   "source": [
    "from mlte.negotiation.artifact import NegotiationCard\n",
    "\n",
    "card = NegotiationCard.load()\n",
    "card.save(force=True)\n",
    "card.print_quality_scenarios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our `TestSuite`, consisting of a list of `TestCases`, each of them addressing one or more Quality Attribute Scenarios from our `NegotiationCard`. When defining the `TestCase`s below, we need to set the id of the corresponding Quality Attribute Scenario we want to test in its \"quality_scenarios\" attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArtifactModel(header=ArtifactHeaderModel(identifier='suite.default', type='suite', timestamp=1759248081, creator=None, level='model'), body=TestSuiteModel(artifact_type=<ArtifactType.TEST_SUITE: 'suite'>, test_cases=[TestCaseModel(identifier='accuracy across gardens', goal='Check if model performs well accross different populations', qas_list=['default.card-qas_001'], measurement=None, validator=ValidatorModel(bool_exp='gASVfgMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgWARj/EAIo/pRLAUsASwBLAUsESxNDbJUBlwB0AQAAAAAAAAAAiAFmAWQBhAh8AGoCAAAAAAAAAAAAAAAAAAAAAAAARACrAAAAAAAAAKsBAAAAAAAAdAUAAAAAAAAAAHwAagIAAAAAAAAAAAAAAAAAAAAAAACrAQAAAAAAAGsoAABTAJROaAQoQwIKAZRLAUsASwBLAksDSzNDKJUBSwABAJcAfABdCQAAfQF8AYkCa1wAAJYBlwEBAIwLBAB5AK0DdwGUToWUKYwCLjCUjAFnlIaUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCTxnZW5leHByPpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6USxJDGfjoAPiAAPAAAjoG2SArmDGIAYhZjQ6hC/mUQwSDDxIBlIwJdGhyZXNob2xklIWUKXSUUpSGlIwDc3VtlIwFYXJyYXmUjANsZW6Uh5SMBXZhbHVllIWUaA2MCDxsYW1iZGE+lIwzYWxsX2FjY3VyYWNpZXNfbW9yZV9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsSQyz4gAC0Y/MAAjoG2CAlpwuiC/MDAjoG8wACNwbkCQyIVY9biVvTCRnyBQI3GpRDAJRoEoWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaB51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaDGMB3NldGF0dHKUk5SHlFKUaCeMDWNlbGxfY29udGVudHOURz/szMzMzMzNh5RSMC4=', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.9', failure='One or more accuracies are below threshold 0.9', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.9'])), TestCaseModel(identifier='ranksums blur2x8', goal='Check blur and noise for 2x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur5x8', goal='Check blur and noise for 5x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur0x8', goal='Check blur and noise for 0x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='effect of blur across families', goal='Check consistency in families', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/Nz1eDFiZ94eUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.0003546099290780142'], success='All p-values are equal to or over threshold 0.0003546099290780142', failure='One or more p-values are below threshold 0.0003546099290780142', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.0003546099290780142'])), TestCaseModel(identifier='ranksums channel loss R', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss G', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss B', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='model size', goal='Check storage consumption', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASV5wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrAgAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwgUmVhbC5sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US21DFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEuWjAlwaW50LnV0aWyUjA5Vbml0c0NvbnRhaW5lcpSTlCmBlGgzjAV1ZGljdJSTlCmBlIwIbWVnYWJ5dGWUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda real: (real.get_value_w_units() < threshold_w_unit)', thresholds=[], success='Real magnitude is less than threshold 150 megabyte', failure='Real magnitude exceeds threshold 150 megabyte', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='less_than', creator_args=['150', 'megabyte'])), TestCaseModel(identifier='predicting memory', goal='Check memory used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVNAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDYXZnlIWUjAVzdGF0c5SFlIyHL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvbWVtb3J5L2xvY2FsX3Byb2Nlc3NfbWVtb3J5X2NvbnN1bXB0aW9uLnB5lIwIPGxhbWJkYT6UjEBNZW1vcnlTdGF0aXN0aWNzLmF2ZXJhZ2VfY29uc3VtcHRpb25fbGVzc190aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEuMQw/4gACYJZ8pmSnQJjbSGjaUaAWMEHRocmVzaG9sZF93X3VuaXSUhZQpdJRSlGNtbHRlLm1lYXN1cmVtZW50Lm1lbW9yeS5sb2NhbF9wcm9jZXNzX21lbW9yeV9jb25zdW1wdGlvbgpfX2RpY3RfXwpoDU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaA51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaCGMB3NldGF0dHKUk5SHlFKUaBeMDWNlbGxfY29udGVudHOUjARwaW50lIwSX3VucGlja2xlX3F1YW50aXR5lJOUjBpwaW50LmZhY2V0cy5wbGFpbi5xdWFudGl0eZSMDVBsYWluUXVhbnRpdHmUk5RHQIAAAAAAAACMCXBpbnQudXRpbJSMDlVuaXRzQ29udGFpbmVylJOUKYGUaDOMBXVkaWN0lJOUKYGUjAhtZWdhYnl0ZZRLAXNLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda stats: (stats.avg < threshold_w_unit)', thresholds=['512.0 megabyte'], success='Average consumption below threshold 512.0 megabyte', failure='Average consumption exceeds threshold 512.0 megabyte', info=None, input_types=['mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics'], creator_entity='mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics', creator_function='average_consumption_less_than', creator_args=['512.0', 'megabyte'])), TestCaseModel(identifier='predicting cpu', goal='Check cpu % used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVIAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDbWF4lIWUjAVzdGF0c5SFlIyBL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvY3B1L2xvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uLnB5lIwIPGxhbWJkYT6UjDlDUFVTdGF0aXN0aWNzLm1heF91dGlsaXphdGlvbl9sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US3dDD/iAAJglnymZKdAmNtIaNpRoBYwQdGhyZXNob2xkX3dfdW5pdJSFlCl0lFKUY21sdGUubWVhc3VyZW1lbnQuY3B1LmxvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEdAPgAAAAAAAIwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZSMB3BlcmNlbnSUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda stats: (stats.max < threshold_w_unit)', thresholds=['30.0 percent'], success='Maximum utilization below threshold 30.00 percent', failure='Maximum utilization exceeds threshold 30.00 percent', info=None, input_types=['mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics'], creator_entity='mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics', creator_function='max_utilization_less_than', creator_args=['30.0', 'percent'])), TestCaseModel(identifier='overall model accuracy', goal='Measure the overall accuracy of your end to end pipeline', qas_list=['default.card-qas_006'], measurement=None, validator=ValidatorModel(bool_exp='gASV4wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrRAAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwjUmVhbC5ncmVhdGVyX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US5tDFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEc/7MzMzMzMzYwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZRLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda real: (real.get_value_w_units() > threshold_w_unit)', thresholds=[], success='Real magnitude is greater than threshold 0.9', failure='Real magnitude is below threshold 0.9', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='greater_than', creator_args=['0.9', 'None'])), TestCaseModel(identifier='repeated results sampling', goal='Repeatedly sampling results gives same results', qas_list=['default.card-qas_012'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='repeated training on training samples', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_013'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='running in new domain', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_014'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/qZmZmZmZmoeUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.05'], success='All p-values are equal to or over threshold 0.05', failure='One or more p-values are below threshold 0.05', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.05'])), TestCaseModel(identifier='test results from dev and op env', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_015'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect the alignment of results for no more than 0.25% difference.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect the alignment of results for no more than 0.25% difference.'])), TestCaseModel(identifier='understanding design choices', goal='understanding design and implementation choices', qas_list=['default.card-qas_016'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect projrct code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect projrct code and documentation.'])), TestCaseModel(identifier='keep ML component up to date', goal='keep trained ML component up to date with op environment changes', qas_list=['default.card-qas_017'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 8hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 8hrs.'])), TestCaseModel(identifier='update data pipelines', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_018'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.'])), TestCaseModel(identifier='update ML training algorithm', goal='update ML component training algorithm', qas_list=['default.card-qas_019'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate train time less than 16hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate train time less than 16hrs.'])), TestCaseModel(identifier='retrain ML model', goal='update ML component training algorithm', qas_list=['default.card-qas_020'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Model takes less than 1 hr to retrain.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Model takes less than 1 hr to retrain.'])), TestCaseModel(identifier='reuse ML component', goal='reuse ML component in new app', qas_list=['default.card-qas_021'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.']))]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlte.tests.test_case import TestCase\n",
    "from mlte.tests.test_suite import TestSuite\n",
    "\n",
    "# The Evidence types we will use to validate each condition.\n",
    "from mlte.measurement.storage import LocalObjectSize\n",
    "from mlte.measurement.cpu import LocalProcessCPUUtilization\n",
    "from mlte.measurement.units import Units\n",
    "from mlte.measurement.memory import LocalProcessMemoryConsumption\n",
    "from mlte.evidence.types.image import Image\n",
    "from mlte.evidence.types.string import String\n",
    "from mlte.evidence.types.real import Real\n",
    "from demo.scenarios import validators\n",
    "from demo.scenarios.evidence.multiple_ranksums import MultipleRanksums\n",
    "from mlte.evidence.types.string import String\n",
    "from mlte.validation.validator import Validator\n",
    "\n",
    "\n",
    "# The full test suite.\n",
    "test_suite = TestSuite(\n",
    "    test_cases=[\n",
    "        # Fairness QAS test cases.\n",
    "        TestCase(\n",
    "            identifier=\"accuracy across gardens\",\n",
    "            goal=\"Check if model performs well accross different populations\",\n",
    "            quality_scenarios=[\"default.card-qas_001\"],\n",
    "            validator=validators.all_accuracies_more_or_equal_than(0.9),\n",
    "        ),\n",
    "        # Robustness QAS test cases.\n",
    "        TestCase(\n",
    "            identifier=\"ranksums blur2x8\",\n",
    "            goal=\"Check blur and noise for 2x8 case\",\n",
    "            quality_scenarios=[\"default.card-qas_002\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 / 3),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"ranksums blur5x8\",\n",
    "            goal=\"Check blur and noise for 5x8 case\",\n",
    "            quality_scenarios=[\"default.card-qas_002\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 / 3),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"ranksums blur0x8\",\n",
    "            goal=\"Check blur and noise for 0x8 case\",\n",
    "            quality_scenarios=[\"default.card-qas_002\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 / 3),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"effect of blur across families\",\n",
    "            goal=\"Check consistency in families\",\n",
    "            quality_scenarios=[\"default.card-qas_002\"],\n",
    "            validator=MultipleRanksums.all_p_values_greater_or_equal_than(0.05 / 141),\n",
    "        ),\n",
    "        #Resilience QAS test case \n",
    "        TestCase(\n",
    "            identifier=\"ranksums channel loss R\",\n",
    "            goal=\"Check consistency between channel loss\",\n",
    "            quality_scenarios=[\"default.card-qas_003\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"ranksums channel loss G\",\n",
    "            goal=\"Check consistency between channel loss\",\n",
    "            quality_scenarios=[\"default.card-qas_003\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"ranksums channel loss B\",\n",
    "            goal=\"Check consistency between channel loss\",\n",
    "            quality_scenarios=[\"default.card-qas_003\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05),\n",
    "        ),\n",
    "        # Resource Utilization QASs test cases.\n",
    "        TestCase(\n",
    "            identifier=\"model size\",\n",
    "            goal=\"Check storage consumption\",\n",
    "            quality_scenarios=[\"default.card-qas_004\"],\n",
    "            validator=LocalObjectSize.get_output_type().less_than(\n",
    "                150, Units.megabyte\n",
    "            ),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"predicting memory\",\n",
    "            goal=\"Check memory used while predicting\",\n",
    "            quality_scenarios=[\"default.card-qas_004\"],\n",
    "            validator=LocalProcessMemoryConsumption.get_output_type().average_consumption_less_than(\n",
    "                512.0, unit=Units.megabyte\n",
    "            ),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"predicting cpu\",\n",
    "            goal=\"Check cpu % used while predicting\",\n",
    "            quality_scenarios=[\"default.card-qas_004\"],\n",
    "            validator=LocalProcessCPUUtilization.get_output_type().max_utilization_less_than(\n",
    "                30.0, unit=Units.percent\n",
    "            ),\n",
    "        ), \n",
    "        # Understandability QAS test case.\n",
    "        #TestCase(\n",
    "        #    identifier=\"image attributions\",\n",
    "        #    goal=\"Check what the model is doing\",\n",
    "        #    quality_scenarios=[\"default.card-qas_005\"],\n",
    "        #    validator=Image.register_info(\"Inspect the image.\"),\n",
    "        #),\n",
    "        # Functional Correctness - Accuracy QAS test cases.\n",
    "        TestCase(\n",
    "            identifier=\"overall model accuracy\",\n",
    "            goal=\"Measure the overall accuracy of your end to end pipeline\",\n",
    "            quality_scenarios=[\"default.card-qas_006\"],\n",
    "            validator=Real.greater_than(0.9),\n",
    "        ),\n",
    "        # Functional Correctness - I/O spec QAS test cases.\n",
    "        #TestCase(\n",
    "        #    identifier=\"input format validation success\",\n",
    "        #    goal=\"Model input format must conform to specified format\",\n",
    "        #    quality_scenarios=[\"default.card-qas_007\"],\n",
    "        #    validator=String.contains(\"Model - Input Validation Pass\"),\n",
    "        #),\n",
    "        #TestCase(\n",
    "        #    identifier=\"output format validation success\",\n",
    "        #    goal=\"Model output format must conform to specified format\",\n",
    "        #    quality_scenarios=[\"default.card-qas_007\"],\n",
    "        #    validator=String.contains(\"Model - Output Validation Pass\"),\n",
    "        #),\n",
    "        # Reliability: Input Validation QAS test cases.\n",
    "        #TestCase(\n",
    "        #    identifier=\"input format validation error\",\n",
    "        #    goal=\"Model inputs must conform to specified format\",\n",
    "        #    quality_scenarios=[\"default.card-qas_008\"],\n",
    "        #    validator=String.contains(\"Model - Input Validation Error\"),\n",
    "        #),\n",
    "        #  Analyzability QAS test cases.\n",
    "        #TestCase(\n",
    "        #    identifier=\"detect ood inputs\",\n",
    "        #    goal=\"Monitor inputs for OOD data and unexpected shifts\",\n",
    "        #    quality_scenarios=[\"default.card-qas_009\"],\n",
    "        #    validator=String.contains(\"Model - Input OOD Error\"),\n",
    "        #), \n",
    "        #Monitorability QAS test case\n",
    "        #TestCase(\n",
    "        #    identifier=\"monitor output confidence shift\",\n",
    "        #    goal=\"Monitor inputs for OOD data and unexpected shifts\",\n",
    "        #    quality_scenarios=[\"default.card-qas_010\"],\n",
    "        #    validator=String.contains(\"Model - Output Confidence Error\"),\n",
    "        #),\n",
    "        #Time Behaviour \n",
    "        #TestCase(\n",
    "        #    identifier=\"predicting cpu time\",\n",
    "        #    goal=\"Check cpu time used while predicting\",\n",
    "        #    quality_scenarios=[\"default.card-qas_011\"],\n",
    "        #    validator=Real.less_than(2.0, Units.second),\n",
    "        #),\n",
    "        #Repeatability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"repeated results sampling\",\n",
    "            goal=\"Repeatedly sampling results gives same results\",\n",
    "            quality_scenarios=[\"default.card-qas_012\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 ),\n",
    "        ),\n",
    "        #Reproducability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"repeated training on training samples\",\n",
    "            goal=\"Repeatedly training on different sammples of training data gives same results on test data set\",\n",
    "            quality_scenarios=[\"default.card-qas_013\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 ),\n",
    "        ),\n",
    "        #Domain Adaptability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"running in new domain\",\n",
    "            goal=\"Repeatedly training on different sammples of training data gives same results on test data set\",\n",
    "            quality_scenarios=[\"default.card-qas_014\"],\n",
    "            validator=MultipleRanksums.all_p_values_greater_or_equal_than(0.05 ),\n",
    "        ),\n",
    "        #Testability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"test results from dev and op env\", #test results from dev and op env\n",
    "            goal=\"aligment of test results from dev and op environments\",\n",
    "            quality_scenarios=[\"default.card-qas_015\"],\n",
    "            validator=Validator.build_info_validator(\"Inspect the alignment of results for no more than 0.25% difference.\"),\n",
    "        ),\n",
    "        #Understandability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"understanding design choices\",\n",
    "            goal=\"understanding design and implementation choices\",\n",
    "            quality_scenarios=[\"default.card-qas_016\"],\n",
    "            validator=Validator.build_info_validator(\"Inspect projrct code and documentation.\"),\n",
    "        ),\n",
    "        #Maintainability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"keep ML component up to date\",\n",
    "            goal=\"keep trained ML component up to date with op environment changes\",\n",
    "            quality_scenarios=[\"default.card-qas_017\"],\n",
    "            validator=Validator.build_info_validator(\"Validate work time less than 8hrs.\"),\n",
    "        ),\n",
    "        #Modifiability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"update data pipelines\",\n",
    "            goal=\"aligment of test results from dev and op environments\",\n",
    "            quality_scenarios=[\"default.card-qas_018\"],\n",
    "            validator=Validator.build_info_validator(\"Validate work time less than 4hrs.\"),\n",
    "        ),\n",
    "        #Replaceability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"update ML training algorithm\",\n",
    "            goal=\"update ML component training algorithm\",\n",
    "            quality_scenarios=[\"default.card-qas_019\"],\n",
    "            validator=Validator.build_info_validator(\"Validate train time less than 16hrs.\"),\n",
    "        ),\n",
    "        #Retrainability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"retrain ML model\",\n",
    "            goal=\"update ML component training algorithm\",\n",
    "            quality_scenarios=[\"default.card-qas_020\"],\n",
    "            validator=Validator.build_info_validator(\"Model takes less than 1 hr to retrain.\"),\n",
    "        ),\n",
    "        #Reuseability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"reuse ML component\",\n",
    "            goal=\"reuse ML component in new app\",\n",
    "            quality_scenarios=[\"default.card-qas_021\"],\n",
    "            validator=Validator.build_info_validator(\"Validate work time less than 4hrs.\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "test_suite.save(parents=True, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
