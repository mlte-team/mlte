{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation and Report Generation\n",
    "\n",
    "The final phase of SDMT involves aggregating evidence, validating the metrics reflected by the evidence we collected, and displaying this information in a report."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlte.session import set_context, set_store\n",
    "\n",
    "store_path = os.path.join(os.getcwd(), \"store\")\n",
    "os.makedirs(store_path, exist_ok=True)   # Ensure we are creating the folder if it is not there.\n",
    "\n",
    "set_context(\"ns\", \"OxfordFlower\", \"0.0.1\")\n",
    "set_store(f\"local://{store_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# The path at which reports are stored\n",
    "REPORTS_DIR = Path(os.getcwd()) / \"reports\"\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Values and get an updated `ValidatedSpec` with `Result`s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `Spec` ready and we have enough evidence, we create a `SpecValidator` with our spec, and add all the `Value`s we have. With that we can validate our spec and generate an output `ValidatedSpec`, with the validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.spec.spec import Spec\n",
    "from mlte.validation.spec_validator import SpecValidator\n",
    "\n",
    "from mlte.measurement.cpu import CPUStatistics\n",
    "from mlte.measurement.memory import MemoryStatistics\n",
    "from mlte.value.types.image import Image\n",
    "from mlte.value.types.integer import Integer\n",
    "\n",
    "from values.multiple_accuracy import MultipleAccuracy\n",
    "from values.multiple_ranksums import MultipleRanksums\n",
    "from values.ranksums import RankSums\n",
    "\n",
    "# Load the specification\n",
    "spec = Spec.load()\n",
    "\n",
    "# Add all values to the validator.\n",
    "spec_validator = SpecValidator(spec)\n",
    "spec_validator.add_value(MultipleAccuracy.load(\"accuracy across gardens.value\"))\n",
    "spec_validator.add_value(RankSums.load(\"ranksums blur2x8.value\"))\n",
    "spec_validator.add_value(RankSums.load(\"ranksums blur5x8.value\"))\n",
    "spec_validator.add_value(RankSums.load(\"ranksums blur0x8.value\"))\n",
    "spec_validator.add_value(MultipleRanksums.load(\"multiple ranksums for clade2.value\"))\n",
    "spec_validator.add_value(MultipleRanksums.load(\"multiple ranksums between clade2 and 3.value\"))\n",
    "spec_validator.add_value(Integer.load(\"model size.value\"))\n",
    "spec_validator.add_value(CPUStatistics.load(\"predicting cpu.value\"))\n",
    "spec_validator.add_value(MemoryStatistics.load(\"predicting memory.value\"))\n",
    "spec_validator.add_value(Image.load(\"image attributions.value\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate requirements and get validated details.\n",
    "validated_spec = spec_validator.validate()\n",
    "validated_spec.save(force=True)\n",
    "\n",
    "# We want to see the validation results in the Notebook, regardles sof them being saved.\n",
    "validated_spec.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see some of the results of the validation.\n",
    "\n",
    "For example, there is a significant difference between original model with no blur and blur 0x8. So we see a drop in model accuracy with increasing blur. But aside from max blur (0x8), the model accuracy fall off isn't bad.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a Report\n",
    "\n",
    "The final step of SDMT involves the generation of a report to communicate the results of model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlte.model.shared import (\n",
    "    ProblemType,\n",
    "    GoalDescriptor,\n",
    "    MetricDescriptor,\n",
    "    ModelProductionDescriptor,\n",
    "    ModelInterfaceDescriptor,\n",
    "    ModelInputDescriptor,\n",
    "    ModelOutputDescriptor,\n",
    "    ModelResourcesDescriptor,\n",
    "    RiskDescriptor,\n",
    "    DataDescriptor,\n",
    "    DataClassification,\n",
    "    FieldDescriptor,\n",
    "    LabelDescriptor,\n",
    ")\n",
    "from mlte.report.artifact import (\n",
    "    Report,\n",
    "    SummaryDescriptor,\n",
    "    PerformanceDesciptor,\n",
    "    IntendedUseDescriptor,\n",
    "    CommentDescriptor,\n",
    "    QuantitiveAnalysisDescriptor,\n",
    ")\n",
    "\n",
    "report = Report(\n",
    "    summary=SummaryDescriptor(\n",
    "        problem_type=ProblemType.CLASSIFICATION, task=\"Flower classification\"\n",
    "    ),\n",
    "    performance=PerformanceDesciptor(\n",
    "        goals=[\n",
    "            GoalDescriptor(\n",
    "                description=\"The model should perform well.\",\n",
    "                metrics=[\n",
    "                    MetricDescriptor(\n",
    "                        description=\"accuracy\",\n",
    "                        baseline=\"Better than random chance.\",\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    intended_use=IntendedUseDescriptor(\n",
    "        usage_context=\"A handheld flower identification device.\",\n",
    "        production_requirements=ModelProductionDescriptor(\n",
    "            integration=\"integration\",\n",
    "            interface=ModelInterfaceDescriptor(\n",
    "                input=ModelInputDescriptor(description=\"Vector[150]\"),\n",
    "                output=ModelOutputDescriptor(description=\"Vector[3]\"),\n",
    "            ),\n",
    "            resources=ModelResourcesDescriptor(\n",
    "                cpu=\"1\", gpu=\"0\", memory=\"6MiB\", storage=\"2KiB\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    risks=RiskDescriptor(\n",
    "        fp=\"The wrong type of flower is identified.\",\n",
    "        fn=\"The flower is not identified.\",\n",
    "        other=\"N/A\",\n",
    "    ),\n",
    "    data=[\n",
    "        DataDescriptor(\n",
    "            description=\"Flower dataset.\",\n",
    "            classification=DataClassification.UNCLASSIFIED,\n",
    "            access=\"None\",\n",
    "            fields=[\n",
    "                FieldDescriptor(\n",
    "                    name=\"Sepal length\",\n",
    "                    description=\"The length of the sepal.\",\n",
    "                    type=\"float\",\n",
    "                    expected_values=\"N/A\",\n",
    "                    missing_values=\"N/A\",\n",
    "                    special_values=\"N/A\",\n",
    "                )\n",
    "            ],\n",
    "            labels=[\n",
    "                LabelDescriptor(description=\"Dahlia\", percentage=30.0),\n",
    "                LabelDescriptor(description=\"Sunflower\", percentage=30.0),\n",
    "                LabelDescriptor(description=\"Azalea\", percentage=40.0),\n",
    "            ],\n",
    "            policies=\"N/A\",\n",
    "            rights=\"N/A\",\n",
    "            source=\"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/\",\n",
    "            identifiable_information=\"N/A\",\n",
    "        )\n",
    "    ],\n",
    "    comments=[\n",
    "        CommentDescriptor(\n",
    "            content=\"This model should not be used for nefarious purposes.\"\n",
    "        )\n",
    "    ],\n",
    "    quantitative_analysis=QuantitiveAnalysisDescriptor(\n",
    "        content=\"Insert graph here.\"\n",
    "    ),\n",
    "    validated_spec_id=validated_spec.identifier,\n",
    ")\n",
    "\n",
    "report.save(force=True, parents=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82adda432962015d5f71beb9387a99f24d390514e497c776c87ff3434daf7312"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
