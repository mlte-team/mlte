{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation and Report Generation\n",
    "\n",
    "The final phase of SDMT involves aggregating evidence, validating the metrics reflected by the evidence we collected, and displaying this information in a report."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from demo.scenarios.session import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Evidence and get an updated `TestResults` with `Result`s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `TestSuite` ready and we have enough evidence, we create a `TestSuiteValidator` with our TestSuite, and add all the `Evidence`s we have. With that we can validate our tests and generate an output `TestResults`, with the validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Test Case: accuracy across gardens, result: Success, details: All accuracies are equal to or over threshold 0.9 - values: [\"[0.946, 0.956, 0.913]\"]\n",
      " > Test Case: ranksums blur2x8, result: Success, details: P-Value is greater or equal to 0.016666666666666666 - values: [\"[0.07946178703316073, 0.9366653249981838]\"]\n",
      " > Test Case: ranksums blur5x8, result: Success, details: P-Value is greater or equal to 0.016666666666666666 - values: [\"[0.4032389192727559, 0.6867724711187835]\"]\n",
      " > Test Case: ranksums blur0x8, result: Failure, details: P-Value is less than threshold 0.016666666666666666 - values: [\"[2.908064206049404, 0.003636736621916332]\"]\n",
      " > Test Case: effect of blur across families, result: Success, details: All p-values are equal to or over threshold 0.0003546099290780142 - values: [\"{'array': [{'evidence.ranksums Order Apiales-Apiales blurdelta_2x8': [0.0, 1.0]}, {'evidence.ranksums Order Apiales-Alismatales blurdelta_2x8': [0.0, 1.0]}, {'evidence.ranksums Order Apiales-Asterales blurdelta_2x8': [-0.1091089451179962, 0.9131160800723744]}, {'evidence.ranksums Order Apiales-Erica...\"]\n",
      " > Test Case: ranksums channel loss R, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[0.8052918417241214, 0.4206512885130542]\"]\n",
      " > Test Case: ranksums channel loss G, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[0.6356942962652858, 0.5249756947411197]\"]\n",
      " > Test Case: ranksums channel loss B, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[0.7673399434396266, 0.44287942555285786]\"]\n",
      " > Test Case: model size, result: Success, details: Real magnitude is less than threshold 150 megabyte - values: [\"13.0 byte\"]\n",
      " > Test Case: predicting memory, result: Success, details: Average consumption below threshold 512.0 megabyte - values: [\"Average: 251292 kilobyte\\nMinimum: 32 kilobyte\\nMaximum: 437792 kilobyte\"]\n",
      " > Test Case: predicting cpu, result: Success, details: Maximum utilization below threshold 30.00 percent - values: [\"Average: 1.83 percent\\nMinimum: 0.00 percent\\nMaximum: 5.40 percent\"]\n",
      " > Test Case: overall model accuracy, result: Success, details: Real magnitude is greater than threshold 0.9 - values: [\"0.947265625\"]\n",
      " > Test Case: repeated results sampling, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[38.903978816768415, 0.8487546281441082]\"]\n",
      " > Test Case: repeated training on training samples, result: Success, details: P-Value is greater or equal to 0.05 - values: [\"[1.3575418994429564, 0.9980720828075595]\"]\n",
      " > Test Case: running in new domain, result: Failure, details: One or more p-values are below threshold 0.05 - values: [\"{'array': [{'evidence.label 0': [35.98058233033483, 7.269476178488252e-06]}, {'evidence.label 1': [1.2823981355178078, 0.2715430886274718]}, {'evidence.label 2': [4.059687454037485, 0.05829167989491706]}, {'evidence.label 3': [0.000382861952999998, 0.9845827951232068]}, {'evidence.label 4': [26.6332...\"]\n",
      " > Test Case: test results from dev and op env, result: Success, details: Manually validated: Visual inspection confirms dresults are only 0.2% different (original message: Inspect the alignment of results for no more than 0.25% difference.)\n",
      " > Test Case: understanding design choices, result: Success, details: Manually validated: An outside developer was able to understand the code and documenation in 2 person days (original message: Inspect projrct code and documentation.)\n",
      " > Test Case: keep ML component up to date, result: Success, details: Manually validated: A new ML model, trained on updated training data and using updated lables, took 4 hrs to produce (original message: Validate work time less than 8hrs.)\n",
      " > Test Case: update data pipelines, result: Failure, details: Manually validated: Updating the the model to use a new sensor took 5 hours (original message: Validate work time less than 4hrs.)\n",
      " > Test Case: update ML training algorithm, result: Failure, details: Manually validated: A new algorithm was used to generate a newly retrained model in 4 person days (original message: Validate train time less than 16hrs.)\n",
      " > Test Case: retrain ML model, result: Success, details: Manually validated: The model was retrained on the same training data and labels with the same algorithm in 45 minutes (original message: Model takes less than 1 hr to retrain.)\n",
      " > Test Case: reuse ML component, result: Success, details: Manually validated: The ML component was successfully reused in the new app with less than 1/2 day development time (original message: Validate work time less than 4hrs.)\n"
     ]
    }
   ],
   "source": [
    "from mlte.results.test_results import TestResults\n",
    "\n",
    "#laod test results\n",
    "\n",
    "test_results = TestResults.load()\n",
    "\n",
    "test_results.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see some of the results of the validation.\n",
    "\n",
    "For example, there is a significant difference between original model with no blur and blur 0x8. So we see a drop in model accuracy with increasing blur. But aside from max blur (0x8), the model accuracy fall off isn't bad.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a Report\n",
    "\n",
    "The final step of SDMT involves the generation of a report to communicate the results of model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArtifactModel(header=ArtifactHeaderModel(identifier='report.default-20250930-120505', type='report', timestamp=1759248305, creator=None, level='version'), body=ReportModel(artifact_type=<ArtifactType.REPORT: 'report'>, negotiation_card_id='card.default', negotiation_card=NegotiationCardModel(artifact_type=<ArtifactType.NEGOTIATION_CARD: 'card'>, system=SystemDescriptor(goals=[GoalDescriptor(description='Correct identification of flowers', metrics=[MetricDescriptor(description='Accuracy > 0.9', baseline='Paper that describes the base model')]), GoalDescriptor(description='Increased number of visits to the garden', metrics=[MetricDescriptor(description='40% growth in repeat visits', baseline='Strategic plan'), MetricDescriptor(description='40% new visits', baseline='Strategic plan')])], problem_type=<ProblemType.CLASSIFICATION: 'classification'>, task='Identify flowers in pictures taken at the garden', usage_context='The model will be part of an application, the Garden Buddy app, that runs on a device loaned out by a botanical garden so that visitors can identify flowers during their visit.', risks=RiskDescriptor(fp='Poor user experience due to incorrectly identified flowers', fn='Poor user experience due to inability to identify flowers', other=['Wrong results due to unknown flowers', 'Users do not like the results due to strange behavior.'])), data=[DataDescriptor(description='Oxford Flower Dataset.', source='Oxford Flower 102', classification=<DataClassification.UNCLASSIFIED: 'unclassified'>, access='None', labeling_method='By hand', labels=[LabelDescriptor(name='', description='', percentage=0.0)], fields=[FieldDescriptor(name='filename', description='Path to flower image.', type='String (to PNG file)', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Kingdom', description='The second highest taxonomic rank.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Phylum', description='The taxonomic rank below kingdom and above Clade 1.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Clade1', description='The taxonomic rank below Phylum and above Clade 2.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Clade2', description='The taxonomic rank below Clade 1 and above Clade 3.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Clade3', description='The taxonomic rank below Clade 2 and above Order.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Order', description='The taxonomic rank below Clade 3 and above Family.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Family', description='The taxonomic rank below Order and above Subfamily.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Subfamily', description='The taxonomic rank below Family and above Genus.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Genus', description='The taxonomic rank below Subfamily and above Species.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Common Name', description='Common name for the flower.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Other Name', description='Other name for the flower.', type='string', expected_values='N/A', missing_values='N/A', special_values='N/A'), FieldDescriptor(name='Label', description='Image Label', type='string', expected_values='Value between 0 and 102', missing_values='N/A', special_values='N/A')], rights='N/A', policies='N/A')], model=ModelDescriptor(development_compute_resources=ModelResourcesDescriptor(cpu='1', gpu='0', memory='2 GB', storage='100 GB'), deployment_platform='Model will be deployed as part of the Garden Buddy App on a small device loaned out to garden visitors.', capability_deployment_mechanism='The model will expose an API that will be called from the flower identification application.', input_specification=[ModelIODescriptor(name='flower-picture', description='Path to the picture of the flower taken at the garden', type='String', expected_values='String corresponding to a valid path to a picture in PNG format')], output_specification=[ModelIODescriptor(name='flower-number-for-lookup', description='Number of the flower identified in the picture, which is used as a lookup number for a table that contains the identified flower information. This table is derived from the training data.', type='Integer', expected_values='Either flower number between 0 and 102, or -1 to indicate that it could not identify the flower.')], production_compute_resources=ModelResourcesDescriptor(cpu='1', gpu='0', memory='512 MB', storage='150 MB')), system_requirements=[QASDescriptor(identifier='default.card-qas_001', quality='Fairness', stimulus='The model receives a picture taken at the garden', source='the Garden Buddy application', environment='normal operations', response='Regardless of the location in the garden, the model can correctly identify the correct flowers', measure='at least 90% of the time'), QASDescriptor(identifier='default.card-qas_002', quality='Robustness', stimulus='The model receives a picture taken at the garden, and it is a bit blurry. ImageMagick will be used with different levels of blur introduced to the origional flower test data set to simulate the operational images taken', source='the by the Garden Buddy application', environment='normal operations', response='The model successfully identifies flowers', measure='at the same rate as non-blurry images, as measured using the Wilcoxon Rank-Sum test, with significance at p-value <=0.05.'), QASDescriptor(identifier='default.card-qas_003', quality='Resilience', stimulus='The model receives a picture taken at the garden, and it is a bit blurry. ImageMagick will be used with different channel loss introduced to the origional flower test data set to simulate the operational images taken', source='the Garden Buddy application ', environment='normal operations. These devices are known to sometimes lose a channel (i.e., RGB channel)', response='The model successfully identifies flowers', measure='at the same rate as full images, as measured using the Wilcoxon Rank-Sum test, with significance at p-value <=0.05.'), QASDescriptor(identifier='default.card-qas_004', quality='Resource  Utilization', stimulus='The model running on the loaned device receives pictures taken at the garden', source='the flower identification application', environment='normal operations. The loaned devices are small, inexpensive devices with limited CPU power, as well as limited memory and disk space (512 MB and 150 MB, respectively)', response='The model executes on the loaned device', measure='without any errors due to unavailable resources'), QASDescriptor(identifier='default.card-qas_005', quality='Understandability', stimulus='The model receives a picture taken at the garden', source='the Garden Buddy application', environment='normal operations', response='The application indicates main features that were used to recognize the flower, as part of the educational experience.', measure='The app displays the original image highlighting the most informative features in flower identification, in addition to the flower name'), QASDescriptor(identifier='default.card-qas_006', quality='Functional Correctness', stimulus='The model receives a picture taken at the garden', source='Garden Buddy application', environment='normal operations', response='The model identifies the flower correctly', measure='with an accurayc of at least 90%'), QASDescriptor(identifier='default.card-qas_007', quality='Functional Correctness', stimulus='The model receives a picture taken at the garden', source='Garden Biddy application', environment='normal operations', response='Model correctly processes inputs and produces outputs', measure='according to established input and output specifications without exceptions'), QASDescriptor(identifier='default.card-qas_008', quality='Resilience', stimulus='The ML pipeline receives a picture taken at the garden that does not conform to the input specification', source='the Garden Buddy application', environment='normal operations', response='The model does not process the input', measure='and instead the ML pipeline produces -99 as the output and creates a log entry with the tag \"Model - Input Validation Error - <Input>, where <Input> is the original input.'), QASDescriptor(identifier='default.card-qas_009', quality='Analyzability', stimulus='The ML pipeline receives a picture that corresponds to an OOD input', source='the Garden Buddy application', environment='normal operations', response='The model will process the input ', measure='and the ML pipeline will create a log entry with the tag \"Model - Input OOD Error - <Input>, where <Input> is the original input'), QASDescriptor(identifier='default.card-qas_010', quality='Monitorability', stimulus='The ML pipeline detects an output distribution change', source='the output produced by the model', environment='normal operations', response='The ML pipeline will create a log entry', measure='with the tag \"Model - Output Confidence Error - <Output>, where <Output> is the output produced by the model that triggered the condition'), QASDescriptor(identifier='default.card-qas_011', quality='Time  Behavior', stimulus='Model running on the loaned device receives a picture', source='the Garden Buddy application', environment='normal operations', response='The time for the model to return an output', measure='is no more than two seconds'), QASDescriptor(identifier='default.card-qas_012', quality='Repeatability', stimulus='The model receives a picture taken at the garden, simulated by using the test data set,', source='the Garden Buddy application', environment='normal operation', response='The results over 50 test data sets, each with 500 randomly selected test samples', measure='will be compared using Kruskal-Wallis test will be used to evaluate if similarity of class of model results, with p<0.05 '), QASDescriptor(identifier='default.card-qas_013', quality='Reproducibility', stimulus='The ML component will periodically need to be retrained in which 10 sampled training data sets will be used to generate a new trained ML component,  ', source='an automated, identicall retraining process', environment='an automated, identicall retraining process', response='The performance of the model, as measured on the same test data set,', measure='using a Friedman test will be used to evaluate if similarity of class of model results, with p<0.05 '), QASDescriptor(identifier='default.card-qas_014', quality='Domain  Adaptability', stimulus='The Garden Buddy application may be used in a VR environment, and as such the ML component may receive synthetic flower images', source='the Garden Buddy application', environment='normal operation', response='Comparing the results of the application on the origional flower test data set and the new synthetic test data set,', measure='should show no signifigant differences in performance on performance will be assessed using ANOVA on each label set, with significance at p-value < 0.05 '), QASDescriptor(identifier='default.card-qas_015', quality='Testability', stimulus='ML component will transition from the development environment through integration with the operational ML enabled system', source='Conclusion of development activities', environment='into the operational environment', response='The new ML component, post integrated into the ML-enabled operational system', measure='should have test set results differ by less than 0.25% when comparing results to those obtained in the development environment. '), QASDescriptor(identifier='default.card-qas_016', quality='Understandability', stimulus='A new developer is joining the Garden Buddy team', source='outside the organiation', environment='development', response='The implementation and design choices are easily understood by a new developer after reading the code and documentation', measure='after 2 person/days'), QASDescriptor(identifier='default.card-qas_017', quality='Maintainability', stimulus='A new flower is introduced into the garden', source='the garden staff updating the garden and hosting traveling botanical exhibits', environment='during run time', response='A new trained ML component, trained on updated training data and number of output labels,', measure='will be available no later than 8 hours after the development team is notified.'), QASDescriptor(identifier='default.card-qas_018', quality='Modifiability', stimulus='The need for the app to run with a new input format for the ML component', source='the operations/maintenance team needs to changing input data processing pipelines as a new device type is used for the Garden Buddy app ', environment='normal operation', response=\"The new sensor's data input  processing pipeline is to replace the old input data processing pipeline\", measure='and the total effort involved is less than 4 hours of operations staff time.'), QASDescriptor(identifier='default.card-qas_019', quality='Replaceability', stimulus='The team needs to quickly change the ML model being run by the application', source='as an advancement in the field has occurred that necessitates an update in the algorithm used to generate the ML component', environment='normal operation', response='The model switch change over is made ', measure=\"and the total effort involved is less than 16 hours of development and operation teams' time\"), QASDescriptor(identifier='default.card-qas_020', quality='Retrainability', stimulus='The ML component needs to be retrained', source='as an environment necessitating a new model has occured ', environment='normal operation', response='The development team kicks off the ML model retraining process', measure='and the total personnel time devoted to kick off, monitoring and checking the output of the retraining process is no more than 1 hour. '), QASDescriptor(identifier='default.card-qas_021', quality='Reusability', stimulus='The decision to produce a new app, with only changing who it is marketed to, user interface, and platform is issued', source='stakeholders', environment='development time', response='The existing garden buddy ML component is used in the new app', measure='with limited changes to the ML component code were needed to integrate the ML component into the new app, totaling no more than 1/2 a development day. ')]), test_suite_id='suite.default', test_suite=TestSuiteModel(artifact_type=<ArtifactType.TEST_SUITE: 'suite'>, test_cases=[TestCaseModel(identifier='accuracy across gardens', goal='Check if model performs well accross different populations', qas_list=['default.card-qas_001'], measurement=None, validator=ValidatorModel(bool_exp='gASVfgMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgWARj/EAIo/pRLAUsASwBLAUsESxNDbJUBlwB0AQAAAAAAAAAAiAFmAWQBhAh8AGoCAAAAAAAAAAAAAAAAAAAAAAAARACrAAAAAAAAAKsBAAAAAAAAdAUAAAAAAAAAAHwAagIAAAAAAAAAAAAAAAAAAAAAAACrAQAAAAAAAGsoAABTAJROaAQoQwIKAZRLAUsASwBLAksDSzNDKJUBSwABAJcAfABdCQAAfQF8AYkCa1wAAJYBlwEBAIwLBAB5AK0DdwGUToWUKYwCLjCUjAFnlIaUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCTxnZW5leHByPpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6USxJDGfjoAPiAAPAAAjoG2SArmDGIAYhZjQ6hC/mUQwSDDxIBlIwJdGhyZXNob2xklIWUKXSUUpSGlIwDc3VtlIwFYXJyYXmUjANsZW6Uh5SMBXZhbHVllIWUaA2MCDxsYW1iZGE+lIwzYWxsX2FjY3VyYWNpZXNfbW9yZV9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsSQyz4gAC0Y/MAAjoG2CAlpwuiC/MDAjoG8wACNwbkCQyIVY9biVvTCRnyBQI3GpRDAJRoEoWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaB51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaDGMB3NldGF0dHKUk5SHlFKUaCeMDWNlbGxfY29udGVudHOURz/szMzMzMzNh5RSMC4=', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.9', failure='One or more accuracies are below threshold 0.9', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.9'])), TestCaseModel(identifier='ranksums blur2x8', goal='Check blur and noise for 2x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur5x8', goal='Check blur and noise for 5x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur0x8', goal='Check blur and noise for 0x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='effect of blur across families', goal='Check consistency in families', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/Nz1eDFiZ94eUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.0003546099290780142'], success='All p-values are equal to or over threshold 0.0003546099290780142', failure='One or more p-values are below threshold 0.0003546099290780142', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.0003546099290780142'])), TestCaseModel(identifier='ranksums channel loss R', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss G', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss B', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='model size', goal='Check storage consumption', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASV5wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrAgAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwgUmVhbC5sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US21DFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEuWjAlwaW50LnV0aWyUjA5Vbml0c0NvbnRhaW5lcpSTlCmBlGgzjAV1ZGljdJSTlCmBlIwIbWVnYWJ5dGWUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda real: (real.get_value_w_units() < threshold_w_unit)', thresholds=[], success='Real magnitude is less than threshold 150 megabyte', failure='Real magnitude exceeds threshold 150 megabyte', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='less_than', creator_args=['150', 'megabyte'])), TestCaseModel(identifier='predicting memory', goal='Check memory used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVNAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDYXZnlIWUjAVzdGF0c5SFlIyHL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvbWVtb3J5L2xvY2FsX3Byb2Nlc3NfbWVtb3J5X2NvbnN1bXB0aW9uLnB5lIwIPGxhbWJkYT6UjEBNZW1vcnlTdGF0aXN0aWNzLmF2ZXJhZ2VfY29uc3VtcHRpb25fbGVzc190aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEuMQw/4gACYJZ8pmSnQJjbSGjaUaAWMEHRocmVzaG9sZF93X3VuaXSUhZQpdJRSlGNtbHRlLm1lYXN1cmVtZW50Lm1lbW9yeS5sb2NhbF9wcm9jZXNzX21lbW9yeV9jb25zdW1wdGlvbgpfX2RpY3RfXwpoDU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaA51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaCGMB3NldGF0dHKUk5SHlFKUaBeMDWNlbGxfY29udGVudHOUjARwaW50lIwSX3VucGlja2xlX3F1YW50aXR5lJOUjBpwaW50LmZhY2V0cy5wbGFpbi5xdWFudGl0eZSMDVBsYWluUXVhbnRpdHmUk5RHQIAAAAAAAACMCXBpbnQudXRpbJSMDlVuaXRzQ29udGFpbmVylJOUKYGUaDOMBXVkaWN0lJOUKYGUjAhtZWdhYnl0ZZRLAXNLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda stats: (stats.avg < threshold_w_unit)', thresholds=['512.0 megabyte'], success='Average consumption below threshold 512.0 megabyte', failure='Average consumption exceeds threshold 512.0 megabyte', info=None, input_types=['mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics'], creator_entity='mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics', creator_function='average_consumption_less_than', creator_args=['512.0', 'megabyte'])), TestCaseModel(identifier='predicting cpu', goal='Check cpu % used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVIAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDbWF4lIWUjAVzdGF0c5SFlIyBL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvY3B1L2xvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uLnB5lIwIPGxhbWJkYT6UjDlDUFVTdGF0aXN0aWNzLm1heF91dGlsaXphdGlvbl9sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US3dDD/iAAJglnymZKdAmNtIaNpRoBYwQdGhyZXNob2xkX3dfdW5pdJSFlCl0lFKUY21sdGUubWVhc3VyZW1lbnQuY3B1LmxvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEdAPgAAAAAAAIwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZSMB3BlcmNlbnSUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda stats: (stats.max < threshold_w_unit)', thresholds=['30.0 percent'], success='Maximum utilization below threshold 30.00 percent', failure='Maximum utilization exceeds threshold 30.00 percent', info=None, input_types=['mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics'], creator_entity='mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics', creator_function='max_utilization_less_than', creator_args=['30.0', 'percent'])), TestCaseModel(identifier='overall model accuracy', goal='Measure the overall accuracy of your end to end pipeline', qas_list=['default.card-qas_006'], measurement=None, validator=ValidatorModel(bool_exp='gASV4wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrRAAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwjUmVhbC5ncmVhdGVyX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US5tDFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEc/7MzMzMzMzYwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZRLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda real: (real.get_value_w_units() > threshold_w_unit)', thresholds=[], success='Real magnitude is greater than threshold 0.9', failure='Real magnitude is below threshold 0.9', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='greater_than', creator_args=['0.9', 'None'])), TestCaseModel(identifier='repeated results sampling', goal='Repeatedly sampling results gives same results', qas_list=['default.card-qas_012'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='repeated training on training samples', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_013'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='running in new domain', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_014'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/qZmZmZmZmoeUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.05'], success='All p-values are equal to or over threshold 0.05', failure='One or more p-values are below threshold 0.05', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.05'])), TestCaseModel(identifier='test results from dev and op env', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_015'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect the alignment of results for no more than 0.25% difference.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect the alignment of results for no more than 0.25% difference.'])), TestCaseModel(identifier='understanding design choices', goal='understanding design and implementation choices', qas_list=['default.card-qas_016'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect projrct code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect projrct code and documentation.'])), TestCaseModel(identifier='keep ML component up to date', goal='keep trained ML component up to date with op environment changes', qas_list=['default.card-qas_017'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 8hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 8hrs.'])), TestCaseModel(identifier='update data pipelines', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_018'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.'])), TestCaseModel(identifier='update ML training algorithm', goal='update ML component training algorithm', qas_list=['default.card-qas_019'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate train time less than 16hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate train time less than 16hrs.'])), TestCaseModel(identifier='retrain ML model', goal='update ML component training algorithm', qas_list=['default.card-qas_020'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Model takes less than 1 hr to retrain.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Model takes less than 1 hr to retrain.'])), TestCaseModel(identifier='reuse ML component', goal='reuse ML component in new app', qas_list=['default.card-qas_021'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.']))]), test_results_id='results.default', test_results=TestResultsModel(artifact_type=<ArtifactType.TEST_RESULTS: 'results'>, test_suite_id='suite.default', test_suite=TestSuiteModel(artifact_type=<ArtifactType.TEST_SUITE: 'suite'>, test_cases=[TestCaseModel(identifier='accuracy across gardens', goal='Check if model performs well accross different populations', qas_list=['default.card-qas_001'], measurement=None, validator=ValidatorModel(bool_exp='gASVfgMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgWARj/EAIo/pRLAUsASwBLAUsESxNDbJUBlwB0AQAAAAAAAAAAiAFmAWQBhAh8AGoCAAAAAAAAAAAAAAAAAAAAAAAARACrAAAAAAAAAKsBAAAAAAAAdAUAAAAAAAAAAHwAagIAAAAAAAAAAAAAAAAAAAAAAACrAQAAAAAAAGsoAABTAJROaAQoQwIKAZRLAUsASwBLAksDSzNDKJUBSwABAJcAfABdCQAAfQF8AYkCa1wAAJYBlwEBAIwLBAB5AK0DdwGUToWUKYwCLjCUjAFnlIaUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCTxnZW5leHByPpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6USxJDGfjoAPiAAPAAAjoG2SArmDGIAYhZjQ6hC/mUQwSDDxIBlIwJdGhyZXNob2xklIWUKXSUUpSGlIwDc3VtlIwFYXJyYXmUjANsZW6Uh5SMBXZhbHVllIWUaA2MCDxsYW1iZGE+lIwzYWxsX2FjY3VyYWNpZXNfbW9yZV9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsSQyz4gAC0Y/MAAjoG2CAlpwuiC/MDAjoG8wACNwbkCQyIVY9biVvTCRnyBQI3GpRDAJRoEoWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaB51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaDGMB3NldGF0dHKUk5SHlFKUaCeMDWNlbGxfY29udGVudHOURz/szMzMzMzNh5RSMC4=', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.9', failure='One or more accuracies are below threshold 0.9', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.9'])), TestCaseModel(identifier='ranksums blur2x8', goal='Check blur and noise for 2x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur5x8', goal='Check blur and noise for 5x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur0x8', goal='Check blur and noise for 0x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='effect of blur across families', goal='Check consistency in families', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/Nz1eDFiZ94eUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.0003546099290780142'], success='All p-values are equal to or over threshold 0.0003546099290780142', failure='One or more p-values are below threshold 0.0003546099290780142', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.0003546099290780142'])), TestCaseModel(identifier='ranksums channel loss R', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss G', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss B', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='model size', goal='Check storage consumption', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASV5wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrAgAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwgUmVhbC5sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US21DFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEuWjAlwaW50LnV0aWyUjA5Vbml0c0NvbnRhaW5lcpSTlCmBlGgzjAV1ZGljdJSTlCmBlIwIbWVnYWJ5dGWUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda real: (real.get_value_w_units() < threshold_w_unit)', thresholds=[], success='Real magnitude is less than threshold 150 megabyte', failure='Real magnitude exceeds threshold 150 megabyte', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='less_than', creator_args=['150', 'megabyte'])), TestCaseModel(identifier='predicting memory', goal='Check memory used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVNAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDYXZnlIWUjAVzdGF0c5SFlIyHL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvbWVtb3J5L2xvY2FsX3Byb2Nlc3NfbWVtb3J5X2NvbnN1bXB0aW9uLnB5lIwIPGxhbWJkYT6UjEBNZW1vcnlTdGF0aXN0aWNzLmF2ZXJhZ2VfY29uc3VtcHRpb25fbGVzc190aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEuMQw/4gACYJZ8pmSnQJjbSGjaUaAWMEHRocmVzaG9sZF93X3VuaXSUhZQpdJRSlGNtbHRlLm1lYXN1cmVtZW50Lm1lbW9yeS5sb2NhbF9wcm9jZXNzX21lbW9yeV9jb25zdW1wdGlvbgpfX2RpY3RfXwpoDU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaA51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaCGMB3NldGF0dHKUk5SHlFKUaBeMDWNlbGxfY29udGVudHOUjARwaW50lIwSX3VucGlja2xlX3F1YW50aXR5lJOUjBpwaW50LmZhY2V0cy5wbGFpbi5xdWFudGl0eZSMDVBsYWluUXVhbnRpdHmUk5RHQIAAAAAAAACMCXBpbnQudXRpbJSMDlVuaXRzQ29udGFpbmVylJOUKYGUaDOMBXVkaWN0lJOUKYGUjAhtZWdhYnl0ZZRLAXNLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda stats: (stats.avg < threshold_w_unit)', thresholds=['512.0 megabyte'], success='Average consumption below threshold 512.0 megabyte', failure='Average consumption exceeds threshold 512.0 megabyte', info=None, input_types=['mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics'], creator_entity='mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics', creator_function='average_consumption_less_than', creator_args=['512.0', 'megabyte'])), TestCaseModel(identifier='predicting cpu', goal='Check cpu % used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVIAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDbWF4lIWUjAVzdGF0c5SFlIyBL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvY3B1L2xvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uLnB5lIwIPGxhbWJkYT6UjDlDUFVTdGF0aXN0aWNzLm1heF91dGlsaXphdGlvbl9sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US3dDD/iAAJglnymZKdAmNtIaNpRoBYwQdGhyZXNob2xkX3dfdW5pdJSFlCl0lFKUY21sdGUubWVhc3VyZW1lbnQuY3B1LmxvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEdAPgAAAAAAAIwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZSMB3BlcmNlbnSUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda stats: (stats.max < threshold_w_unit)', thresholds=['30.0 percent'], success='Maximum utilization below threshold 30.00 percent', failure='Maximum utilization exceeds threshold 30.00 percent', info=None, input_types=['mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics'], creator_entity='mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics', creator_function='max_utilization_less_than', creator_args=['30.0', 'percent'])), TestCaseModel(identifier='overall model accuracy', goal='Measure the overall accuracy of your end to end pipeline', qas_list=['default.card-qas_006'], measurement=None, validator=ValidatorModel(bool_exp='gASV4wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrRAAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwjUmVhbC5ncmVhdGVyX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US5tDFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEc/7MzMzMzMzYwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZRLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda real: (real.get_value_w_units() > threshold_w_unit)', thresholds=[], success='Real magnitude is greater than threshold 0.9', failure='Real magnitude is below threshold 0.9', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='greater_than', creator_args=['0.9', 'None'])), TestCaseModel(identifier='repeated results sampling', goal='Repeatedly sampling results gives same results', qas_list=['default.card-qas_012'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='repeated training on training samples', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_013'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='running in new domain', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_014'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/qZmZmZmZmoeUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.05'], success='All p-values are equal to or over threshold 0.05', failure='One or more p-values are below threshold 0.05', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.05'])), TestCaseModel(identifier='test results from dev and op env', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_015'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect the alignment of results for no more than 0.25% difference.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect the alignment of results for no more than 0.25% difference.'])), TestCaseModel(identifier='understanding design choices', goal='understanding design and implementation choices', qas_list=['default.card-qas_016'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect projrct code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect projrct code and documentation.'])), TestCaseModel(identifier='keep ML component up to date', goal='keep trained ML component up to date with op environment changes', qas_list=['default.card-qas_017'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 8hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 8hrs.'])), TestCaseModel(identifier='update data pipelines', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_018'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.'])), TestCaseModel(identifier='update ML training algorithm', goal='update ML component training algorithm', qas_list=['default.card-qas_019'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate train time less than 16hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate train time less than 16hrs.'])), TestCaseModel(identifier='retrain ML model', goal='update ML component training algorithm', qas_list=['default.card-qas_020'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Model takes less than 1 hr to retrain.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Model takes less than 1 hr to retrain.'])), TestCaseModel(identifier='reuse ML component', goal='reuse ML component in new app', qas_list=['default.card-qas_021'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.']))]), results={'accuracy across gardens': ResultModel(type='Success', message='All accuracies are equal to or over threshold 0.9 - values: [\"[0.946, 0.956, 0.913]\"]', evidence_metadata=EvidenceMetadata(test_case_id='accuracy across gardens', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.calculate_model_performance_acc'}))), 'ranksums blur2x8': ResultModel(type='Success', message='P-Value is greater or equal to 0.016666666666666666 - values: [\"[0.07946178703316073, 0.9366653249981838]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums blur2x8', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'ranksums blur5x8': ResultModel(type='Success', message='P-Value is greater or equal to 0.016666666666666666 - values: [\"[0.4032389192727559, 0.6867724711187835]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums blur5x8', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'ranksums blur0x8': ResultModel(type='Failure', message='P-Value is less than threshold 0.016666666666666666 - values: [\"[2.908064206049404, 0.003636736621916332]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums blur0x8', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'effect of blur across families': ResultModel(type='Success', message='All p-values are equal to or over threshold 0.0003546099290780142 - values: [\"{\\'array\\': [{\\'evidence.ranksums Order Apiales-Apiales blurdelta_2x8\\': [0.0, 1.0]}, {\\'evidence.ranksums Order Apiales-Alismatales blurdelta_2x8\\': [0.0, 1.0]}, {\\'evidence.ranksums Order Apiales-Asterales blurdelta_2x8\\': [-0.1091089451179962, 0.9131160800723744]}, {\\'evidence.ranksums Order Apiales-Erica...\"]', evidence_metadata=EvidenceMetadata(test_case_id='effect of blur across families', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', additional_data={'function': '__main__.calculate_multiple_ranksums'}))), 'ranksums channel loss R': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[0.8052918417241214, 0.4206512885130542]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums channel loss R', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'ranksums channel loss G': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[0.6356942962652858, 0.5249756947411197]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums channel loss G', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'ranksums channel loss B': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[0.7673399434396266, 0.44287942555285786]\"]', evidence_metadata=EvidenceMetadata(test_case_id='ranksums channel loss B', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.ranksums'}))), 'model size': ResultModel(type='Success', message='Real magnitude is less than threshold 150 megabyte - values: [\"13.0 byte\"]', evidence_metadata=EvidenceMetadata(test_case_id='model size', measurement=MeasurementMetadata(measurement_class='mlte.measurement.storage.local_object_size.LocalObjectSize', output_class='mlte.evidence.types.real.Real', additional_data={}))), 'predicting memory': ResultModel(type='Success', message='Average consumption below threshold 512.0 megabyte - values: [\"Average: 251292 kilobyte\\\\nMinimum: 32 kilobyte\\\\nMaximum: 437792 kilobyte\"]', evidence_metadata=EvidenceMetadata(test_case_id='predicting memory', measurement=MeasurementMetadata(measurement_class='mlte.measurement.memory.local_process_memory_consumption.LocalProcessMemoryConsumption', output_class='mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics', additional_data={}))), 'predicting cpu': ResultModel(type='Success', message='Maximum utilization below threshold 30.00 percent - values: [\"Average: 1.83 percent\\\\nMinimum: 0.00 percent\\\\nMaximum: 5.40 percent\"]', evidence_metadata=EvidenceMetadata(test_case_id='predicting cpu', measurement=MeasurementMetadata(measurement_class='mlte.measurement.cpu.local_process_cpu_utilization.LocalProcessCPUUtilization', output_class='mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics', additional_data={}))), 'overall model accuracy': ResultModel(type='Success', message='Real magnitude is greater than threshold 0.9 - values: [\"0.947265625\"]', evidence_metadata=EvidenceMetadata(test_case_id='overall model accuracy', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.real.Real', additional_data={'function': '__main__.calculate_model_performance_basic_acc'}))), 'repeated results sampling': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[38.903978816768415, 0.8487546281441082]\"]', evidence_metadata=EvidenceMetadata(test_case_id='repeated results sampling', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.kruskal'}))), 'repeated training on training samples': ResultModel(type='Success', message='P-Value is greater or equal to 0.05 - values: [\"[1.3575418994429564, 0.9980720828075595]\"]', evidence_metadata=EvidenceMetadata(test_case_id='repeated training on training samples', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': 'scipy.stats._stats_py.friedmanchisquare'}))), 'running in new domain': ResultModel(type='Failure', message='One or more p-values are below threshold 0.05 - values: [\"{\\'array\\': [{\\'evidence.label 0\\': [35.98058233033483, 7.269476178488252e-06]}, {\\'evidence.label 1\\': [1.2823981355178078, 0.2715430886274718]}, {\\'evidence.label 2\\': [4.059687454037485, 0.05829167989491706]}, {\\'evidence.label 3\\': [0.000382861952999998, 0.9845827951232068]}, {\\'evidence.label 4\\': [26.6332...\"]', evidence_metadata=EvidenceMetadata(test_case_id='running in new domain', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', additional_data={'function': '__main__.calculate_multiple_anova'}))), 'test results from dev and op env': ResultModel(type='Success', message='Manually validated: Visual inspection confirms dresults are only 0.2% different (original message: Inspect the alignment of results for no more than 0.25% difference.)', evidence_metadata=None), 'understanding design choices': ResultModel(type='Success', message='Manually validated: An outside developer was able to understand the code and documenation in 2 person days (original message: Inspect projrct code and documentation.)', evidence_metadata=None), 'keep ML component up to date': ResultModel(type='Success', message='Manually validated: A new ML model, trained on updated training data and using updated lables, took 4 hrs to produce (original message: Validate work time less than 8hrs.)', evidence_metadata=None), 'update data pipelines': ResultModel(type='Failure', message='Manually validated: Updating the the model to use a new sensor took 5 hours (original message: Validate work time less than 4hrs.)', evidence_metadata=None), 'update ML training algorithm': ResultModel(type='Failure', message='Manually validated: A new algorithm was used to generate a newly retrained model in 4 person days (original message: Validate train time less than 16hrs.)', evidence_metadata=None), 'retrain ML model': ResultModel(type='Success', message='Manually validated: The model was retrained on the same training data and labels with the same algorithm in 45 minutes (original message: Model takes less than 1 hr to retrain.)', evidence_metadata=None), 'reuse ML component': ResultModel(type='Success', message='Manually validated: The ML component was successfully reused in the new app with less than 1/2 day development time (original message: Validate work time less than 4hrs.)', evidence_metadata=None)}), comments=[CommentDescriptor(content='This model should not be used for nefarious purposes.')]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlte.report.artifact import (\n",
    "    Report,\n",
    "    CommentDescriptor,\n",
    ")\n",
    "\n",
    "# Create a report with the default NegotiationCard, TestSuite and TestResults in this store.\n",
    "report = Report(\n",
    "    comments=[\n",
    "        CommentDescriptor(\n",
    "            content=\"This model should not be used for nefarious purposes.\"\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "report.save(force=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
