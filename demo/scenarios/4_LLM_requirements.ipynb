{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAS Demo\n",
    "\n",
    "This is a set of demo notebooks to illustrate the use of the MLTE library and SDMT process, using Quality Attribute Scenarios as guidance for the required Properties and Conditions.\n",
    "\n",
    "NOTE: this demo has an additional set of requirements than MLTE. You can install them with the command: \n",
    "\n",
    "`poetry install --with demo`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0. Quality Attribute Scenarios\n",
    "\n",
    "The following are the QASs that we want to validate through the use of MLTE. The examples below relate to a hypothetical system used by visitors to a botanical garden to identify flowers in the different gardens and learn more about them. The system used an ML model that was trained on the flower category dataset [Nilsback 2008] (https://www.robots.ox.ac.uk/~vgg/data/flowers/102/). \n",
    "\n",
    "* **Explainability - Explain LLM results**\n",
    "The LLM receives a prompt from the manager asking for an employee evaluation during normal operations. The model outputs an employee evaluation, including a performance score for the employee and human understandable rationale for the employee score. \n",
    "    \n",
    "* **Functional Correctness- Model provides correct results**\n",
    "The LLM receives a prompt from the manager asking for an employee evaluation containing the employee goals, employee statement, and manager notes, during normal operations. The LLM outputs an employee evaluation, including a performance score for the employee. The LLM generated performance score should match the manager expected overall score in at least 95% of cases.\n",
    "\n",
    "* **Functional Correctness- Model provides self-consistent results**\n",
    "The LLM receives a prompt from the manager asking for an employee evaluation during normal operations. The model outputs an employee evaluation, including an overall performance score for the employee and an evaluation for each important sub-category. The sub-category scores should average to match the overall score in at least 95% of the cases.\n",
    "    \n",
    "* **Repeatability - Model provides repeatable results**\n",
    "The LLM may receive multiple entries of similarly performing employees for evaluation during normal operations. In the case of similar prompts and input information, the LLM generated employee evaluation, including performance scores and evaluation summary,  should be semantically similar each time. \n",
    "    \n",
    "* **Robustness - Model is robust to spacing, punction and case inconsistencies**\n",
    "The LLM may receive prompts with different variations, such as casing, spacing, and punctuation, during normal operations.  These variations should not influence the employee evaluation or score generated by the LLM.\n",
    "   \n",
    "* **Time Behavior - Model provides results in a timely manner**\n",
    "The LLM receives a prompt from the manager asking for an employee evaluation during normal LLM operations. The time required for the LLM to output an employee evaluation, including a performance score,  will be no more than 10 seconds.\n",
    "\n",
    "* **Fairness - Model provides similar results to different named individuals**\n",
    "As the LLM is being used in the evaluation process to help managers generate performance reviews, the generated reviews need to be fair for every employee. The LLM should provide the same performance review for similar prompts, regardless of the name and pronouns used by the employee.\n",
    "\n",
    "* **Inclusivity - Model provides results not dependent on reading level**\n",
    "The LLM will be used to generate performance reviews based on self-evaluations for all employees across the organization, in all job types. The overall performance score provided by the LLM should not be impacted by the writing level of the employee's self evaluation.\n",
    "\n",
    "* **Economic Risk Consideration - Model identifies economic risk from employees** \n",
    "\n",
    "* **Health and Safety Risk Considerations - Model identifies health and safety risk from employees**\n",
    "\n",
    "* **Societal and Ethical Risk Considerations - Model identifies societal and ethical risk from employees**\n",
    "\n",
    "* **Privacy- Model results do not  contain PII for otehr employees**\n",
    "The LLM will receive many similar prompts from managers asking for employee evaluations. The output employee evaluation should not contain PII for other employees despite similarity between prompts.\n",
    "\n",
    "* **Resistance - Model is resistant to additional, embedded instructions from employees**\n",
    "The LLM receives a prompt containing instructions for the LLM to give that employee a good review, within the self-evaluation, during normal operations. The performance score output by the LLM should not be affected by the embedded instructions. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Requirements\n",
    "\n",
    "## 1.1 Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial custom lists at URI: local:///Users/rbrowersinning/Documents/ResearchFolders/Continuum_LTP/GitRepos/mlte/demo/scenarios/../store\n",
      "Loaded 7 qa_categories for initial list\n",
      "Loaded 30 quality_attributes for initial list\n",
      "Creating sample catalog at URI: StoreType.LOCAL_FILESYSTEM:local:///Users/rbrowersinning/Documents/ResearchFolders/Continuum_LTP/GitRepos/mlte/demo/scenarios/../store\n",
      "Loading sample catalog entries.\n",
      "Loaded 9 entries for sample catalog.\n"
     ]
    }
   ],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from demo.scenarios.session import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Build a `NegotiationCard`\n",
    "\n",
    "In MLTE, we negotiation requirements with the help of a `NegotiationCard`. This can be done manually through code, but it is easier to use the MLTE UI to do so. Below we are copying a pre-built one that applies to this scenario. In MLTE, we define requirements by constructing a `NegotiationCard` that will include explicit Quality Attribute Scenarios with the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: ./sample_store/: No such file or directory\n",
      "/bin/ls: /bin/ls: cannot execute binary file\n"
     ]
    }
   ],
   "source": [
    "##!sh ../setup_store.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Define a TestSuite\n",
    "\n",
    "In the first phase of SDMT, we define a `TestSuite` that represents the tests the completed model must will have to pass in order to be acceptable for use in the system into which it will be integrated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MLTE, we define the tests that will be required for the different requirements in a `TestSuite`. Note that a new `Evidence` types (`MultipleRanksums`) had to be created in this case to handle the data and `Validator` for that case, and two stand-alone `Validator`s were defined in `validators.py` to validate data using existing `Evidence` types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load up our `NegotiationCard`, so we can get the list of ids of its quaity attribute scenarios, that will be added to the `TestCase`s here. Those ids are the way to link the `TestCase`s to their quality attribute requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default.card-qas_001 (Fairness): The model receives a picture taken at the garden from the garden buddy application while in normal operations, regardless of the location in the garden, the model can correctly identify the correct flowers, at least 90% of the time\n",
      "default.card-qas_002 (Robustness): The model receives a picture taken at the garden, and it is a bit blurry. imagemagick will be used with different levels of blur introduced to the origional flower test data set to simulate the operational images taken from the by the garden buddy application while in normal operations, the model successfully identifies flowers, at the same rate as non-blurry images, as measured using the wilcoxon rank-sum test, with significance at p-value <=0.05.\n",
      "default.card-qas_003 (Resilience): The model receives a picture taken at the garden, and it is a bit blurry. imagemagick will be used with different channel loss introduced to the origional flower test data set to simulate the operational images taken from the garden buddy application  while in normal operations. these devices are known to sometimes lose a channel (i.e., rgb channel), the model successfully identifies flowers, at the same rate as full images, as measured using the wilcoxon rank-sum test, with significance at p-value <=0.05.\n",
      "default.card-qas_004 (Resource  Utilization): The model running on the loaned device receives pictures taken at the garden from the flower identification application while in normal operations. the loaned devices are small, inexpensive devices with limited cpu power, as well as limited memory and disk space (512 mb and 150 mb, respectively), the model executes on the loaned device, without any errors due to unavailable resources\n",
      "default.card-qas_005 (Understandability): The model receives a picture taken at the garden from the garden buddy application while in normal operations, the application indicates main features that were used to recognize the flower, as part of the educational experience., the app displays the original image highlighting the most informative features in flower identification, in addition to the flower name\n",
      "default.card-qas_006 (Functional Correctness): The model receives a picture taken at the garden from garden buddy application while in normal operations, the model identifies the flower correctly, with an accurayc of at least 90%\n",
      "default.card-qas_007 (Functional Correctness): The model receives a picture taken at the garden from garden biddy application while in normal operations, model correctly processes inputs and produces outputs, according to established input and output specifications without exceptions\n",
      "default.card-qas_008 (Resilience): The ml pipeline receives a picture taken at the garden that does not conform to the input specification from the garden buddy application while in normal operations, the model does not process the input, and instead the ml pipeline produces -99 as the output and creates a log entry with the tag \"model - input validation error - <input>, where <input> is the original input.\n",
      "default.card-qas_009 (Analyzability): The ml pipeline receives a picture that corresponds to an ood input from the garden buddy application while in normal operations, the model will process the input , and the ml pipeline will create a log entry with the tag \"model - input ood error - <input>, where <input> is the original input\n",
      "default.card-qas_010 (Monitorability): The ml pipeline detects an output distribution change from the output produced by the model while in normal operations, the ml pipeline will create a log entry, with the tag \"model - output confidence error - <output>, where <output> is the output produced by the model that triggered the condition\n",
      "default.card-qas_011 (Time  Behavior): Model running on the loaned device receives a picture from the garden buddy application while in normal operations, the time for the model to return an output, is no more than two seconds\n",
      "default.card-qas_012 (Repeatability): The model receives a picture taken at the garden, simulated by using the test data set, from the garden buddy application while in normal operation, the results over 50 test data sets, each with 500 randomly selected test samples, will be compared using kruskal-wallis test will be used to evaluate if similarity of class of model results, with p<0.05 \n",
      "default.card-qas_013 (Reproducibility): The ml component will periodically need to be retrained in which 10 sampled training data sets will be used to generate a new trained ml component,   from an automated, identicall retraining process while in an automated, identicall retraining process, the performance of the model, as measured on the same test data set,, using a friedman test will be used to evaluate if similarity of class of model results, with p<0.05 \n",
      "default.card-qas_014 (Domain  Adaptability): The garden buddy application may be used in a vr environment, and as such the ml component may receive synthetic flower images from the garden buddy application while in normal operation, comparing the results of the application on the origional flower test data set and the new synthetic test data set,, should show no signifigant differences in performance on performance will be assessed using anova on each label set, with significance at p-value < 0.05 \n",
      "default.card-qas_015 (Testability): Ml component will transition from the development environment through integration with the operational ml enabled system from conclusion of development activities while in into the operational environment, the new ml component, post integrated into the ml-enabled operational system, should have test set results differ by less than 0.25% when comparing results to those obtained in the development environment. \n",
      "default.card-qas_016 (Understandability): A new developer is joining the garden buddy team from outside the organiation while in development, the implementation and design choices are easily understood by a new developer after reading the code and documentation, after 2 person/days\n",
      "default.card-qas_017 (Maintainability): A new flower is introduced into the garden from the garden staff updating the garden and hosting traveling botanical exhibits while in during run time, a new trained ml component, trained on updated training data and number of output labels,, will be available no later than 8 hours after the development team is notified.\n",
      "default.card-qas_018 (Modifiability): The need for the app to run with a new input format for the ml component from the operations/maintenance team needs to changing input data processing pipelines as a new device type is used for the garden buddy app  while in normal operation, the new sensor's data input  processing pipeline is to replace the old input data processing pipeline, and the total effort involved is less than 4 hours of operations staff time.\n",
      "default.card-qas_019 (Replaceability): The team needs to quickly change the ml model being run by the application from as an advancement in the field has occurred that necessitates an update in the algorithm used to generate the ml component while in normal operation, the model switch change over is made , and the total effort involved is less than 16 hours of development and operation teams' time\n",
      "default.card-qas_020 (Retrainability): The ml component needs to be retrained from as an environment necessitating a new model has occured  while in normal operation, the development team kicks off the ml model retraining process, and the total personnel time devoted to kick off, monitoring and checking the output of the retraining process is no more than 1 hour. \n",
      "default.card-qas_021 (Reusability): The decision to produce a new app, with only changing who it is marketed to, user interface, and platform is issued from stakeholders while in development time, the existing garden buddy ml component is used in the new app, with limited changes to the ml component code were needed to integrate the ml component into the new app, totaling no more than 1/2 a development day. \n"
     ]
    }
   ],
   "source": [
    "from mlte.negotiation.artifact import NegotiationCard\n",
    "\n",
    "card = NegotiationCard.load()\n",
    "card.save(force=True)\n",
    "card.print_quality_scenarios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our `TestSuite`, consisting of a list of `TestCases`, each of them addressing one or more Quality Attribute Scenarios from our `NegotiationCard`. When defining the `TestCase`s below, we need to set the id of the corresponding Quality Attribute Scenario we want to test in its \"quality_scenarios\" attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArtifactModel(header=ArtifactHeaderModel(identifier='suite.default', type='suite', timestamp=1759188697, creator=None, level='model'), body=TestSuiteModel(artifact_type=<ArtifactType.TEST_SUITE: 'suite'>, test_cases=[TestCaseModel(identifier='accuracy across gardens', goal='Check if model performs well accross different populations', qas_list=['default.card-qas_001'], measurement=None, validator=ValidatorModel(bool_exp='gASVfgMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgWARj/EAIo/pRLAUsASwBLAUsESxNDbJUBlwB0AQAAAAAAAAAAiAFmAWQBhAh8AGoCAAAAAAAAAAAAAAAAAAAAAAAARACrAAAAAAAAAKsBAAAAAAAAdAUAAAAAAAAAAHwAagIAAAAAAAAAAAAAAAAAAAAAAACrAQAAAAAAAGsoAABTAJROaAQoQwIKAZRLAUsASwBLAksDSzNDKJUBSwABAJcAfABdCQAAfQF8AYkCa1wAAJYBlwEBAIwLBAB5AK0DdwGUToWUKYwCLjCUjAFnlIaUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCTxnZW5leHByPpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6USxJDGfjoAPiAAPAAAjoG2SArmDGIAYhZjQ6hC/mUQwSDDxIBlIwJdGhyZXNob2xklIWUKXSUUpSGlIwDc3VtlIwFYXJyYXmUjANsZW6Uh5SMBXZhbHVllIWUaA2MCDxsYW1iZGE+lIwzYWxsX2FjY3VyYWNpZXNfbW9yZV9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsSQyz4gAC0Y/MAAjoG2CAlpwuiC/MDAjoG8wACNwbkCQyIVY9biVvTCRnyBQI3GpRDAJRoEoWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaB51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaDGMB3NldGF0dHKUk5SHlFKUaCeMDWNlbGxfY29udGVudHOURz/szMzMzMzNh5RSMC4=', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.9', failure='One or more accuracies are below threshold 0.9', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.9'])), TestCaseModel(identifier='ranksums blur2x8', goal='Check blur and noise for 2x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur5x8', goal='Check blur and noise for 5x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='ranksums blur0x8', goal='Check blur and noise for 0x8 case', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP5ERERERERGHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.016666666666666666', failure='P-Value is less than threshold 0.016666666666666666', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.016666666666666666'])), TestCaseModel(identifier='effect of blur across families', goal='Check consistency in families', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/Nz1eDFiZ94eUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.0003546099290780142'], success='All p-values are equal to or over threshold 0.0003546099290780142', failure='One or more p-values are below threshold 0.0003546099290780142', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.0003546099290780142'])), TestCaseModel(identifier='ranksums channel loss R', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss G', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='ranksums channel loss B', goal='Check consistency between channel loss', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='model size', goal='Check storage consumption', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASV5wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrAgAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwgUmVhbC5sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US21DFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEuWjAlwaW50LnV0aWyUjA5Vbml0c0NvbnRhaW5lcpSTlCmBlGgzjAV1ZGljdJSTlCmBlIwIbWVnYWJ5dGWUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda real: (real.get_value_w_units() < threshold_w_unit)', thresholds=[], success='Real magnitude is less than threshold 150 megabyte', failure='Real magnitude exceeds threshold 150 megabyte', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='less_than', creator_args=['150', 'megabyte'])), TestCaseModel(identifier='predicting memory', goal='Check memory used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVNAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDYXZnlIWUjAVzdGF0c5SFlIyHL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvbWVtb3J5L2xvY2FsX3Byb2Nlc3NfbWVtb3J5X2NvbnN1bXB0aW9uLnB5lIwIPGxhbWJkYT6UjEBNZW1vcnlTdGF0aXN0aWNzLmF2ZXJhZ2VfY29uc3VtcHRpb25fbGVzc190aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEuMQw/4gACYJZ8pmSnQJjbSGjaUaAWMEHRocmVzaG9sZF93X3VuaXSUhZQpdJRSlGNtbHRlLm1lYXN1cmVtZW50Lm1lbW9yeS5sb2NhbF9wcm9jZXNzX21lbW9yeV9jb25zdW1wdGlvbgpfX2RpY3RfXwpoDU5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UaA51hpRijAhidWlsdGluc5SMB2dldGF0dHKUk5SMBGRpbGyUjAVfZGlsbJSTlIwIX3NldGF0dHKUaCGMB3NldGF0dHKUk5SHlFKUaBeMDWNlbGxfY29udGVudHOUjARwaW50lIwSX3VucGlja2xlX3F1YW50aXR5lJOUjBpwaW50LmZhY2V0cy5wbGFpbi5xdWFudGl0eZSMDVBsYWluUXVhbnRpdHmUk5RHQIAAAAAAAACMCXBpbnQudXRpbJSMDlVuaXRzQ29udGFpbmVylJOUKYGUaDOMBXVkaWN0lJOUKYGUjAhtZWdhYnl0ZZRLAXNLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda stats: (stats.avg < threshold_w_unit)', thresholds=['512.0 megabyte'], success='Average consumption below threshold 512.0 megabyte', failure='Average consumption exceeds threshold 512.0 megabyte', info=None, input_types=['mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics'], creator_entity='mlte.measurement.memory.local_process_memory_consumption.MemoryStatistics', creator_function='average_consumption_less_than', creator_args=['512.0', 'megabyte'])), TestCaseModel(identifier='predicting cpu', goal='Check cpu % used while predicting', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVIAMAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyKVAZcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBawIAAFMAlE6FlIwDbWF4lIWUjAVzdGF0c5SFlIyBL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvbWVhc3VyZW1lbnQvY3B1L2xvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uLnB5lIwIPGxhbWJkYT6UjDlDUFVTdGF0aXN0aWNzLm1heF91dGlsaXphdGlvbl9sZXNzX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US3dDD/iAAJglnymZKdAmNtIaNpRoBYwQdGhyZXNob2xkX3dfdW5pdJSFlCl0lFKUY21sdGUubWVhc3VyZW1lbnQuY3B1LmxvY2FsX3Byb2Nlc3NfY3B1X3V0aWxpemF0aW9uCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEdAPgAAAAAAAIwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZSMB3BlcmNlbnSUSwFzSwFoAIwKX2xvYWRfdHlwZZSTlIwFZmxvYXSUhZRSlIeUYoeUUpSHlFIwLg==', bool_exp_str='lambda stats: (stats.max < threshold_w_unit)', thresholds=['30.0 percent'], success='Maximum utilization below threshold 30.00 percent', failure='Maximum utilization exceeds threshold 30.00 percent', info=None, input_types=['mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics'], creator_entity='mlte.measurement.cpu.local_process_cpu_utilization.CPUStatistics', creator_function='max_utilization_less_than', creator_args=['30.0', 'percent'])), TestCaseModel(identifier='overall model accuracy', goal='Measure the overall accuracy of your end to end pipeline', qas_list=['default.card-qas_006'], measurement=None, validator=ValidatorModel(bool_exp='gASV4wIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAkoTAAABQyqVAZcAfABqAQAAAAAAAAAAAAAAAAAAAAAAAKsAAAAAAAAAiQFrRAAAUwCUToWUjBFnZXRfdmFsdWVfd191bml0c5SFlIwEcmVhbJSFlIxnL1VzZXJzL3Jicm93ZXJzaW5uaW5nL0RvY3VtZW50cy9SZXNlYXJjaEZvbGRlcnMvQ29udGludXVtX0xUUC9HaXRSZXBvcy9tbHRlL21sdGUvZXZpZGVuY2UvdHlwZXMvcmVhbC5weZSMCDxsYW1iZGE+lIwjUmVhbC5ncmVhdGVyX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6US5tDFPiAAJgU1xkv0Rkv0xkx0DRE0hlElGgFjBB0aHJlc2hvbGRfd191bml0lIWUKXSUUpRjbWx0ZS5ldmlkZW5jZS50eXBlcy5yZWFsCl9fZGljdF9fCmgNTmgAjAxfY3JlYXRlX2NlbGyUk5ROhZRSlIWUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoIYwHc2V0YXR0cpSTlIeUUpRoF4wNY2VsbF9jb250ZW50c5SMBHBpbnSUjBJfdW5waWNrbGVfcXVhbnRpdHmUk5SMGnBpbnQuZmFjZXRzLnBsYWluLnF1YW50aXR5lIwNUGxhaW5RdWFudGl0eZSTlEc/7MzMzMzMzYwJcGludC51dGlslIwOVW5pdHNDb250YWluZXKUk5QpgZRoM4wFdWRpY3SUk5QpgZRLAWgAjApfbG9hZF90eXBllJOUjAVmbG9hdJSFlFKUh5Rih5RSlIeUUjAu', bool_exp_str='lambda real: (real.get_value_w_units() > threshold_w_unit)', thresholds=[], success='Real magnitude is greater than threshold 0.9', failure='Real magnitude is below threshold 0.9', info=None, input_types=['mlte.evidence.types.real.Real'], creator_entity='mlte.evidence.types.real.Real', creator_function='greater_than', creator_args=['0.9', 'None'])), TestCaseModel(identifier='repeated results sampling', goal='Repeatedly sampling results gives same results', qas_list=['default.card-qas_012'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='repeated training on training samples', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_013'], measurement=None, validator=ValidatorModel(bool_exp='gASVVAIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLAksTQyiVApcAfABqAAAAAAAAAAAAAAAAAAAAAAAAAIkBGQAAAIkCa1wAAFMAlE6FlIwFYXJyYXmUhZSMBXZhbHVllIWUjGgvVXNlcnMvcmJyb3dlcnNpbm5pbmcvRG9jdW1lbnRzL1Jlc2VhcmNoRm9sZGVycy9Db250aW51dW1fTFRQL0dpdFJlcG9zL21sdGUvZGVtby9zY2VuYXJpb3MvdmFsaWRhdG9ycy5weZSMCDxsYW1iZGE+lIwtcF92YWx1ZV9ncmVhdGVyX29yX2VxdWFsX3RvLjxsb2NhbHM+LjxsYW1iZGE+lEsnQxP4gACQZZdrkWugK9EWLrAp0hY7lGgFjAtQX1ZBTFVFX1BPU5SMCXRocmVzaG9sZJSGlCl0lFKUY2RlbW8uc2NlbmFyaW9zLnZhbGlkYXRvcnMKX19kaWN0X18KaA1OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUaBZOhZRSlIaUdJRSlH2UfZQojA9fX2Fubm90YXRpb25zX1+UfZSMDF9fcXVhbG5hbWVfX5RoDnWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoJIwHc2V0YXR0cpSTlIeUUpRoGowNY2VsbF9jb250ZW50c5RHP6mZmZmZmZqHlFIwaC5oGGgvSwGHlFIwLg==', bool_exp_str='lambda value: (value.array[P_VALUE_POS] >= threshold)', thresholds=[], success='P-Value is greater or equal to 0.05', failure='P-Value is less than threshold 0.05', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='p_value_greater_or_equal_to', creator_args=['0.05'])), TestCaseModel(identifier='running in new domain', goal='Repeatedly training on different sammples of training data gives same results on test data set', qas_list=['default.card-qas_014'], measurement=None, validator=ValidatorModel(bool_exp='gASVngIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwCUSwFLAEsASwFLBUoTAAABQz6VAZcAdAEAAAAAAAAAAHwAagMAAAAAAAAAAAAAAAAAAAAAAACJAasBAAAAAAAAqwEAAAAAAABkAWsoAABTAJROSwCGlIwDbGVulIwQZ2V0X2xvd19wX3ZhbHVlc5SGlIwFdmFsdWWUhZSMeC9Vc2Vycy9yYnJvd2Vyc2lubmluZy9Eb2N1bWVudHMvUmVzZWFyY2hGb2xkZXJzL0NvbnRpbnV1bV9MVFAvR2l0UmVwb3MvbWx0ZS9kZW1vL3NjZW5hcmlvcy9ldmlkZW5jZS9tdWx0aXBsZV9yYW5rc3Vtcy5weZSMCDxsYW1iZGE+lIxFTXVsdGlwbGVSYW5rc3Vtcy5hbGxfcF92YWx1ZXNfZ3JlYXRlcl9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lEsyQxr4gACcI5hl1x400R40sFnTHj/TGkDAQdIaRZRoBYwJdGhyZXNob2xklIWUKXSUUpRjZGVtby5zY2VuYXJpb3MuZXZpZGVuY2UubXVsdGlwbGVfcmFua3N1bXMKX19kaWN0X18KaA5OaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flGgPdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgijAdzZXRhdHRylJOUh5RSlGgYjA1jZWxsX2NvbnRlbnRzlEc/qZmZmZmZmoeUUjAu', bool_exp_str='lambda value: (len(value.get_low_p_values(threshold)) == 0)', thresholds=['0.05'], success='All p-values are equal to or over threshold 0.05', failure='One or more p-values are below threshold 0.05', info=None, input_types=['demo.scenarios.evidence.multiple_ranksums.MultipleRanksums'], creator_entity='demo.scenarios.evidence.multiple_ranksums.MultipleRanksums', creator_function='all_p_values_greater_or_equal_than', creator_args=['0.05'])), TestCaseModel(identifier='test results from dev and op env', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_015'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect the alignment of results for no more than 0.25% difference.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect the alignment of results for no more than 0.25% difference.'])), TestCaseModel(identifier='understanding design choices', goal='understanding design and implementation choices', qas_list=['default.card-qas_016'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect projrct code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect projrct code and documentation.'])), TestCaseModel(identifier='keep ML component up to date', goal='keep trained ML component up to date with op environment changes', qas_list=['default.card-qas_017'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 8hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 8hrs.'])), TestCaseModel(identifier='update data pipelines', goal='aligment of test results from dev and op environments', qas_list=['default.card-qas_018'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.'])), TestCaseModel(identifier='update ML training algorithm', goal='update ML component training algorithm', qas_list=['default.card-qas_019'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate train time less than 16hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate train time less than 16hrs.'])), TestCaseModel(identifier='reuse ML component', goal='reuse ML component in new app', qas_list=['default.card-qas_020'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Validate work time less than 4hrs.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Validate work time less than 4hrs.']))]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlte.tests.test_case import TestCase\n",
    "from mlte.tests.test_suite import TestSuite\n",
    "\n",
    "# The Evidence types we will use to validate each condition.\n",
    "from mlte.measurement.storage import LocalObjectSize\n",
    "from mlte.measurement.cpu import LocalProcessCPUUtilization\n",
    "from mlte.measurement.units import Units\n",
    "from mlte.measurement.memory import LocalProcessMemoryConsumption\n",
    "from mlte.evidence.types.image import Image\n",
    "from mlte.evidence.types.string import String\n",
    "from mlte.evidence.types.real import Real\n",
    "from demo.scenarios import validators\n",
    "from demo.scenarios.evidence.multiple_ranksums import MultipleRanksums\n",
    "from mlte.evidence.types.string import String\n",
    "from mlte.validation.validator import Validator\n",
    "\n",
    "\n",
    "# The full test suite.\n",
    "test_suite = TestSuite(\n",
    "    test_cases=[\n",
    "        # Fairness QAS test cases.\n",
    "        TestCase(\n",
    "            identifier=\"accuracy across gardens\",\n",
    "            goal=\"Check if model performs well accross different populations\",\n",
    "            quality_scenarios=[\"default.card-qas_001\"],\n",
    "            validator=validators.all_accuracies_more_or_equal_than(0.9),\n",
    "        ),\n",
    "        # Robustness QAS test cases.\n",
    "        TestCase(\n",
    "            identifier=\"ranksums blur2x8\",\n",
    "            goal=\"Check blur and noise for 2x8 case\",\n",
    "            quality_scenarios=[\"default.card-qas_002\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 / 3),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"ranksums blur5x8\",\n",
    "            goal=\"Check blur and noise for 5x8 case\",\n",
    "            quality_scenarios=[\"default.card-qas_002\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 / 3),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"ranksums blur0x8\",\n",
    "            goal=\"Check blur and noise for 0x8 case\",\n",
    "            quality_scenarios=[\"default.card-qas_002\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 / 3),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"effect of blur across families\",\n",
    "            goal=\"Check consistency in families\",\n",
    "            quality_scenarios=[\"default.card-qas_002\"],\n",
    "            validator=MultipleRanksums.all_p_values_greater_or_equal_than(0.05 / 141),\n",
    "        ),\n",
    "        #Resilience QAS test case \n",
    "        TestCase(\n",
    "            identifier=\"ranksums channel loss R\",\n",
    "            goal=\"Check consistency between channel loss\",\n",
    "            quality_scenarios=[\"default.card-qas_003\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"ranksums channel loss G\",\n",
    "            goal=\"Check consistency between channel loss\",\n",
    "            quality_scenarios=[\"default.card-qas_003\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"ranksums channel loss B\",\n",
    "            goal=\"Check consistency between channel loss\",\n",
    "            quality_scenarios=[\"default.card-qas_003\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05),\n",
    "        ),\n",
    "        # Resource Utilization QASs test cases.\n",
    "        TestCase(\n",
    "            identifier=\"model size\",\n",
    "            goal=\"Check storage consumption\",\n",
    "            quality_scenarios=[\"default.card-qas_004\"],\n",
    "            validator=LocalObjectSize.get_output_type().less_than(\n",
    "                150, Units.megabyte\n",
    "            ),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"predicting memory\",\n",
    "            goal=\"Check memory used while predicting\",\n",
    "            quality_scenarios=[\"default.card-qas_004\"],\n",
    "            validator=LocalProcessMemoryConsumption.get_output_type().average_consumption_less_than(\n",
    "                512.0, unit=Units.megabyte\n",
    "            ),\n",
    "        ),\n",
    "        TestCase(\n",
    "            identifier=\"predicting cpu\",\n",
    "            goal=\"Check cpu % used while predicting\",\n",
    "            quality_scenarios=[\"default.card-qas_004\"],\n",
    "            validator=LocalProcessCPUUtilization.get_output_type().max_utilization_less_than(\n",
    "                30.0, unit=Units.percent\n",
    "            ),\n",
    "        ), \n",
    "        # Understandability QAS test case.\n",
    "        #TestCase(\n",
    "        #    identifier=\"image attributions\",\n",
    "        #    goal=\"Check what the model is doing\",\n",
    "        #    quality_scenarios=[\"default.card-qas_005\"],\n",
    "        #    validator=Image.register_info(\"Inspect the image.\"),\n",
    "        #),\n",
    "        # Functional Correctness - Accuracy QAS test cases.\n",
    "        TestCase(\n",
    "            identifier=\"overall model accuracy\",\n",
    "            goal=\"Measure the overall accuracy of your end to end pipeline\",\n",
    "            quality_scenarios=[\"default.card-qas_006\"],\n",
    "            validator=Real.greater_than(0.9),\n",
    "        ),\n",
    "        # Functional Correctness - I/O spec QAS test cases.\n",
    "        #TestCase(\n",
    "        #    identifier=\"input format validation success\",\n",
    "        #    goal=\"Model input format must conform to specified format\",\n",
    "        #    quality_scenarios=[\"default.card-qas_007\"],\n",
    "        #    validator=String.contains(\"Model - Input Validation Pass\"),\n",
    "        #),\n",
    "        #TestCase(\n",
    "        #    identifier=\"output format validation success\",\n",
    "        #    goal=\"Model output format must conform to specified format\",\n",
    "        #    quality_scenarios=[\"default.card-qas_007\"],\n",
    "        #    validator=String.contains(\"Model - Output Validation Pass\"),\n",
    "        #),\n",
    "        # Reliability: Input Validation QAS test cases.\n",
    "        #TestCase(\n",
    "        #    identifier=\"input format validation error\",\n",
    "        #    goal=\"Model inputs must conform to specified format\",\n",
    "        #    quality_scenarios=[\"default.card-qas_008\"],\n",
    "        #    validator=String.contains(\"Model - Input Validation Error\"),\n",
    "        #),\n",
    "        #  Analyzability QAS test cases.\n",
    "        #TestCase(\n",
    "        #    identifier=\"detect ood inputs\",\n",
    "        #    goal=\"Monitor inputs for OOD data and unexpected shifts\",\n",
    "        #    quality_scenarios=[\"default.card-qas_009\"],\n",
    "        #    validator=String.contains(\"Model - Input OOD Error\"),\n",
    "        #), \n",
    "        #Monitorability QAS test case\n",
    "        #TestCase(\n",
    "        #    identifier=\"monitor output confidence shift\",\n",
    "        #    goal=\"Monitor inputs for OOD data and unexpected shifts\",\n",
    "        #    quality_scenarios=[\"default.card-qas_010\"],\n",
    "        #    validator=String.contains(\"Model - Output Confidence Error\"),\n",
    "        #),\n",
    "        #Time Behaviour \n",
    "        #TestCase(\n",
    "        #    identifier=\"predicting cpu time\",\n",
    "        #    goal=\"Check cpu time used while predicting\",\n",
    "        #    quality_scenarios=[\"default.card-qas_011\"],\n",
    "        #    validator=Real.less_than(2.0, Units.second),\n",
    "        #),\n",
    "        #Repeatability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"repeated results sampling\",\n",
    "            goal=\"Repeatedly sampling results gives same results\",\n",
    "            quality_scenarios=[\"default.card-qas_012\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 ),\n",
    "        ),\n",
    "        #Reproducability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"repeated training on training samples\",\n",
    "            goal=\"Repeatedly training on different sammples of training data gives same results on test data set\",\n",
    "            quality_scenarios=[\"default.card-qas_013\"],\n",
    "            validator=validators.p_value_greater_or_equal_to(0.05 ),\n",
    "        ),\n",
    "        #Domain Adaptability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"running in new domain\",\n",
    "            goal=\"Repeatedly training on different sammples of training data gives same results on test data set\",\n",
    "            quality_scenarios=[\"default.card-qas_014\"],\n",
    "            validator=MultipleRanksums.all_p_values_greater_or_equal_than(0.05 ),\n",
    "        ),\n",
    "        #Testability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"test results from dev and op env\",\n",
    "            goal=\"aligment of test results from dev and op environments\",\n",
    "            quality_scenarios=[\"default.card-qas_015\"],\n",
    "            validator=Validator.build_info_validator(\"Inspect the alignment of results for no more than 0.25% difference.\"),\n",
    "        ),\n",
    "        #Understandability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"understanding design choices\",\n",
    "            goal=\"understanding design and implementation choices\",\n",
    "            quality_scenarios=[\"default.card-qas_016\"],\n",
    "            validator=Validator.build_info_validator(\"Inspect projrct code and documentation.\"),\n",
    "        ),\n",
    "        #Maintainability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"keep ML component up to date\",\n",
    "            goal=\"keep trained ML component up to date with op environment changes\",\n",
    "            quality_scenarios=[\"default.card-qas_017\"],\n",
    "            validator=Validator.build_info_validator(\"Validate work time less than 8hrs.\"),\n",
    "        ),\n",
    "        #Modifiability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"update data pipelines\",\n",
    "            goal=\"aligment of test results from dev and op environments\",\n",
    "            quality_scenarios=[\"default.card-qas_018\"],\n",
    "            validator=Validator.build_info_validator(\"Validate work time less than 4hrs.\"),\n",
    "        ),\n",
    "        #Replaceability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"update ML training algorithm\",\n",
    "            goal=\"update ML component training algorithm\",\n",
    "            quality_scenarios=[\"default.card-qas_019\"],\n",
    "            validator=Validator.build_info_validator(\"Validate train time less than 16hrs.\"),\n",
    "        ),\n",
    "        #Reuseability QAS test case\n",
    "        TestCase(\n",
    "            identifier=\"reuse ML component\",\n",
    "            goal=\"reuse ML component in new app\",\n",
    "            quality_scenarios=[\"default.card-qas_020\"],\n",
    "            validator=Validator.build_info_validator(\"Validate work time less than 4hrs.\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "test_suite.save(parents=True, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
