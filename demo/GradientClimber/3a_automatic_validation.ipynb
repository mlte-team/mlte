{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b184657",
   "metadata": {},
   "source": [
    "## 3a. Automatic Validation\n",
    "\n",
    "The final phase of SDMT involves aggregating evidence, validating the metrics reflected by the evidence we collected, and displaying this information in a report. In this first step, we will do the automatic validation of the test cases against the `Evidence` we have collected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c4fd3",
   "metadata": {},
   "source": [
    "### Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active session. Initializing the context tells MLTE how to store all of the artifacts that it produces. This import will also set up global constants related to folders and model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09014e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial custom lists at URI: local:///Users/jhansen/continuum/mlte/demo/GradientClimber/../store\n",
      "Loaded 7 qa_categories for initial list\n",
      "Loaded 30 quality_attributes for initial list\n",
      "Creating sample catalog at URI: StoreType.LOCAL_FILESYSTEM:local:///Users/jhansen/continuum/mlte/demo/GradientClimber/../store\n",
      "Loading sample catalog entries.\n",
      "Loaded 9 entries for sample catalog.\n"
     ]
    }
   ],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from demo.GradientClimber.session import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9921b916",
   "metadata": {},
   "source": [
    "### Automatic Validation\n",
    "\n",
    "Now run the automatic validation for all test cases, given the collected `Evidence` in the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b5eee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Test Case: functional correctness, result: Success, details: All accuracies are equal to or over threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]\n",
      " > Test Case: reliability, result: Failure, details: One or more accuracies are below threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]\n",
      " > Test Case: gradient climber position accuracy, result: Success, details: All accuracies are equal to or over threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]\n",
      " > Test Case: gradient climber velocity accuracy, result: Failure, details: One or more accuracies are below threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]\n",
      " > Test Case: interpretability, result: Info, details: Inspect project code and documentation.\n",
      " > Test Case: deployability, result: Info, details: Inspect project code and documentation.\n",
      " > Test Case: portability, result: Info, details: Inspect project code and documentation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ArtifactModel(header=ArtifactHeaderModel(identifier='results.default', type='results', timestamp=1761661508, creator=None, level='version'), body=TestResultsModel(artifact_type=<ArtifactType.TEST_RESULTS: 'results'>, test_suite_id='suite.default', test_suite=TestSuiteModel(artifact_type=<ArtifactType.TEST_SUITE: 'suite'>, test_cases=[TestCaseModel(identifier='functional correctness', goal='Check if model complies with position requirements', qas_list=['default.card-qas_001'], measurement=None, validator=ValidatorModel(bool_exp='gASVuQIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMOi9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vc2NlbmFyaW9zL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoEIWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHE5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UjDNhbGxfYWNjdXJhY2llc19tb3JlX29yX2VxdWFsX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6UdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgvjAdzZXRhdHRylJOUh5RSlGgkjA1jZWxsX2NvbnRlbnRzlEc/7/fO2RaHK4eUUjAu', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='reliability', goal='Check if model complies with position requirements', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVuQIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMOi9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vc2NlbmFyaW9zL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoEIWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHE5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UjDNhbGxfYWNjdXJhY2llc19tb3JlX29yX2VxdWFsX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6UdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgvjAdzZXRhdHRylJOUh5RSlGgkjA1jZWxsX2NvbnRlbnRzlEc/7/fO2RaHK4eUUjAu', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='gradient climber position accuracy', goal='Check if model complies with position requirements', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVuQIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMOi9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vc2NlbmFyaW9zL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoEIWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHE5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UjDNhbGxfYWNjdXJhY2llc19tb3JlX29yX2VxdWFsX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6UdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgvjAdzZXRhdHRylJOUh5RSlGgkjA1jZWxsX2NvbnRlbnRzlEc/7/fO2RaHK4eUUjAu', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='gradient climber velocity accuracy', goal='Check if model complies with position requirements', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVuQIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMOi9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vc2NlbmFyaW9zL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoEIWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHE5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UjDNhbGxfYWNjdXJhY2llc19tb3JlX29yX2VxdWFsX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6UdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgvjAdzZXRhdHRylJOUh5RSlGgkjA1jZWxsX2NvbnRlbnRzlEc/7/fO2RaHK4eUUjAu', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='interpretability', goal='Model output is from the RL Gym mountain car example which can only produce 0,1 or 2 as output.', qas_list=['default.card-qas_005'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect project code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect project code and documentation.'])), TestCaseModel(identifier='deployability', goal='Verified that the q-table file is available and of a manageable size.', qas_list=['default.card-qas_006'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect project code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect project code and documentation.'])), TestCaseModel(identifier='portability', goal='Data is in the form of an npy file which is portable by design.', qas_list=['default.card-qas_007'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect project code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect project code and documentation.']))]), results={'functional correctness': ResultModel(type='Success', message='All accuracies are equal to or over threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]', evidence_metadata=EvidenceMetadata(test_case_id='functional correctness', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.test_functional_correctness'}))), 'reliability': ResultModel(type='Failure', message='One or more accuracies are below threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]', evidence_metadata=EvidenceMetadata(test_case_id='reliability', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.test_reliability'}))), 'gradient climber position accuracy': ResultModel(type='Success', message='All accuracies are equal to or over threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]', evidence_metadata=EvidenceMetadata(test_case_id='gradient climber position accuracy', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.test_position_compliance'}))), 'gradient climber velocity accuracy': ResultModel(type='Failure', message='One or more accuracies are below threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]', evidence_metadata=EvidenceMetadata(test_case_id='gradient climber velocity accuracy', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.test_velocity_compliance'}))), 'interpretability': ResultModel(type='Info', message='Inspect project code and documentation.', evidence_metadata=None), 'deployability': ResultModel(type='Info', message='Inspect project code and documentation.', evidence_metadata=None), 'portability': ResultModel(type='Info', message='Inspect project code and documentation.', evidence_metadata=None)}))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlte.validation.test_suite_validator import TestSuiteValidator\n",
    "\n",
    "# Load validator for default TestSuite id\n",
    "test_suite_validator = TestSuiteValidator()\n",
    "\n",
    "# Load all Evidence and validate TestCases\n",
    "test_results = test_suite_validator.load_and_validate()\n",
    "\n",
    "# We want to see the validation results in the Notebook, regardless of them being saved.\n",
    "test_results.print_results()\n",
    "\n",
    "# TestResults also supports persistence\n",
    "test_results.save(force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
