{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9a0bb9",
   "metadata": {},
   "source": [
    "## 3b. Manual Validation - Adding Success/Failure validation to qualitative QAS\n",
    "\n",
    "Some test cases require Evidence that can't be gathered by the tool, so we want to define that outside of the tool, and then manually mark them as Success or Failure. Note that some functions will be loaded from external Python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1e30f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial custom lists at URI: local:///Users/jhansen/continuum/mlte/demo/GradientClimber/../store\n",
      "Loaded 7 qa_categories for initial list\n",
      "Loaded 30 quality_attributes for initial list\n",
      "Creating sample catalog at URI: StoreType.LOCAL_FILESYSTEM:local:///Users/jhansen/continuum/mlte/demo/GradientClimber/../store\n",
      "Loading sample catalog entries.\n",
      "Loaded 9 entries for sample catalog.\n"
     ]
    }
   ],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from demo.GradientClimber.session import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b0ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Test Case: interpretability, result: Info, details: Inspect project code and documentation.\n",
      " > Test Case: deployability, result: Info, details: Inspect project code and documentation.\n",
      " > Test Case: portability, result: Info, details: Inspect project code and documentation.\n"
     ]
    }
   ],
   "source": [
    "from mlte.results.test_results import TestResults\n",
    "\n",
    "# Load test results\n",
    "test_results = TestResults.load()\n",
    "\n",
    "# See which are marked as Info (not validated)\n",
    "test_results.print_results(result_type=\"Info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ae484f",
   "metadata": {},
   "source": [
    "Now we will manually validate all cases that we know were not validated automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7714f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Test Case: functional correctness, result: Success, details: All accuracies are equal to or over threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]\n",
      " > Test Case: reliability, result: Failure, details: One or more accuracies are below threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]\n",
      " > Test Case: gradient climber position accuracy, result: Success, details: All accuracies are equal to or over threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]\n",
      " > Test Case: gradient climber velocity accuracy, result: Failure, details: One or more accuracies are below threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]\n",
      " > Test Case: interpretability, result: Success, details: Manually validated: Model output is from the RL Gym mountain car example which can only produce 0,1 or 2 as output. (original message: Inspect project code and documentation.)\n",
      " > Test Case: deployability, result: Success, details: Manually validated: Verified that the q-table file is available and of a manageable size. (original message: Inspect project code and documentation.)\n",
      " > Test Case: portability, result: Success, details: Manually validated: Data is in the form of an npy file which is portable by design. (original message: Inspect project code and documentation.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ArtifactModel(header=ArtifactHeaderModel(identifier='results.default', type='results', timestamp=1761661541, creator=None, level='version'), body=TestResultsModel(artifact_type=<ArtifactType.TEST_RESULTS: 'results'>, test_suite_id='suite.default', test_suite=TestSuiteModel(artifact_type=<ArtifactType.TEST_SUITE: 'suite'>, test_cases=[TestCaseModel(identifier='functional correctness', goal='Check if model complies with position requirements', qas_list=['default.card-qas_001'], measurement=None, validator=ValidatorModel(bool_exp='gASVuQIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMOi9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vc2NlbmFyaW9zL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoEIWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHE5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UjDNhbGxfYWNjdXJhY2llc19tb3JlX29yX2VxdWFsX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6UdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgvjAdzZXRhdHRylJOUh5RSlGgkjA1jZWxsX2NvbnRlbnRzlEc/7/fO2RaHK4eUUjAu', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='reliability', goal='Check if model complies with position requirements', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVuQIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMOi9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vc2NlbmFyaW9zL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoEIWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHE5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UjDNhbGxfYWNjdXJhY2llc19tb3JlX29yX2VxdWFsX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6UdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgvjAdzZXRhdHRylJOUh5RSlGgkjA1jZWxsX2NvbnRlbnRzlEc/7/fO2RaHK4eUUjAu', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='gradient climber position accuracy', goal='Check if model complies with position requirements', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVuQIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMOi9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vc2NlbmFyaW9zL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoEIWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHE5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UjDNhbGxfYWNjdXJhY2llc19tb3JlX29yX2VxdWFsX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6UdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgvjAdzZXRhdHRylJOUh5RSlGgkjA1jZWxsX2NvbnRlbnRzlEc/7/fO2RaHK4eUUjAu', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='gradient climber velocity accuracy', goal='Check if model complies with position requirements', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVuQIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMOi9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vc2NlbmFyaW9zL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoEIWUKXSUUpRjZGVtby5zY2VuYXJpb3MudmFsaWRhdG9ycwpfX2RpY3RfXwpoHE5oAIwMX2NyZWF0ZV9jZWxslJOUToWUUpSFlHSUUpR9lH2UKIwPX19hbm5vdGF0aW9uc19flH2UjAxfX3F1YWxuYW1lX1+UjDNhbGxfYWNjdXJhY2llc19tb3JlX29yX2VxdWFsX3RoYW4uPGxvY2Fscz4uPGxhbWJkYT6UdYaUYowIYnVpbHRpbnOUjAdnZXRhdHRylJOUjARkaWxslIwFX2RpbGyUk5SMCF9zZXRhdHRylGgvjAdzZXRhdHRylJOUh5RSlGgkjA1jZWxsX2NvbnRlbnRzlEc/7/fO2RaHK4eUUjAu', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.scenarios.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='interpretability', goal='Model output is from the RL Gym mountain car example which can only produce 0,1 or 2 as output.', qas_list=['default.card-qas_005'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect project code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect project code and documentation.'])), TestCaseModel(identifier='deployability', goal='Verified that the q-table file is available and of a manageable size.', qas_list=['default.card-qas_006'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect project code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect project code and documentation.'])), TestCaseModel(identifier='portability', goal='Data is in the form of an npy file which is portable by design.', qas_list=['default.card-qas_007'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect project code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect project code and documentation.']))]), results={'functional correctness': ResultModel(type='Success', message='All accuracies are equal to or over threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]', evidence_metadata=EvidenceMetadata(test_case_id='functional correctness', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.test_functional_correctness'}))), 'reliability': ResultModel(type='Failure', message='One or more accuracies are below threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]', evidence_metadata=EvidenceMetadata(test_case_id='reliability', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.test_reliability'}))), 'gradient climber position accuracy': ResultModel(type='Success', message='All accuracies are equal to or over threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]', evidence_metadata=EvidenceMetadata(test_case_id='gradient climber position accuracy', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.test_position_compliance'}))), 'gradient climber velocity accuracy': ResultModel(type='Failure', message='One or more accuracies are below threshold 0.999 - values: [\"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\"]', evidence_metadata=EvidenceMetadata(test_case_id='gradient climber velocity accuracy', measurement=MeasurementMetadata(measurement_class='mlte.measurement.external_measurement.ExternalMeasurement', output_class='mlte.evidence.types.array.Array', additional_data={'function': '__main__.test_velocity_compliance'}))), 'interpretability': ResultModel(type='Success', message='Manually validated: Model output is from the RL Gym mountain car example which can only produce 0,1 or 2 as output. (original message: Inspect project code and documentation.)', evidence_metadata=None), 'deployability': ResultModel(type='Success', message='Manually validated: Verified that the q-table file is available and of a manageable size. (original message: Inspect project code and documentation.)', evidence_metadata=None), 'portability': ResultModel(type='Success', message='Manually validated: Data is in the form of an npy file which is portable by design. (original message: Inspect project code and documentation.)', evidence_metadata=None)}))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlte.results.result import Success\n",
    "from mlte.results.result import Failure\n",
    "\n",
    "MANUAL_VALIDATION = [\n",
    "    {\n",
    "        \"id\": \"interpretability\",\n",
    "        \"result\": Success,\n",
    "        \"message\": \"Model output is from the RL Gym mountain car example which can only produce 0,1 or 2 as output.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"deployability\",\n",
    "        \"result\": Success,\n",
    "        \"message\": \"Verified that the q-table file is available and of a manageable size.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"portability\",\n",
    "        \"result\": Success,\n",
    "        \"message\": \"Data is in the form of an npy file which is portable by design.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for r in MANUAL_VALIDATION:\n",
    "    test_results.convert_result(\n",
    "        test_case_id=r[\"id\"], result_type=r[\"result\"], message=r[\"message\"]\n",
    "    )\n",
    "\n",
    "test_results.print_results()\n",
    "test_results.save(force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
