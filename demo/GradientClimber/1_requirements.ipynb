{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAS Demo\n",
    "\n",
    "This notebook is adapted for use in the Gradient Climber application using the Garden Buddy application as an example.  We use the Gradient Climber Quality Attribute Scenarios as guidence for the required Properties and Conditions.\n",
    "\n",
    "NOTE: this demo has an additional set of requirements than MLTE. You can install them with the command: \n",
    "\n",
    "`poetry install --with demo`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Quality Attribute Scenarios\n",
    "\n",
    "The following are the QASs that we want to validate through the use of MLTE. The examples below relate to a reinforcement learning system based on the mountain car example [Andrew W. Moore (1990). Efficient Memory-Based Learning for Robot Control (PhD thesis, University of Cambridge)] ().\n",
    "\n",
    "* **Interpretability - Model Produces Valid Outputs**\n",
    "The model always produces outputs according to the output actions specified in the  documentation during normal operation\n",
    "\n",
    "\n",
    "* **Functional Correctness - Model Does the Expected Thing**\n",
    "Agent receives \"start\" command from system initialized with random position during Normal Operation. Agent moves car to desired location of x=0.6 within 250 time steps.\n",
    "After initialization, the model successfully navigates the vehicle from a stationary position at the bottom of a hill, to the desired location (top of the hill in front of the vehicle) within the specified time bound.\n",
    "\n",
    "* **Deployability - Model Can be Deployed into Productin When Needed**\n",
    "New version of agent Q-table deployed onto device during Maintenance. New q-table is loaded into into available memory and system produces outputs within 16ms (60hz).\n",
    "\n",
    "* **Reliability - Model Performs as Exected without Failure**\n",
    "Model receives valid values from sensors during Normal Operation and produces outputs (actions) which improve the expected reward 99.9% of the time.\n",
    "Model receives valid input values from from sensors during normal operation with the gradient climber system active. The model output is correct and improves the expected reward 99.9% of the time.\n",
    "\n",
    "* **Portability - Model can be Adatped for Use on New Hardware/Software Platforms**\n",
    "A new model is generated during the model training process. The model should be serialized in a format that can be moved across platforms with no need for retraining \n",
    "\n",
    "* **Compliance (Speed) - Model Adheres to Designated Ethical and Saftey Requirements**\n",
    "The model receives a position and velocity input from *source* during normal operations. Regardless of input, the model will not produce output values that cause the vehicle to exceed the legal speed limit set in the operational configuration.\n",
    "\n",
    "* **Compliance (Position) - Model Adheres to Designated Ethical and Saftey Requirements**\n",
    "The model receives a position and velocity from *source* during normal operations. Regardless of input, the model will not produce output values that cause the vehicle to exit the area of operation set in the operational configuration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Requirements\n",
    "\n",
    "## 1.1 Initialize MLTE Context\n",
    "\n",
    "MLTE contains a global context that manages the currently active _session_. Initializing the context tells MLTE how to store all of the artifacts that it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial custom lists at URI: local:///Users/jhansen/continuum/mlte/demo/GradientClimber/../store\n",
      "Loaded 7 qa_categories for initial list\n",
      "Loaded 30 quality_attributes for initial list\n",
      "Creating sample catalog at URI: StoreType.LOCAL_FILESYSTEM:local:///Users/jhansen/continuum/mlte/demo/GradientClimber/../store\n",
      "Loading sample catalog entries.\n",
      "Loaded 9 entries for sample catalog.\n"
     ]
    }
   ],
   "source": [
    "# Sets up context for the model being used, sets up constants related to folders and model data to be used.\n",
    "from demo.GradientClimber.session import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Build a `NegotiationCard`\n",
    "\n",
    "In MLTE, we negotiation requirements with the help of a `NegotiationCard`. This can be done manually through code, but it is easier to use the MLTE UI to do so. Below we are copying a pre-built one that applies to this scenario. In MLTE, we define requirements by constructing a `NegotiationCard` that will include explicit Quality Attribute Scenarios with the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "(cd ../ && bash setup_store.sh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Define a TestSuite\n",
    "\n",
    "In the first phase of SDMT, we define a `TestSuite` that represents the tests the completed model must will have to pass in order to be acceptable for use in the system into which it will be integrated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MLTE, we define the tests that will be required for the different requirements in a `TestSuite`. Note that a new `Evidence` types (`MultipleRanksums`) had to be created in this case to handle the data and `Validator` for that case, and two stand-alone `Validator`s were defined in `validators.py` to validate data using existing `Evidence` types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load up our `NegotiationCard`, so we can get the list of ids of its quaity attribute scenarios, that will be added to the `TestCase`s here. Those ids are the way to link the `TestCase`s to their quality attribute requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default.card-qas_001 (Accuracy): After initialization, the from user activates the gradient climber system while in normal operation with the vehicle stationary and located at the bottom of a hill, the model outputs manipulate the vehicle state to, produces a position=0.6 at some time $t$<250\n",
      "default.card-qas_002 (Accuracy): Model receives valid input values from  from  sensors while in normal operation with the gradient climber system active, the model output is correct, and improves the expected reward 99.9% of the time\n",
      "default.card-qas_003 (Model Impartial to Photo Location): Regardless of input values  from sensors while in normal operation with the gradient climber system active, the model will not produce output values that cause the vehicle to exit the area of operation specified in the set operational configuration., the position is compared to the operational parameters, and verified that -1.2<position<0.6\n",
      "default.card-qas_004 (Detect Shifts in Output (Confidence) Distribution): Regardless of input values  from sensors while in normal operation with the gradient climber system active, the model will not produce output values that cause the velocity to exceed the legal speed limit set in the operational configuration. , this is measured by making sure that $|vehicle_velocity|<0.05$ at all times.\n",
      "default.card-qas_005 (Interpretability): When a model generates from outputs while in during operations, those outputs are always in the set of allowed outputs as documented., all observed outputs from model are from the documented output set\n",
      "default.card-qas_006 (Deployability): When a new version of a model is deployed onto from a new device while in during maintenance, the model will operate correctly and produce outputs within 16ms., ensure that the model begins operating within 16ms of deployment\n",
      "default.card-qas_007 (Portability): Capability of an ml component to be adapted for or transferred to from a different harderware, software or operational environment while in , without any unanticipated side effects and within specified resource and time constraints, model can be serialized in a way that can be moved across platforms\n"
     ]
    }
   ],
   "source": [
    "from mlte.negotiation.artifact import NegotiationCard\n",
    "\n",
    "card = NegotiationCard.load()\n",
    "card.save(force=True)\n",
    "card.print_quality_scenarios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our `TestSuite`, consisting of a list of `TestCases`, each of them addressing one or more Quality Attribute Scenarios from our `NegotiationCard`. When defining the `TestCase`s below, we need to set the id of the corresponding Quality Attribute Scenario we want to test in its \"quality_scenarios\" attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArtifactModel(header=ArtifactHeaderModel(identifier='suite.default', type='suite', timestamp=1761662158, creator=None, level='model'), body=TestSuiteModel(artifact_type=<ArtifactType.TEST_SUITE: 'suite'>, test_cases=[TestCaseModel(identifier='functional correctness', goal='Check if model complies with position requirements', qas_list=['default.card-qas_001'], measurement=None, validator=ValidatorModel(bool_exp='gASVwwIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMQC9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vR3JhZGllbnRDbGltYmVyL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoESl0lFKUY2RlbW8uR3JhZGllbnRDbGltYmVyLnZhbGlkYXRvcnMKX19kaWN0X18KaBxOaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flIwzYWxsX2FjY3VyYWNpZXNfbW9yZV9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lHWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoLowHc2V0YXR0cpSTlIeUUpRoI4wNY2VsbF9jb250ZW50c5RHP+/3ztkWhyuHlFIwLg==', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.GradientClimber.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='reliability', goal='Check if model complies with position requirements', qas_list=['default.card-qas_002'], measurement=None, validator=ValidatorModel(bool_exp='gASVwwIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMQC9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vR3JhZGllbnRDbGltYmVyL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoESl0lFKUY2RlbW8uR3JhZGllbnRDbGltYmVyLnZhbGlkYXRvcnMKX19kaWN0X18KaBxOaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flIwzYWxsX2FjY3VyYWNpZXNfbW9yZV9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lHWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoLowHc2V0YXR0cpSTlIeUUpRoI4wNY2VsbF9jb250ZW50c5RHP+/3ztkWhyuHlFIwLg==', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.GradientClimber.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='gradient climber position accuracy', goal='Check if model complies with position requirements', qas_list=['default.card-qas_003'], measurement=None, validator=ValidatorModel(bool_exp='gASVwwIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMQC9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vR3JhZGllbnRDbGltYmVyL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoESl0lFKUY2RlbW8uR3JhZGllbnRDbGltYmVyLnZhbGlkYXRvcnMKX19kaWN0X18KaBxOaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flIwzYWxsX2FjY3VyYWNpZXNfbW9yZV9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lHWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoLowHc2V0YXR0cpSTlIeUUpRoI4wNY2VsbF9jb250ZW50c5RHP+/3ztkWhyuHlFIwLg==', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.GradientClimber.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='gradient climber velocity accuracy', goal='Check if model complies with position requirements', qas_list=['default.card-qas_004'], measurement=None, validator=ValidatorModel(bool_exp='gASVwwIAAAAAAACMCmRpbGwuX2RpbGyUjBBfY3JlYXRlX2Z1bmN0aW9ulJOUKGgAjAxfY3JlYXRlX2NvZGWUk5QoQwgMAQT/BgII/pRLAUsASwBLAUsESxNDInQAhwBmAWQBZAKECHwAagFEAIMBgwF0AnwAagGDAWsCUwCUTmgEKEMEBgEI/5RLAUsASwBLAksDSzNDGIEAfABdB30BfAGIAGsFVgABAHECZABTAJROhZQpjAIuMJSMAWeUhpSMQC9Vc2Vycy9qaGFuc2VuL2NvbnRpbnV1bS9tbHRlL2RlbW8vR3JhZGllbnRDbGltYmVyL3ZhbGlkYXRvcnMucHmUjAk8Z2VuZXhwcj6USxJDCAKABAAIAQr/lIwJdGhyZXNob2xklIWUKXSUUpSMRmFsbF9hY2N1cmFjaWVzX21vcmVfb3JfZXF1YWxfdGhhbi48bG9jYWxzPi48bGFtYmRhPi48bG9jYWxzPi48Z2VuZXhwcj6Uh5SMA3N1bZSMBWFycmF5lIwDbGVulIeUjAV2YWx1ZZSFlGgNjAg8bGFtYmRhPpRLEkMKDAAEAQb/CAIE/pRoESl0lFKUY2RlbW8uR3JhZGllbnRDbGltYmVyLnZhbGlkYXRvcnMKX19kaWN0X18KaBxOaACMDF9jcmVhdGVfY2VsbJSTlE6FlFKUhZR0lFKUfZR9lCiMD19fYW5ub3RhdGlvbnNfX5R9lIwMX19xdWFsbmFtZV9flIwzYWxsX2FjY3VyYWNpZXNfbW9yZV9vcl9lcXVhbF90aGFuLjxsb2NhbHM+LjxsYW1iZGE+lHWGlGKMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwEZGlsbJSMBV9kaWxslJOUjAhfc2V0YXR0cpRoLowHc2V0YXR0cpSTlIeUUpRoI4wNY2VsbF9jb250ZW50c5RHP+/3ztkWhyuHlFIwLg==', bool_exp_str='lambda value: (sum(((g >= threshold) for g in value.array)) == len(value.array))', thresholds=[], success='All accuracies are equal to or over threshold 0.999', failure='One or more accuracies are below threshold 0.999', info=None, input_types=['mlte.evidence.types.array.Array'], creator_entity='demo.GradientClimber.validators', creator_function='all_accuracies_more_or_equal_than', creator_args=['0.999'])), TestCaseModel(identifier='interpretability', goal='Model output is from the RL Gym mountain car example which can only produce 0,1 or 2 as output.', qas_list=['default.card-qas_005'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect project code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect project code and documentation.'])), TestCaseModel(identifier='deployability', goal='Verified that the q-table file is available and of a manageable size.', qas_list=['default.card-qas_006'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect project code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect project code and documentation.'])), TestCaseModel(identifier='portability', goal='Data is in the form of an npy file which is portable by design.', qas_list=['default.card-qas_007'], measurement=None, validator=ValidatorModel(bool_exp=None, bool_exp_str=None, thresholds=[], success=None, failure=None, info='Inspect project code and documentation.', input_types=[], creator_entity='mlte.validation.validator.Validator', creator_function='build_info_validator', creator_args=['Inspect project code and documentation.']))]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlte.tests.test_case import TestCase\n",
    "from mlte.tests.test_suite import TestSuite\n",
    "\n",
    "# The Evidence types we will use to validate each condition.\n",
    "from mlte.measurement.storage import LocalObjectSize\n",
    "from mlte.measurement.cpu import LocalProcessCPUUtilization\n",
    "from mlte.measurement.units import Units\n",
    "from mlte.measurement.memory import LocalProcessMemoryConsumption\n",
    "from mlte.evidence.types.image import Image\n",
    "from mlte.evidence.types.string import String\n",
    "from mlte.evidence.types.real import Real\n",
    "from demo.GradientClimber import validators\n",
    "from mlte.evidence.types.string import String\n",
    "from mlte.validation.validator import Validator\n",
    "\n",
    "test_suite = TestSuite(\n",
    "    test_cases=[\n",
    "        # Functional correctness\n",
    "        TestCase(\n",
    "            identifier=\"functional correctness\",\n",
    "            goal=\"Ensure that the model navigates vehicle to goal location within required time\",\n",
    "            quality_scenarios=[\"default.card-qas_001\"],\n",
    "            validator=validators.passed_percent_more_or_equal_then(0.9),\n",
    "        ),\n",
    "        # Reliability\n",
    "        TestCase(\n",
    "            identifier=\"reliability\",\n",
    "            goal=\"Ensure model outputs an action that improves expected reward 99.9% of the time\",\n",
    "            quality_scenarios=[\"default.card-qas_002\"],\n",
    "            validator=validators.passed_percent_more_or_equal_then(0.999),\n",
    "        ),\n",
    "        # Compliance (position)\n",
    "        TestCase(\n",
    "            identifier=\"gradient climber position accuracy\",\n",
    "            goal=\"Check if model complies with position requirements\",\n",
    "            quality_scenarios=[\"default.card-qas_003\"],\n",
    "            validator=validators.passed_percent_more_or_equal_then(1.0),\n",
    "        ),\n",
    "        # Compliance (velocity)\n",
    "        TestCase(\n",
    "            identifier=\"gradient climber velocity accuracy\",\n",
    "            goal=\"Check if model complies with position requirements\",\n",
    "            quality_scenarios=[\"default.card-qas_004\"],\n",
    "            validator=validators.passed_percent_more_or_equal_then(1.0),\n",
    "        ),\n",
    "        # Interpretability\n",
    "        TestCase(\n",
    "            identifier=\"interpretability\",\n",
    "            goal=\"Model output is from the RL Gym mountain car example which can only produce 0,1 or 2 as output.\",\n",
    "            quality_scenarios=[\"default.card-qas_005\"],\n",
    "            validator=Validator.build_info_validator(\n",
    "                \"Inspect project code and documentation.\"\n",
    "            ),\n",
    "        ),\n",
    "        # Deployability\n",
    "        TestCase(\n",
    "            identifier=\"deployability\",\n",
    "            goal=\"Verified that the q-table file is available and of a manageable size.\",\n",
    "            quality_scenarios=[\"default.card-qas_006\"],\n",
    "            validator=Validator.build_info_validator(\n",
    "                \"Inspect project code and documentation.\"\n",
    "            ),\n",
    "        ),\n",
    "        # Portability\n",
    "        TestCase(\n",
    "            identifier=\"portability\",\n",
    "            goal=\"Data is in the form of an npy file which is portable by design.\",\n",
    "            quality_scenarios=[\"default.card-qas_007\"],\n",
    "            validator=Validator.build_info_validator(\n",
    "                \"Inspect project code and documentation.\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# The full test suite.\n",
    "\n",
    "test_suite.save(parents=True, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
